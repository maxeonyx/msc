{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a247b8c3-1a9d-42c1-bc9a-41c99ed78357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "assert len(physical_devices) == 3\n",
    "\n",
    "# to allow other tensorflow processes to use the gpu\n",
    "# https://stackoverflow.com/a/60699372/7989988\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[2], True)\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "from IPython.display import display\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import enlighten\n",
    "import tensorflow_probability as tfp\n",
    "from dotmap import DotMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d8b7f-1fa3-4787-8eb7-a341e673ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import training\n",
    "import datasets\n",
    "import vizualization\n",
    "import schedules\n",
    "\n",
    "# todo\n",
    "# - combine shuffled and unshuffled datasets into same thing\n",
    "# - add extra shuffled indices and noise\n",
    "# - add \"noise fraction\" parameter which can be changed the same way as the \"n\" parameter.\n",
    "# - add different amounts of noise to the data and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664a41e-2373-4007-ad5b-04367635212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DotMap({\n",
    "    'distributed': True,\n",
    "    'minibatch_size': 32,\n",
    "    'num_devices': 3,\n",
    "    'n_steps': 120001,\n",
    "    'test_size': 120,\n",
    "    'test_minibatch_size': 30,\n",
    "    'test_interval': 5000,\n",
    "    'test_n_shuf': [1, 8, 16, 32],\n",
    "    'test_n_seq': [1, 28*6, 28*9, 28*12],\n",
    "    'display_images': False,\n",
    "    'display_image_interval': 1000,\n",
    "    'dont_display_until_loss': 0.45,\n",
    "    'n_colors': 4,\n",
    "    'dataset': {\n",
    "        'buffer_size': 60000,\n",
    "    },\n",
    "    'bg_color': [1.0, 0.4, 0.6],\n",
    "    'lr_schedule': None,\n",
    "    'lr_warmup_steps': 300,\n",
    "    'max_lr': 0.0001,\n",
    "    'min_lr': 0.0001,\n",
    "    'batch_size_schedule': None,\n",
    "    'start_accum_steps': 1,\n",
    "    'end_accum_steps': 30,\n",
    "    'seq_length': 784,\n",
    "    'image_width': 28,\n",
    "    'image_height': 28,\n",
    "    'use_wandb': True,\n",
    "    'wandb_log_interval': 10,\n",
    "    'loss_window_size': 500,\n",
    "})\n",
    "\n",
    "# need to change for multiworkerstrategy\n",
    "if config.distributed:\n",
    "    config.num_devices = len(physical_devices)\n",
    "else:\n",
    "    config.num_devices = 1\n",
    "config.global_batch_size = config.minibatch_size * config.num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee847f8-c7e5-4889-af95-b4e635213d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea is to not have to re-run this cell for subsequent training runs unless the centroids change\n",
    "dataset, metadata = tfds.load('mnist', with_info=True, as_supervised=True)\n",
    "ds_train_original = dataset['train']\n",
    "ds_test_original = dataset['test']\n",
    "\n",
    "centroids = datasets.find_centroids(ds_train_original, num_clusters=config['n_colors'], batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3520fc-ca13-4318-8a43-9036938e8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_dist, gamma_name = datasets.mnist_gamma_distribution()\n",
    "ds = datasets.Datasets(config, ds_train_original, ds_test_original, centroids, gamma_dist)\n",
    "viz = vizualization.Viz(config, ds, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eff212-a982-456d-b8ac-30aed2cd39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_test = ds.make_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a3bbc-bc94-4fa4-9966-45fd3e96fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model config\n",
    "config.model = DotMap({\n",
    "        'n_colors': config.n_colors,\n",
    "        'n_enc_a_layers': 3,\n",
    "        'n_enc_b_layers': 3,\n",
    "        'ffl_dim': 800,\n",
    "        'embd_dim': 512,\n",
    "        'n_dec_layers': 3,\n",
    "        'dec_dim': 600,\n",
    "        'n_heads': 4,\n",
    "        'dropout_rate': 0.1,\n",
    "        'use_idxs_input': True,\n",
    "        'architecture': 'anp',\n",
    "        'position_embedding': 'pos_enc',\n",
    "        'activation': 'swish',\n",
    "    })\n",
    "\n",
    "if config.distributed == False:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.transformer(config.model)\n",
    "    # Adam params taken from the linked notebook\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=config.max_lr)\n",
    "\n",
    "ds_train_dist = strategy.experimental_distribute_dataset(ds_train)\n",
    "\n",
    "model_name = \"cuda6-0.1noise-3l-512w\"\n",
    "print(model_name)\n",
    "\n",
    "training.wandb_init(config, model_name, resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3be492-e108-4029-bbab-2809cd2c866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.training_mode = 'combination'\n",
    "training_loop = training.TrainingLoop(config, viz, model, optimizer, ds, ds_train_dist, ds_test, schedules.batch_size_schedule(config), model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f70ee-08ec-4530-9f47-192f9b46e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with strategy.scope():\n",
    "    training_loop.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f30fd6-3f96-4a8c-b4ae-52ba26ea1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop.process_batch(show_input=True)\n",
    "training_loop.new_test_batch()\n",
    "training_loop.process_batch(show_input=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910cb2da-bf45-4cc7-be45-1b20f98087f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d75399-2b6a-4609-a996-c227938332a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
