{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx9vGgfSkcpL"
   },
   "source": [
    "\n",
    "# Conditional autoregressive transformer\n",
    "\n",
    "Train a transformer to predict missing pixel from mnist \n",
    "\n",
    "### plan\n",
    "\n",
    "* note to try padded mnist (relative encoding might require black padding???)\n",
    "* probably don't need positional encoding?\n",
    "* create transformer model\n",
    "* masking \n",
    "* randomised masking\n",
    "* relative position encoding (x - current_x, y - current_y, val)\n",
    "* train to predict when current pixel missing\n",
    "* train to predict when 10% are missing\n",
    "* train to predict when 90% are missing\n",
    "* train to predict when 99% are missing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"txformer-pure-huge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init weights and biases project\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "\n",
    "wandb.init(project='conditional-mnist', entity='maxeonyx')\n",
    "config = wandb.config\n",
    "config.learning_rate = 0.01\n",
    "\n",
    "callbacks += [WandbCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve GPU 0 only (for VUW machines)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "\n",
    "def display_uint8_image(image, size=None):\n",
    "    if len(image.shape) == 3:\n",
    "        image = image[:, :, 0]\n",
    "    if tf.is_tensor(image):\n",
    "        image = image.numpy()\n",
    "    image = Image.fromarray(image, \"L\")\n",
    "    if size is not None:\n",
    "        image = image.resize(size, resample=Image.NEAREST)\n",
    "    display(image)\n",
    "\n",
    "def display_float32_image(image, size=None):\n",
    "    if len(image.shape) == 3:\n",
    "        image = image[:, :, 0]\n",
    "    if tf.is_tensor(image):\n",
    "        image = image.numpy()\n",
    "    display_uint8_image(image.astype(np.uint8), size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idxs_to_onehots(idxs, depth=784):\n",
    "    onehots = tf.one_hot(idxs, depth, dtype=tf.bool, on_value=False, off_value=True)\n",
    "    return onehots\n",
    "\n",
    "# takes 2D tensor (batch and index list)\n",
    "def idxs_to_multihot(idxs, depth=784):\n",
    "    onehots = idxs_to_onehots(idxs, depth)\n",
    "    multihot = tf.math.reduce_all(onehots, axis=len(onehots.shape)-2)\n",
    "    return multihot\n",
    "\n",
    "def idxs_to_attention_mask(idxs):\n",
    "    multihot = idxs_to_multihot(idxs)\n",
    "    attn_mask = tf.logical_and(multihot[:, :, None], multihot[:, None, :])\n",
    "    return attn_mask\n",
    "\n",
    "def mask_to_image_mask(mask):\n",
    "    image_mask = tf.reshape(mask, [28, 28])\n",
    "    return image_mask\n",
    "\n",
    "# scale is the max-min of vals\n",
    "# for mnist it's 28 because thats the width and height of the images\n",
    "def positional_encoding(vals, dims, scale=1000):\n",
    "\n",
    "    i = tf.range(dims//2, dtype=tf.float32)\n",
    "    i = tf.expand_dims(i, -2)\n",
    "    \n",
    "    vals = tf.expand_dims(vals, -1)\n",
    "    \n",
    "    # the bit inside the sin / cos\n",
    "    rate = vals / tf.pow(scale, 2.*i/dims)\n",
    "    \n",
    "    sin = tf.sin(rate)\n",
    "    cos = tf.cos(rate)\n",
    "    \n",
    "#     # expand dims to allow alternating concat\n",
    "#     sin = tf.expand_dims(sin, -1)\n",
    "#     cos = tf.expand_dims(cos, -1)\n",
    "    \n",
    "    encoding = tf.concat([sin, cos], axis=-1)\n",
    "    \n",
    "#     encoding = tf.reshape(encoding, [-1, dims])\n",
    "    \n",
    "    return encoding\n",
    "\n",
    "print(positional_encoding(tf.constant([0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi]), 8))\n",
    "\n",
    "def img_to_tuples(img):\n",
    "    \n",
    "    height, width = img.shape\n",
    "    length = height * width\n",
    "    vals = tf.reshape(img, [length])\n",
    "    vals = tf.cast(vals, tf.float32)\n",
    "    rows = tf.range(height, dtype=tf.int32)\n",
    "    cols = tf.range(width, dtype=tf.int32)\n",
    "    cols, rows = tf.meshgrid(rows, cols)\n",
    "    rows = tf.reshape(rows, [-1])\n",
    "    cols = tf.reshape(cols, [-1])\n",
    "    \n",
    "    # permute the order, to ensure the network uses the positional encoding and not the implicit locaiton\n",
    "    idxs = tf.range(length)\n",
    "    idxs = tf.random.shuffle(idxs)\n",
    "    \n",
    "    rows = tf.gather(rows, idxs)\n",
    "    cols = tf.gather(cols, idxs)\n",
    "    vals = tf.gather(vals, idxs)\n",
    "    \n",
    "    return vals, rows, cols, idxs\n",
    "\n",
    "def random_mask():\n",
    "    idxs = tf.range(784)\n",
    "    idxs = tf.random.shuffle(idxs)\n",
    "    n = tf.random.uniform(shape=[], maxval=784, dtype=tf.int32)\n",
    "    idxs = idxs[:n]\n",
    "    mask = idxs_to_multihot(idxs)\n",
    "    return mask\n",
    "\n",
    "def random_square_mask(maxsize=28):\n",
    "    height = tf.random.uniform(shape=[], minval=1, maxval=maxsize, dtype=tf.int32)\n",
    "    width = tf.random.uniform(shape=[], minval=1, maxval=maxsize, dtype=tf.int32)\n",
    "    start_row = tf.random.uniform(shape=[], minval=0, maxval=maxsize-height, dtype=tf.int32)\n",
    "    start_col = tf.random.uniform(shape=[], minval=0, maxval=maxsize-width, dtype=tf.int32)\n",
    "    rows = tf.range(start_row, start_row + height)\n",
    "    cols = tf.range(start_col, start_col + width)\n",
    "    cols, rows = tf.meshgrid(rows, cols)\n",
    "    idxs = rows*maxsize+cols\n",
    "    idxs = tf.reshape(idxs, [-1])\n",
    "    return idxs_to_multihot(idxs, depth=maxsize*maxsize)\n",
    "\n",
    "def random_offset():\n",
    "    return tf.random.uniform(shape=[2], maxval=28, dtype=tf.int32)\n",
    "    \n",
    "def display_mask(mask):\n",
    "    image_mask = np.array(mask_to_image_mask(mask), np.uint8)\n",
    "    image_mask = image_mask * 255\n",
    "    display_uint8_image(image_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "positions = tf.range(-28, 28, dtype=tf.float32)\n",
    "encodings = positional_encoding(positions, 16, scale=28)\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "im = ax.imshow(encodings)\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow.data data generator\n",
    "\n",
    "from tensorflow import data as td\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "def make_dataset_generator(x, y, seed, options={'single pixel', '256 color'}):\n",
    "\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    \n",
    "    # keep track of the index in the original MNIST\n",
    "    def to_dict(i, xy):\n",
    "        image, label = xy\n",
    "        data = {}\n",
    "        data['index'] = i\n",
    "        data['image'] = image\n",
    "        data['label'] = label\n",
    "        return data\n",
    "    dataset = dataset.enumerate()\n",
    "    dataset = dataset.map(to_dict)\n",
    "    \n",
    "    # shuffle the digits\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    # repeat the dataset infinitely\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    def to_binary_mnist(data):\n",
    "        data['image'] = tf.cast(tf.round(data['image'] / 255), tf.float32)\n",
    "        return data\n",
    "    if '2 color' in options:\n",
    "        dataset = dataset.map(to_binary_mnist)\n",
    "    \n",
    "    # add a transformation of MNIST images into val, row, col\n",
    "    def add_tuples(data):\n",
    "        data['val'], data['row'], data['col'], data['idxs'] = img_to_tuples(data['image'])\n",
    "        return data\n",
    "    dataset = dataset.map(add_tuples)\n",
    "    \n",
    "    # create a mask of random pixels masked out\n",
    "    def add_mask(data):\n",
    "        data['mask'] = random_mask()\n",
    "        return data\n",
    "    dataset = dataset.map(add_mask)\n",
    "    \n",
    "    # mask out a square region as well as random pixels\n",
    "    def add_square_mask(data):\n",
    "        mask = data['mask']\n",
    "        square_mask = random_square_mask()\n",
    "        data['mask'] = tf.logical_and(mask, square_mask)\n",
    "        return data\n",
    "    dataset = dataset.map(add_square_mask)\n",
    "    \n",
    "    def shuffle_mask(data):\n",
    "        data['mask'] = tf.gather(data['mask'], data['idxs'])\n",
    "        return data\n",
    "    dataset = dataset.map(shuffle_mask)\n",
    "    \n",
    "    # generate training pairs\n",
    "    \n",
    "    def single_pixel(data):\n",
    "        data['target_val'] = tf.cast(data['image'][data['target_row'], data['target_col']], tf.float32)\n",
    "        \n",
    "        mask_out_target_pixel = True\n",
    "        if mask_out_target_pixel:\n",
    "            target_idx = data['target_row'] * 28 + data['target_col']\n",
    "            target_mask = idxs_to_onehots(target_idx)\n",
    "            data['mask'] = tf.logical_and(data['mask'], target_mask)\n",
    "        \n",
    "        # offset positions relative to target pixel so target is at 0,0\n",
    "        data['row'] = data['row'] - tf.cast(data['target_row'], tf.float32)\n",
    "        data['col'] = data['col'] - tf.cast(data['target_col'], tf.float32)\n",
    "        \n",
    "        return (data, data['target_val'])\n",
    "    \n",
    "    def single_pixel_random_rowcol(data):\n",
    "        data['target_row']  = tf.random.uniform([], minval=0, maxval=28, dtype=tf.int32)\n",
    "        data['target_col']  = tf.random.uniform([], minval=0, maxval=28, dtype=tf.int32)\n",
    "        \n",
    "        return single_pixel(data)\n",
    "        \n",
    "    def many_single_pixels(data):\n",
    "        rows = tf.range(28)\n",
    "        cols = tf.range(28)\n",
    "        cols, rows = tf.meshgrid(rows, cols)\n",
    "        \n",
    "        rows = tf.reshape(rows, [-1])\n",
    "        cols = tf.reshape(cols, [-1])\n",
    "        \n",
    "        image = data['image']\n",
    "        val = data['val']\n",
    "        row = data['row']\n",
    "        col = data['col']\n",
    "        mask = data['mask']\n",
    "        label = data['label']\n",
    "        index = data['index']\n",
    "        \n",
    "        def data_plus_pixel_index(i):\n",
    "            new_datum = {}\n",
    "            new_datum['pix_index'] = i\n",
    "            new_datum['target_row'] = rows[i]\n",
    "            new_datum['target_col'] = cols[i]\n",
    "            return new_datum\n",
    "        \n",
    "        def add_original(new_datum):\n",
    "            \n",
    "            new_datum['index'] = index\n",
    "            new_datum['val'] = val\n",
    "            new_datum['row'] = row\n",
    "            new_datum['col'] = col\n",
    "            new_datum['image'] = image\n",
    "            new_datum['mask'] = mask\n",
    "            new_datum['label'] = label\n",
    "            \n",
    "            return new_datum\n",
    "        \n",
    "        d = tf.data.Dataset.range(784)\n",
    "        d = d.map(data_plus_pixel_index)\n",
    "        d = d.map(add_original)\n",
    "        d = d.map(single_pixel)\n",
    "        \n",
    "        return d\n",
    "    \n",
    "    def whole_image(data):\n",
    "        return data, data['val']\n",
    "    \n",
    "    # single pixel example. the row & col are translated by a random\n",
    "    # amount and the target val is the new pixel at 0,0\n",
    "    if 'single pixel' in options:\n",
    "        dataset = dataset.map(single_pixel_random_rowcol)\n",
    "    \n",
    "    # 'many single pixels' generates 784 single pixels from each image,\n",
    "    # and the target vals are each pixel in turn, translated so that\n",
    "    # they are at 0,0\n",
    "    elif 'many single pixels' in options:\n",
    "        dataset = dataset.interleave(many_single_pixels, block_length=784)\n",
    "    \n",
    "    elif 'whole image' in options:\n",
    "        dataset = dataset.map(whole_image)\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "def make_datasets(options):\n",
    "\n",
    "    train = make_dataset_generator(x_train, y_train, seed=192_168_1_1, options=options)\n",
    "    test = make_dataset_generator(x_test, y_test, seed=10_1_1_1, options=options)\n",
    "    \n",
    "    return train, iter(test)\n",
    "options={'whole image', '256 color'}\n",
    "dataset_train, dataset_test = make_datasets(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def shape_summary(data):\n",
    "    for name, v in data.items():\n",
    "        print(name, \"shape\", v.shape)\n",
    "        print(name, \"dtype\", v.dtype)\n",
    "\n",
    "def el_summary(data, outputs=None):\n",
    "    print(\"index\", data[\"index\"].numpy(), \"which is a\", data[\"label\"].numpy())\n",
    "    if 'pix_index' in data:\n",
    "        print(\"pix_idx:\", data[\"pix_index\"].numpy())\n",
    "\n",
    "    image = np.zeros([28, 28])\n",
    "    image[data['row'], data['col']] = data['val']\n",
    "    mask = np.zeros([28, 28], dtype=np.bool_)\n",
    "    mask[data['row'], data['col']] = data['mask']\n",
    "    \n",
    "    if outputs is not None:\n",
    "        output_image = np.zeros([28, 28])\n",
    "        output_image[data['row'], data['col']] = np.reshape(outputs, [784])\n",
    "        outputs = output_image\n",
    "        \n",
    "    if '2 color' in options:\n",
    "        if outputs is not None:\n",
    "            outputs = outputs * 255.\n",
    "        image = image * 255.\n",
    "        \n",
    "    display_float32_image(image)\n",
    "    display_float32_image(tf.cast(mask, tf.float32) * 255)\n",
    "    display_float32_image(image * tf.cast(mask, tf.float32))\n",
    "    \n",
    "    if outputs is not None:\n",
    "        print('input sum', np.sum(data['val']))\n",
    "        print('output sum', np.sum(outputs))\n",
    "        display_float32_image(outputs)\n",
    "\n",
    "def train_summary(d):\n",
    "    data, target = next(iter(d))\n",
    "    shape_summary(data)\n",
    "    el_summary(data)\n",
    "    data, target = next(iter(d))\n",
    "    el_summary(data)\n",
    "\n",
    "def test_summary(d):\n",
    "    data, target = next(d)\n",
    "    shape_summary(data)\n",
    "    el_summary(data)\n",
    "    data, target = next(d)\n",
    "    el_summary(data)\n",
    "    for i in range(780):\n",
    "        next(d)\n",
    "    data, target = next(d)\n",
    "    el_summary(data)\n",
    "    data, target = next(d)\n",
    "    el_summary(data)\n",
    "    data, target = next(d)\n",
    "    el_summary(data)\n",
    "    data, target = next(d)\n",
    "    el_summary(data)\n",
    "\n",
    "train_summary(dataset_train)\n",
    "\n",
    "\n",
    "# TODO: TEST DATASET GENERATOR DOES NOT WORK HOW I EXPECT.\n",
    "#       IT SHOULD PRODUCE 784 EXAMPLES with the SAME image and mask, then change\n",
    "#       to a different image and mask.\n",
    "\n",
    "test_summary(dataset_test)\n",
    "\n",
    "# reset datasets after summary, because it consumes elements\n",
    "dataset_train, dataset_test = make_datasets(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_options = options\n",
    "options = {'whole image', '2 color'}\n",
    "binary1, binary2 = make_datasets(options)\n",
    "\n",
    "train_summary(binary1)\n",
    "options = old_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Maths\n",
    "\n",
    "Dimensions $N$, $D$, $E$ and $B$.\n",
    "\n",
    "- $N = 784$ is the number of inputs.\n",
    "- $D$ is the width of the _key_ $K$ and _query_ $Q$ vectors.\n",
    "- $E$ is the width of the _value_ vectors $V$.\n",
    "- There is also a (or multiple) batch dimension(s) $B$.\n",
    "\n",
    "$K$ is $B \\times N \\times D$ dimensional.\n",
    "$Q$ is $B \\times N \\times D$ dimensional.\n",
    "$V$ is $B \\times N \\times E$ dimensional.\n",
    "Because it is self-attention, $K$ and $Q$ have the same length $N$, and the attention matrix is square.\n",
    "The attention matrix is $A = Q \\cdot K^T$, and is $B \\times N \\times N$ dimensional. Formally:\n",
    "$$\n",
    "A_{b,i,j} = \\sum_d Q_{b,i,d} K_{b,j,d}\n",
    "$$\n",
    "\n",
    "We do softmax normalization along the columns $j$ of the attention matrix (such that each _row_ $i$ sums to 1). The result is the attention weights. Formally:\n",
    "$$\n",
    "\\bar{A}_{b,i,j} = \\frac{e^{A_{b,i,j}}}{\\sum_{j'} e^{A_{b,i,j'}}}\n",
    "$$\n",
    "\n",
    "The output $O$ of the attention layer is $B \\times N \\times E$ dimensional. It is obtained by the attention weights multiplied by the value vectors $V$. $A$ is $B \\times N \\times N$ dimensional and $V$ is $B \\times N \\times E$ dimensional.\n",
    "$$\n",
    "    O_{b,i,e} = \\sum_j A_{b,i,j} V_{b,j,e}\n",
    "$$\n",
    "\n",
    "Often the dimensions $E = D$ because this allows multiple attention layers in sequence, but this need not be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5noipvB9oe8v"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def multi_head_attention(n_heads, n_kq_dim, n_val_dim):\n",
    "    \n",
    "    k_dense = layers.Dense(n_kq_dim, activation='linear')\n",
    "    q_dense = layers.Dense(n_kq_dim, activation='linear')\n",
    "    \n",
    "    \n",
    "    \n",
    "    softmax = layers.Softmax(axis=-1)\n",
    "    \n",
    "    val_dense = layers.Dense(n_val_dim, activation='relu')\n",
    "    \n",
    "    def call(inputs, mask):\n",
    "        \n",
    "        k = k_dense(inputs)\n",
    "        q = q_dense(inputs)\n",
    "        \n",
    "        scores = tf.matmul(query, key, transpose_b=True)\n",
    "        weights = softmax(scores, mask)\n",
    "        \n",
    "        vals = val_dense(inputs)\n",
    "        \n",
    "        vals = tf.expand_dims(-1)\n",
    "        weights = tf.expand_dims(-2)\n",
    "        \n",
    "        outputs = tf.reduce_sum(vals * weights)\n",
    "        \n",
    "        \n",
    "        vals *= mask\n",
    "        \n",
    "\n",
    "def transformer_block(n_embed_dim, n_heads, n_dense_dim, dropout_rate, output_shape=None):\n",
    "    \n",
    "    attn = layers.MultiHeadAttention(num_heads=n_heads, key_dim=n_embed_dim, output_shape=output_shape)\n",
    "    dense_net_1 = layers.Dense(n_dense_dim, activation='relu')\n",
    "    dense_net_2 = layers.Dense(n_embed_dim if output_shape is None else output_shape)\n",
    "    layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "    layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "    if dropout_rate is not None:\n",
    "        dropout1 = layers.Dropout(dropout_rate)\n",
    "        dropout2 = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(inputs, masks, include_residual, separate_query=None):\n",
    "        mask = tf.logical_and(masks[:, :, None], masks[:, None, :])\n",
    "        if separate_query is not None:\n",
    "            m = attn(inputs, separate_query, attention_mask=mask)\n",
    "        else:\n",
    "            m = attn(inputs, inputs, attention_mask=mask)\n",
    "        if dropout_rate is not None:\n",
    "            m = dropout1(m)\n",
    "        attn_output = m\n",
    "        if include_residual:\n",
    "            m = inputs + m\n",
    "#         # mask outputs. important! without, model learns magic powers (can detect and use verrrrrrry small numbers which are not literally 0)\n",
    "#         m = m * tf.expand_dims(tf.cast(masks, tf.float32), -1)\n",
    "        m = layernorm1(m)\n",
    "        m = dense_net_1(m)\n",
    "        m = dense_net_2(m)\n",
    "        if dropout_rate is not None:\n",
    "            m = dropout2(m)\n",
    "        dense_output = m\n",
    "        return layernorm2(attn_output + dense_output)\n",
    "    \n",
    "    return call\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[[1,2],[3,4]]])\n",
    "print(tf.tile(x, multiples=[3, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Xi5wBCwEVHp"
   },
   "outputs": [],
   "source": [
    "def model(batch_size):\n",
    "\n",
    "    n_embd = 32\n",
    "    pointwise_feedforward_dim = 128\n",
    "\n",
    "    val = keras.Input(shape=[784], name='val', batch_size=batch_size)\n",
    "    row = keras.Input(shape=[784], name='row', batch_size=batch_size)\n",
    "    col = keras.Input(shape=[784], name='col', batch_size=batch_size)\n",
    "    mask = keras.Input(shape=[784], name='mask', batch_size=batch_size, dtype=tf.bool)\n",
    "    \n",
    "    print(val.shape)\n",
    "    print(row.shape)\n",
    "    print(col.shape)\n",
    "    print(mask.shape)\n",
    "    \n",
    "    row_pos_enc = positional_encoding(row, n_embd//2)\n",
    "    col_pos_enc = positional_encoding(col, n_embd//2)\n",
    "    \n",
    "    print(row_pos_enc.shape)\n",
    "    print(col_pos_enc.shape)\n",
    "    \n",
    "    pos_enc = tf.concat([row_pos_enc, col_pos_enc], axis=-1)\n",
    "    print(pos_enc.shape)\n",
    "    \n",
    "    # produce images of the attention/relevance/contribution for each output.\n",
    "\n",
    "    # make it smaller\n",
    "    # - less heads\n",
    "    # - less dense layers\n",
    "    # - smaller layer sizes'\n",
    "    \n",
    "    # look at standard transformer structure again.\n",
    "    # what is the expected training time?\n",
    "    \n",
    "    # simple setup -> build up.\n",
    "    \n",
    "    # literature / other task at the same time\n",
    "    # have enough to get help from supervisors in discussion\n",
    "    # start writing\n",
    "    \n",
    "    # make n_embd-dimensional input embeddings per pixel from [x, y, v]\n",
    "    # embedding\n",
    "    \n",
    "    m = tf.expand_dims(val, -1)\n",
    "#     m = tf.stack([val, row, col], axis=-1)\n",
    "\n",
    "    m = layers.Dense(pointwise_feedforward_dim, activation='relu')(m)\n",
    "    m = layers.Dense(n_embd, activation=None)(m)\n",
    "    \n",
    "#     print(m.shape)\n",
    "\n",
    "#     rows_unshuffled = tf.range(28, dtype=tf.float32)\n",
    "#     cols_unshuffled = tf.range(28, dtype=tf.float32)\n",
    "#     cols_unshuffled, rows_unshuffled = tf.meshgrid(rows_unshuffled, cols_unshuffled)\n",
    "#     rows_unshuffled = tf.reshape(rows_unshuffled, [-1])\n",
    "#     cols_unshuffled = tf.reshape(cols_unshuffled, [-1])\n",
    "    \n",
    "#     row_unsh_pos_enc = positional_encoding(rows_unshuffled, n_embd//2)\n",
    "#     col_unsh_pos_enc = positional_encoding(cols_unshuffled, n_embd//2)\n",
    "    \n",
    "#     unsh_pos_enc = tf.concat([row_unsh_pos_enc, col_unsh_pos_enc], axis=-1)\n",
    "#     unsh_pos_enc = tf.expand_dims(unsh_pos_enc, axis=0)\n",
    "#     unsh_pos_enc = tf.tile(unsh_pos_enc, multiples=[tf.shape(val)[0], 1, 1])\n",
    "    \n",
    "    m *= tf.expand_dims(tf.cast(mask, tf.float32), axis=-1)\n",
    "    \n",
    "    m += pos_enc\n",
    "    \n",
    "    m = transformer_block(n_embed_dim=n_embd, n_heads=8, n_dense_dim=pointwise_feedforward_dim, dropout_rate=0.1)(m, masks=mask, include_residual=True)\n",
    "    m = transformer_block(n_embed_dim=n_embd, n_heads=8, n_dense_dim=pointwise_feedforward_dim, dropout_rate=0.1)(m, masks=mask, include_residual=True)\n",
    "    m = transformer_block(n_embed_dim=n_embd, n_heads=8, n_dense_dim=pointwise_feedforward_dim, dropout_rate=0.1)(m, masks=mask, include_residual=True)\n",
    "    m = transformer_block(n_embed_dim=n_embd, n_heads=8, n_dense_dim=pointwise_feedforward_dim, dropout_rate=0.1)(m, masks=mask, include_residual=True)\n",
    "#     m = transformer_block(n_embed_dim=n_embd, output_shape=1, n_heads=1, n_dense_dim=pointwise_feedforward_dim, dropout_rate=None)(m, masks=mask, include_residual=True)\n",
    "#     m = transformer_block(n_embed_dim=n_embd, n_heads=8, n_dense_dim=pointwise_feedforward_dim, dropout_rate=None)(m, masks=mask, include_residual=True)\n",
    "#     m = transformer_block(n_embed_dim=n_embd, n_heads=8, n_dense_dim=pointwise_feedforward_dim, dropout_rate=0.1)(m, masks=mask, include_residual=True)\n",
    "#     m = transformer_block(n_embed_dim=n_embd, n_heads=8, n_dense_dim=pointwise_feedforward_dim, dropout_rate=0.1)(m, masks=mask, include_residual=True)\n",
    "#     m = transformer_block(n_embed_dim=1, n_heads=8, n_dense_dim=pointwise_feedforward_dim, dropout_rate=0.1)(m, masks=mask, include_residual=True)\n",
    "    \n",
    "#     m = layers.Dense(784, activation='relu')(m)\n",
    "    m = layers.Dense(1, activation=None)(m)\n",
    "    \n",
    "    target_val = layers.Reshape([784], name='target_val')(m)\n",
    "    \n",
    "    model = keras.Model(inputs=[val, row, col, mask], outputs=[target_val], name=model_name)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rOqsXnxifpG",
    "outputId": "e1fee0a6-197b-4ca4-92a0-1d23c1906133"
   },
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.003)\n",
    "lr_metric = get_lr_metric(optimizer)\n",
    "\n",
    "txformer = model(batch_size)\n",
    "txformer.compile(optimizer=optimizer, loss=keras.losses.MeanSquaredError())\n",
    "\n",
    "load_saved_model = False\n",
    "if load_saved_model:\n",
    "    txformer.load_weights(f\"./models/{model_name}\")\n",
    "\n",
    "txformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "fzuSaIstGU0A",
    "outputId": "765dc0e1-e241-4363-8f90-c06fe21ea4e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# display:\n",
    "# - before mask\n",
    "# - mask\n",
    "# - after mask\n",
    "# - prediction\n",
    "def gen_image(dataset):\n",
    "    \n",
    "    data, targ = next(dataset)\n",
    "    \n",
    "    inputs = [data['val'], data['row'], data['col'], data['mask']]\n",
    "    inputs = [tf.expand_dims(x, 0) for x in inputs]\n",
    "\n",
    "    outputs = tf.clip_by_value(txformer(inputs), 0, 255)\n",
    "    \n",
    "    el_summary(data, outputs)\n",
    "\n",
    "def gen_image_many_pixels(dataset):\n",
    "    \n",
    "    # assume dataset is a 'many single pixel dataset'\n",
    "    # so it has runs of 784 examples, one for each pixel in an mnist digit\n",
    "#     dataset = dataset.take(784)\n",
    "#     batch_size = 32\n",
    "#     dataset = dataset.batch(batch_size)\n",
    "#     reconstructed_image = np.zeros([28, 28])\n",
    "#     for batch, batch_targ in dataset:\n",
    "#         inputs = [batch['val'], batch['row'], batch['col'], batch['mask']]\n",
    "#         out_vals = txformer(inputs)\n",
    "        \n",
    "#         # np can do this yay\n",
    "#         reconstructed_image[batch['target_row'], batch['target_col']] = out_vals\n",
    "\n",
    "    reconstructed_image = np.ones([28, 28]) * 230\n",
    "    for row in range(28):\n",
    "        for col in range(28):\n",
    "            data, targ = next(dataset)\n",
    "            inputs = [data['val'], data['row'], data['col'], data['mask']]\n",
    "            inputs = [tf.expand_dims(x, 0) for x in inputs]\n",
    "            \n",
    "            out_vals = txformer(inputs)\n",
    "            reconstructed_image[data['target_row'], data['target_col']] = out_vals\n",
    "    \n",
    "    reconstructed_image = np.clip(reconstructed_image, 0, 255)\n",
    "    image = data['image']\n",
    "    mask = data['mask']\n",
    "    \n",
    "    if '2 color' in options:\n",
    "        outputs = outputs * 255.\n",
    "        image = image  * 255.\n",
    "    \n",
    "    print(\"index\", data[\"index\"], \"which is a\", data[\"label\"])\n",
    "    display_float32_image(image)\n",
    "    display_mask(mask)\n",
    "    display_float32_image(tf.reshape(image, [28, 28]) * tf.cast(mask_to_image_mask(mask), tf.float32))\n",
    "    display_float32_image(reconstructed_image)\n",
    "        \n",
    "        \n",
    "def image_performance_test(n=5):\n",
    "    for i in range(n):\n",
    "        gen_image(dataset_test)\n",
    "\n",
    "def fit_one_epoch(dataset):\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(10000)\n",
    "    \n",
    "    global callbacks\n",
    "    callbacks += []\n",
    "    \n",
    "    txformer.fit(dataset, epochs=1, steps_per_epoch=5000, batch_size=batch_size, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_performance_test(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "Qc-55LXO8Dtl",
    "outputId": "47b797e1-67ca-440b-c252-7e961a14c6ee"
   },
   "outputs": [],
   "source": [
    "fit_one_epoch(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_performance_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Po6NnXshwaCj"
   },
   "outputs": [],
   "source": [
    "fit_one_epoch(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_performance_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhSfq8VcPOEW"
   },
   "outputs": [],
   "source": [
    "fit_one_epoch(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DD2oRg5MMrmK"
   },
   "outputs": [],
   "source": [
    "image_performance_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNhU_P0QPWPt"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not load_saved_model:\n",
    "    txformer.save_weights(f\"./models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_performance_test(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_performance_test(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not load_saved_model:\n",
    "    txformer.save_weights(f\"./models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)\n",
    "image_performance_test(n=20)\n",
    "if not load_saved_model:\n",
    "    txformer.save_weights(f\"./models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)\n",
    "image_performance_test(n=20)\n",
    "if not load_saved_model:\n",
    "    txformer.save_weights(f\"./models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST conditional prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
