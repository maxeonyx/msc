{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx9vGgfSkcpL"
   },
   "source": [
    "\n",
    "# Conditional autoregressive transformer\n",
    "\n",
    "Train a transformer to predict missing pixel from mnist \n",
    "\n",
    "### plan\n",
    "\n",
    "* note to try padded mnist (relative encoding might require black padding???)\n",
    "* probably don't need positional encoding?\n",
    "* create transformer model\n",
    "* masking \n",
    "* randomised masking\n",
    "* relative position encoding (x - current_x, y - current_y, val)\n",
    "* train to predict when current pixel missing\n",
    "* train to predict when 10% are missing\n",
    "* train to predict when 90% are missing\n",
    "* train to predict when 99% are missing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QOGwXO1EUsAz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def display_uint8_image(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = image[:, :, 0]\n",
    "    if tf.is_tensor(image):\n",
    "        image = image.numpy()\n",
    "    display(Image.fromarray(image, \"L\"))\n",
    "\n",
    "def display_float32_image(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = image[:, :, 0]\n",
    "    if tf.is_tensor(image):\n",
    "        image = image.numpy()\n",
    "    display_uint8_image(image.astype(np.uint8))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 7, 8, 0, 2, 5, 1, 6, 9, 4],\n",
       "       [3, 7, 8, 0, 2, 5, 1, 6, 9, 4],\n",
       "       [3, 7, 8, 0, 2, 5, 1, 6, 9, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = np.indices([3, 10])\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "rng.permutation(idxs[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qr9uxXbhzo9g",
    "outputId": "158a591e-46a3-4307-e49a-12b0052586f3"
   },
   "outputs": [],
   "source": [
    "# reformat MNIST data into (x, y, val) tuples\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(\n",
    "    path='mnist.npz'\n",
    ")\n",
    "\n",
    "def idxs_to_onehots(idxs):\n",
    "    onehots = tf.one_hot(idxs, depth=784, dtype=tf.bool, on_value=False, off_value=True)\n",
    "    return onehots\n",
    "\n",
    "# takes 2D tensor (batch and index list)\n",
    "def idxs_to_multihot(idxs):\n",
    "    onehots = idxs_to_onehots(idxs)\n",
    "    multihot = tf.math.reduce_all(onehots, axis=len(onehots.shape)-2)\n",
    "    return multihot\n",
    "\n",
    "def idxs_to_attention_mask(idxs):\n",
    "    multihot = idxs_to_multihot(idxs)\n",
    "    attn_mask = tf.logical_and(multihot[:, :, None], multihot[:, None, :])\n",
    "    return attn_mask\n",
    "\n",
    "def mask_to_image_mask(masks):\n",
    "    image_masks = tf.reshape(masks, [-1, 28, 28])\n",
    "    return image_masks\n",
    "\n",
    "def display_mask(mask):\n",
    "    image_mask = np.array(mask_to_image_mask(mask[np.newaxis, :]), np.uint8)[0]\n",
    "    image_mask = image_mask * 255\n",
    "    display_uint8_image(image_mask)\n",
    "\n",
    "# [row, col, value] tuples\n",
    "def mnist_to_rcv_tuples(dataset):\n",
    "    # positional encoding is just indices as floats\n",
    "    x_idx = np.arange(dataset.shape[1]).astype(np.float32)\n",
    "    y_idx = np.arange(dataset.shape[2]).astype(np.float32)\n",
    "\n",
    "    # make 28x28 cartesian product and repeat N times\n",
    "    idxs = np.transpose([np.repeat(y_idx, len(x_idx)),np.tile(x_idx, len(y_idx))])\n",
    "    \n",
    "    all_idxs = np.tile(idxs.reshape(-1), dataset.shape[0]).reshape(-1,784,2)\n",
    "    # pixel data as float between 0 and 255\n",
    "    all = dataset.astype(np.float32).reshape(-1, 784, 1)\n",
    "    \n",
    "    big = np.dstack((all_idxs, all))\n",
    "    \n",
    "    return big\n",
    "\n",
    "def random_offset_tuples(dataset, min_masked_px=0, max_masked_px=784, random_squares=True):\n",
    "    tuples = mnist_to_rcv_tuples(dataset)\n",
    "    offsets = np.random.randint(0, 28, [dataset.shape[0], 2])\n",
    "    mask_sizes = np.random.randint(min_masked_px, max_masked_px, [dataset.shape[0]])\n",
    "    tuples[:, :, 0] -= offsets[:, 0, np.newaxis] # row (y) offset\n",
    "    tuples[:, :, 1] -= offsets[:, 1, np.newaxis] # col (x) offset\n",
    "    target_idxs = offsets[:, 0] * 28 + offsets[:, 1]\n",
    "    \n",
    "    # permutations \n",
    "    masks = np.ones([dataset.shape[0], 784], dtype=np.bool_)\n",
    "    for i in range(dataset.shape[0]):\n",
    "        # shuffle tuples\n",
    "        tup_shuffle_idxs = np.random.permutation(784)\n",
    "        tuples[i] = tuples[i, tup_shuffle_idxs]\n",
    "        \n",
    "        idxs = np.random.permutation(784)\n",
    "                           \n",
    "        n_mask_px = np.random.randint(min_masked_px, max_masked_px)\n",
    "        # n mask plus always mask the target idx\n",
    "        mask_idxs = np.concatenate([idxs[:n_mask_px], target_idxs[i:i+1]])\n",
    "        \n",
    "        if random_squares:\n",
    "            # random square cut out of the masks\n",
    "            start_row, start_col = np.random.randint(0, 28, [2])\n",
    "            end_row = np.random.randint(start_row, 28)\n",
    "            end_col = np.random.randint(start_col, 28)\n",
    "            height, width = abs(end_row - start_row), abs(end_col - start_col)\n",
    "            square_row_idxs, square_col_idxs = np.indices([height, width])\n",
    "            square_row_idxs += start_row\n",
    "            square_col_idxs += start_col\n",
    "            square_mask_idxs = square_row_idxs * 28 + square_col_idxs\n",
    "            square_mask_idxs = square_mask_idxs.reshape(-1)\n",
    "            \n",
    "            mask_idxs = np.concatenate([mask_idxs, square_mask_idxs])\n",
    "            \n",
    "        masks[i:i+1] = idxs_to_multihot(mask_idxs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    target_pxs = dataset[np.arange(dataset.shape[0]), offsets[:, 0], offsets[:, 1]].astype(np.float32)\n",
    "    return {\n",
    "        \"imgs\": tf.cast(dataset, tf.uint8),\n",
    "        \"tuples\": tf.cast(tuples, tf.float32),\n",
    "        \"offsets\": offsets,\n",
    "        \"target_pxs\": target_pxs,\n",
    "        \"target_idxs\": target_idxs,\n",
    "        \"masks\": tf.cast(masks, tf.bool)\n",
    "    }\n",
    "\n",
    "dataset = random_offset_tuples(x_train)\n",
    "test_dataset = random_offset_tuples(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs shape (10000, 28, 28)\n",
      "tuples shape (10000, 784, 3)\n",
      "offsets shape (10000, 2)\n",
      "target_pxs shape (10000,)\n",
      "target_idxs shape (10000,)\n",
      "masks shape (10000, 784)\n",
      "index 0 which is a 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVR4nGNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kJuHrgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72D408DEB0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F73CC3DBEE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F2995B80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1 which is a 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4nGNgoAlgRDBLOPVCGKYfX4xN2cq/f//+/fv3lhwOuat9G/7+rcKUM/n195ICDwPbub89mJK+vy9JMjAwVP3464jFWHkhBgYGhot/sUoyMDAwMJR+/3uMC4ecz/e/z+2R+EwormJjWHkQh8YN3/7O58EhJ/nq70tlXK459vdvLy45vx9/9+IyVPgEHo1tf/+uxaWR4cffv5LoYixIbKHfDAwMH3+z8jMIFjIw/C3/hix5iYGBgWH1c/FwCPdFKzwlrPNHqPrzj2HTGYYjxxHJpIyVgUE7nIFh3gOGdddxuWyAAQCfcVM+FkfDOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F73CC3907C0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F73CC3DBEE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E8129E80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2 which is a 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiElEQVR4nGNgGARA7V8unM2ELmn47ylune0fccvpfpmG4KAbq861ErfOU/e5ccop/LuBxEMz1p7hNW5JXYYunKZavj3LgVOns9CNHzgl9f+vwWmqxIvrKHwUnQliJ3BLyjO8x2kqw5N/Tjh12orj1sfQ++8sMy6dXF4Ma/7i0sh6bAMXHnPpBAAPgx/ARH1j7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E8083CA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F73CC3DBEE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F2995B80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 3 which is a 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA70lEQVR4nMXQsWoCQRQF0JvBNNrGdjcgIR8gJJVrqRZCfkMkgn+QlEIIAcHaHzClVWySJkmXSgxqIbKCbcrLxRSbNe7M2uqr7syZefAecOTK9fTp78MLUs2ds9nJ+b71OPMfWzdXAALz9ZrSVCQpclp0bbiRpPVckmPlmUh268Ed2bDsfEVx2skCfsif9qkzxcsZAOCWYsHGDy+K/nuM2zmNuV5E6cQYc5/4+UDG0W07iTFfXlGhl45PJGelKGeQrOElgPFb8vJbqtWW0kYpG2qT8W7ZtdEP/zAcFbI2IniMsOkIAKD6zEGl6qXjweoXXfV/5XmKZEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E8083DC0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F2995B80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4AB8C70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 4 which is a 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2klEQVR4nGNgGLzA6AGU4SYLZTAhJN3ZoQy/bgxJFi8Y64wWN7qko+V8KEtIiwvNRt03N3mgzAN/RNEkV3w3hWn8/xdNMuTTZRiz9+9eVlTJlX+yoCyFF7+cUOX4H/6BMdv+wM2AupZdegVMRJnhCppzOM9cFIKwxP7+zYaJskCo73eDt/YxMDDoKMv/Z/iPppNBc9XXP3/+/Hnx/PefP5wwQUa4tKEyAwPDGoaF0TDTsID6P3900exEAEZGhss4Jf8jOYcJXZKD4QdOKxlevMnHLbnZCbcclQAA/k48Hcv/z+EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E8083BE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F73CC3DBEE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F73CC3DBEE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 5 which is a 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVR4nGNgGOzA9182My454cf//nHikgz8928pIw459tP//nni0mj6798vBI8JzVQGhl24NDIc+ffDAJec1b9/b5G4qMaaMjBMx2nq4n/vZHDJ2fz5dx+Zj2KsMBPDbnymmuKSk/nz7xKKALKxVkwMG3GamvnvlQhOnW4Mjz7ikmRVYfjxG5fkv9MMd1DtYUEw/9b8P4fTPdQEAJbDL46GK5NFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E80839D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F73CC376EE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E8083F10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 6 which is a 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA10lEQVR4nGNgGLRA7ECbAozN78uKIif4+tdKuNydj6rIciJ7/06Gc7r/pqBodPv7VxTG1v63lhfFwpl/E+Byz//FoGhc/P8MN4yd8W8eqlMX/d0EdR9n89u/MFEWGMN714fpDAwM9g4WDGtQNTIYP/n799/fv3///vv797Yyms6zugYepa8XMjAsvshw7C4DDqD075woLjmGBX9dccqF/vtohFNy3r+lOOUYnn/BrTHj3wvcGi/8ncvAKwfnMqFJ/43e34xT57+/s2RxSNruaxBnw20rlQAAKNJLfTqR0FsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F73CC3908E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E81FA400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4AB8C70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 7 which is a 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1klEQVR4nGNgGKqAb+pBVlxy0Q/+/hXGISfz+t/fv8uEsEtO+Pvv79+/74rZsMjJf/x7Yeffv3+fS2CR9P93kIEj6fa//ycRJjPBGOz/+xl+zLv9//+3X5iSkQzeDAwMJgwMJ75gGhv294JG6LLfb/+90cKUFHr399/fvztVbvydgcVFLh/+/5vIwdD2774yNtl5fTwMDJzr/y7EIgkFEX8f4QgmBgYGpmV/63BrNfj6Vw23bPG/NZw4JUVv/dPDrVXu31Lckgy7vmAJJhjgu++HRysRAAA+/lIBnbxrFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E8083F70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F2995B80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4AB8C70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 8 which is a 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4nGNgoD9gxBARlGNgeFh45dZFTMXeM2/+/fv3+re/f9FllPu+/PkLAwwMDCzIkjL5EPrGVQgNlxQpOLLj18ev3LuunDz//Suqidzn/voxMCgwyDFhuoNt498WLhwe4mn9+5IfhxxDzN/7MliEIVZYMZx/gksjw6u/3+oNMYUhwff/HwPDvxkn5O5cZdA+jm5G918EeLECTZLZ9Na93zDZPzWYFjh7nIDKrsfmrIq/P2cYL8EhafT37989f/7+nYJNknP5379///5az41NkkF8y/O/dxuwSjEwMDDEThXDKUcfAAAG83bQTLLiMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F73CC390370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E81FA400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E8129E80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 9 which is a 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABBElEQVR4nN3QsS8DcRjG8UcOPUFiINLNYGgj2M7QpTGISSIxWRkMFomIGESCwWJ1XTtYDP4Ag60xoqNBqjW0IWlPQ/Tc9wyWa/P7/QOe7c3nfYb3lf5N+rqm6fHVPH7pybA46zcA6JQvBntortCE6uVpeMdrZavbCg24OXel20zp8zmaSJB7GFE/Gpakx5klIInLH9Q8SXKmdisBcXFAkvr/0IkULqxl9JXNvk1K9ZMw0Ry6bkcxhAD8XKV77hzbz72/pOY9Sf5B0/iTIrQ2HCNprwPrZtJmAOWU2bwWBDlL8RjaeYuNfoNvsZEa3LsWXIlh0WJ6gDObqRrX01bcibetZsovhERycinB3ycAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E8083CA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F2995B80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F73CC3DBEE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, v in test_dataset.items():\n",
    "    print(name, \"shape\", v.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"index\", i, \"which is a\", y_test[i])\n",
    "    display_uint8_image(x_test[i])\n",
    "    display_mask(dataset[\"masks\"][i])\n",
    "    display_uint8_image(tf.constant(x_test[i]) * tf.cast(mask_to_image_mask(dataset[\"masks\"][np.newaxis, i])[0], tf.uint8))\n",
    "    \n",
    "# print(dataset[\"tuples\"][:10, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# f_masks = np.array([29, 31, 754, 752])\n",
    "# print(f_masks)\n",
    "# f_masks = idxs_to_multihot(f_masks)\n",
    "# print(f_masks)\n",
    "# display_mask(f_masks)\n",
    "\n",
    "# t_masks = np.indices([784])\n",
    "# print(t_masks)\n",
    "# t_masks = idxs_to_multihot(t_masks)\n",
    "# print(t_masks)\n",
    "# display_mask(t_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fNNZdCnizvLU",
    "outputId": "8472bdb9-66be-4f7a-8b8a-66ac282bb160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784, 3) (60000, 2) (60000,)\n",
      "tf.Tensor(\n",
      "[[-13. -17.   0.]\n",
      " [-13. -16.   0.]\n",
      " [-13. -15.   0.]\n",
      " ...\n",
      " [ 14.   8.   0.]\n",
      " [ 14.   9.   0.]\n",
      " [ 14.  10.   0.]], shape=(784, 3), dtype=float32)\n",
      "[13 17]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(dataset[\"tuples\"].shape, dataset[\"offsets\"].shape, dataset[\"target_pxs\"].shape)\n",
    "print(dataset[\"tuples\"][0])\n",
    "print(dataset[\"offsets\"][0])\n",
    "print(dataset[\"target_pxs\"][0])\n",
    "\n",
    "# actual training dataset is 784 x,y,v tuples, but with the spatial location changed so the the pixel to predict is in the center\n",
    "# and the pixel value to predict removed (via masking)\n",
    "\n",
    "# then, can mask more and more stuff and compare performance\n",
    "\n",
    "# we can also use the model in an \"iterative\" mode to generate images, in an arbitrary order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "W3nKMxnPe6cc"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "5noipvB9oe8v"
   },
   "outputs": [],
   "source": [
    "# example from keras docs https://keras.io/examples/nlp/text_classification_with_transformer/\n",
    "# uses built-in MultiHeadAttention https://keras.io/api/layers/attention_layers/multi_head_attention/\n",
    "\n",
    "# class TransformerBlock(layers.Layer):\n",
    "#     def __init__(self, n_embed_dim, n_heads, n_dense_dim, dropout_rate, **kwargs):\n",
    "#         super(TransformerBlock, self).__init__(**kwargs)\n",
    "#         self.att = layers.MultiHeadAttention(num_heads=n_heads, key_dim=n_embed_dim)\n",
    "#         self.dense_net = keras.Sequential([\n",
    "#             layers.Dense(n_dense_dim, activation='relu'),\n",
    "#             layers.Dense(n_embed_dim),\n",
    "#         ])\n",
    "#         self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "#         self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "#         self.dropout1 = layers.Dropout(dropout_rate)\n",
    "#         self.dropout2 = layers.Dropout(dropout_rate)\n",
    "    \n",
    "#     def call(self, inputs, masks, is_training):\n",
    "#         # make mask 2D\n",
    "#         mask = tf.logical_and(masks[:, :, None], masks[:, None, :])\n",
    "#         attn_output = self.att(inputs, inputs, attention_mask=mask)\n",
    "#         attn_output = self.dropout1(attn_output, training=is_training)\n",
    "#         out1 = self.layernorm1(inputs + attn_output)\n",
    "#         dense_output = self.dense_net(out1)\n",
    "#         dense_output = self.dropout2(dense_output, training=is_training)\n",
    "#         return self.layernorm2(out1 + dense_output)\n",
    "\n",
    "def transformer_block(n_embed_dim, n_heads, n_dense_dim, dropout_rate):\n",
    "    attn = layers.MultiHeadAttention(num_heads=n_heads, key_dim=n_embed_dim)\n",
    "    dense_net_1 = layers.Dense(n_dense_dim, activation='relu')\n",
    "    denst_net_2 = layers.Dense(n_embed_dim)\n",
    "    layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "    layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "    dropout1 = layers.Dropout(dropout_rate)\n",
    "    dropout2 = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(inputs, masks, include_residual, is_training):\n",
    "        mask = tf.logical_and(masks[:, :, None], masks[:, None, :])\n",
    "        attn_output = attn(inputs, inputs, attention_mask=mask)\n",
    "        attn_output = dropout1(attn_output, training=is_training)\n",
    "        if include_residual:\n",
    "            out1 = layernorm1(inputs + attn_output)\n",
    "        else:\n",
    "            out1 = layernorm1(attn_output)\n",
    "        dense_output = dense_net_1(out1)\n",
    "        dense_output = dense_net_2(dense_output)\n",
    "        dense_output = dropout2(dense_output, training=is_training)\n",
    "        return layernorm2(out1 + dense_output)\n",
    "    \n",
    "    return call\n",
    "    \n",
    "\n",
    "# class TokenAndPositionEmbedding(layers.Layer):\n",
    "#     def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "#         super(TokenAndPositionEmbedding, self).__init__()\n",
    "#         self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "#         self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "#     def call(self, x):\n",
    "#         maxlen = tf.shape(x)[-1]\n",
    "#         positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "#         positions = self.pos_emb(positions)\n",
    "#         x = self.token_emb(x)\n",
    "#         return x + positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfcvlCuCLUbM",
    "outputId": "d4d6f3de-eef7-4cb5-b6db-ae0ac89603ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.bool"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([True, False]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "-Xi5wBCwEVHp"
   },
   "outputs": [],
   "source": [
    "def model(batch_size):\n",
    "\n",
    "    # no batch size to start makes it simpler\n",
    "    n_embd = 10\n",
    "\n",
    "    data_input = keras.Input(shape=[784, 3], batch_size=None)\n",
    "    mask_input = keras.Input(shape=[784], batch_size=None, dtype=tf.bool)\n",
    "    m = data_input\n",
    "\n",
    "    # make n_embd-dimensional input embeddings per pixel from [x, y, v]\n",
    "    m = layers.Dense(20, activation='relu')(m)\n",
    "    m = layers.Dense(20, activation='relu')(m)\n",
    "    m = layers.Dense(n_embd, activation=None)(m)\n",
    "    m = transformer_block(n_embed_dim=n_embd, n_heads=7, n_dense_dim=16, dropout_rate=0.1)(m, masks=mask_input, include_residual=False, is_training=True)\n",
    "    m = transformer_block(n_embed_dim=n_embd, n_heads=7, n_dense_dim=16, dropout_rate=0.1)(m, masks=mask_input, is_training=True)\n",
    "    m = layers.Flatten()(m)\n",
    "    # m = layers.Dense(10, activation='relu')(m)\n",
    "    m = layers.Dense(1, activation=None)(m)\n",
    "\n",
    "    model = keras.Model(inputs=[data_input, mask_input], outputs=[m])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAoKvpfStPPH",
    "outputId": "9a668532-642d-4a64-8044-13ed1fb53daa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Wed_Jul_14_19:41:19_PDT_2021\n",
      "Cuda compilation tools, release 11.4, V11.4.100\n",
      "Build cuda_11.4.r11.4/compiler.30188945_0\n",
      "Fri Sep  3 17:55:14 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:26:00.0  On |                  N/A |\n",
      "|  0%   43C    P2    26W / 170W |   5094MiB /  5926MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       654      G   /usr/lib/Xorg                     246MiB |\n",
      "|    0   N/A  N/A       955      G   /usr/bin/gnome-shell               35MiB |\n",
      "|    0   N/A  N/A      1471      G   ...AAAAAAAAA= --shared-files        5MiB |\n",
      "|    0   N/A  N/A      1574      G   ...e/Steam/ubuntu12_32/steam        9MiB |\n",
      "|    0   N/A  N/A      1601      G   ./steamwebhelper                    2MiB |\n",
      "|    0   N/A  N/A      1616      G   ...oken=10886588545307636283       12MiB |\n",
      "|    0   N/A  N/A      2339      G   /usr/lib/firefox/firefox          367MiB |\n",
      "|    0   N/A  N/A      4011      G   /usr/lib/firefox/firefox            1MiB |\n",
      "|    0   N/A  N/A      9039      C   ...onal-mnist/env/bin/python     4405MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rOqsXnxifpG",
    "outputId": "e1fee0a6-197b-4ca4-92a0-1d23c1906133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 784, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 784, 20)      80          input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 784, 20)      420         dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_6 (Sli (None, 784, 1)       0           input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_7 (Sli (None, 1, 784)       0           input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 784, 10)      210         dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.logical_and_3 (TFOpLamb (None, 784, 784)     0           tf.__operators__.getitem_6[0][0] \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_16 (MultiH (None, 784, 10)      3020        dense_68[0][0]                   \n",
      "                                                                 dense_68[0][0]                   \n",
      "                                                                 tf.math.logical_and_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 784, 10)      0           multi_head_attention_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 784, 10)      0           dense_68[0][0]                   \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_32 (LayerNo (None, 784, 10)      20          tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 784, 16)      176         layer_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 784, 10)      170         dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 784, 10)      0           dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 784, 10)      0           layer_normalization_32[0][0]     \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_8 (Sli (None, 784, 1)       0           input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_9 (Sli (None, 1, 784)       0           input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_33 (LayerNo (None, 784, 10)      20          tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.logical_and_4 (TFOpLamb (None, 784, 784)     0           tf.__operators__.getitem_8[0][0] \n",
      "                                                                 tf.__operators__.getitem_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_17 (MultiH (None, 784, 10)      3020        layer_normalization_33[0][0]     \n",
      "                                                                 layer_normalization_33[0][0]     \n",
      "                                                                 tf.math.logical_and_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 784, 10)      0           multi_head_attention_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 784, 10)      0           layer_normalization_33[0][0]     \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_34 (LayerNo (None, 784, 10)      20          tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 784, 16)      176         layer_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 784, 10)      170         dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 784, 10)      0           dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 784, 10)      0           layer_normalization_34[0][0]     \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_35 (LayerNo (None, 784, 10)      20          tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7840)         0           layer_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 1)            7841        flatten_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,363\n",
      "Trainable params: 15,363\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size=16\n",
    "\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "lr_metric = get_lr_metric(optimizer)\n",
    "\n",
    "txformer = model(batch_size)\n",
    "txformer.compile(optimizer=optimizer, loss='mse', metrics=['MeanAbsoluteError', lr_metric])\n",
    "load_saved_model = False\n",
    "if load_saved_model:\n",
    "    txformer.load_weights(\"./models/txformer-var-mask\")\n",
    "\n",
    "txformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "fzuSaIstGU0A",
    "outputId": "765dc0e1-e241-4363-8f90-c06fe21ea4e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST idx 0 which is a 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVR4nGNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kJuHrgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F5C49EB0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFklEQVR4nGP8z4AbMOGRG5UclRxhkgCD/gE3CChK/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4BED550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVR4nGNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kJuHrgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F5C49EB0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABq0lEQVR4nH2Sz2pTURDGfzNzzk1TbJPGtMlGfAAVFQpSEEUEX0ARfAE3gq/hI7juRt0H3LpQwY3UhQuJEf8gLopoo3SRm9wzLm5vkpuFszvzne98831zAAATamWoMe/VQAFMFBRinVVdXG2vli5k/l+yor0EBARZRk2sAJrpelvDaxutEDQBa5f3XY5/PyvaE9Ybhbx4OwERAcRbvYuTRrhwl7yZx8L/PjiYAARAfDweml/9+EHdWdu7mW9kEzTNXUhpJZN47fan/WajZk9LH9o4u/NueKN9Mk/BiTkPopImf/Y2Dt6UDAe0tBajqMV+99voSrdKT0lOEBBi8Gm6F199mS2SDaCgiMGZ7ucn2/1aTlodZOfhj92eNG2BmGSAYNbZev+03yXqAswqgdb295+XekvRCjIFFRc68aUORolIqDZoFkpy3Lr/9XGrn2msRgji5qFISDjFo83DZp6rEKalovtU81RET3ZnczpIx6Qcr201ELudYT4+1wvZ4jMFRDS5M/Nb64fPf8lMmW9LxEHMLT99fvdokI5mVmRe+OLhoAiEBgSCmVTh/QPqeH1l59I+ywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F9781FA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST idx 1 which is a 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4nGNgoAlgRDBLOPVCGKYfX4xN2cq/f//+/fv3lhwOuat9G/7+rcKUM/n195ICDwPbub89mJK+vy9JMjAwVP3464jFWHkhBgYGhot/sUoyMDAwMJR+/3uMC4ecz/e/z+2R+EwormJjWHkQh8YN3/7O58EhJ/nq70tlXK459vdvLy45vx9/9+IyVPgEHo1tf/+uxaWR4cffv5LoYixIbKHfDAwMH3+z8jMIFjIw/C3/hix5iYGBgWH1c/FwCPdFKzwlrPNHqPrzj2HTGYYjxxHJpIyVgUE7nIFh3gOGdddxuWyAAQCfcVM+FkfDOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F5CBFB20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFklEQVR4nGP8z4AbMOGRG5UclRxhkgCD/gE3CChK/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F5CBFB20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4nGNgoAlgRDBLOPVCGKYfX4xN2cq/f//+/fv3lhwOuat9G/7+rcKUM/n195ICDwPbub89mJK+vy9JMjAwVP3464jFWHkhBgYGhot/sUoyMDAwMJR+/3uMC4ecz/e/z+2R+EwormJjWHkQh8YN3/7O58EhJ/nq70tlXK459vdvLy45vx9/9+IyVPgEHo1tf/+uxaWR4cffv5LoYixIbKHfDAwMH3+z8jMIFjIw/C3/hix5iYGBgWH1c/FwCPdFKzwlrPNHqPrzj2HTGYYjxxHJpIyVgUE7nIFh3gOGdddxuWyAAQCfcVM+FkfDOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F5CBFB20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB3ElEQVR4nG1SPYtTQRQ99+u9JM/NxpiNRFYwxRY24g+wEbFXkMVC8WfYWPoHrBREF8RCQexkQVg/sFsQFewsFnQVF1FjPjcvmRmL9/KyEW8zl3PunHvunQEAgPFPMOg/aBaUVTAtAlmE7NAwA5L0fHIo2n/pvxTlFI+zLJZXqwPn0Lv0pzdrrGmejN82hpvvT1+05Gshnjsy+nDi0Y3rePDLoqiQzXtaa/vNTUmftMvBKuOCBNizH9qtz74n0oxc1c9uurl9AZbL27u3jzRyQGW+IEat9m7v3srhxZEzmhCv7306uQRl6AFKQQAq9d3u3eZRAdSKnTFADFRrO6ON5jGY6EHBrKZ+udNpNxgm8+eIOLOa1L7177dWwHFsOUm5Zaot7YTBatMQRShJ5ihimCPjIGdbeOrdRF3gfYcpAKSAAMyyfKoT1tZgApv7UQk28eAQJdh4hjB9fuHOVaHRgH5s9Qkg8uLqzRct+BEPfz68UvH0HaPuOisQAhzC8a1z9aEvmV6T3sfX3UG/64gA9uJgZ9BWlupvlKfucdqbjQKWWKFKMSgxAtNst6SYAhAHKMhLECdusrB20YgMFkFJNS4YAijAAhDIUoYHeQ/i7BcIo8RgQCImBUHmmn8BkB2QqQlkUBgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F5C4C2E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST idx 2 which is a 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiElEQVR4nGNgGARA7V8unM2ELmn47ylune0fccvpfpmG4KAbq861ErfOU/e5ccop/LuBxEMz1p7hNW5JXYYunKZavj3LgVOns9CNHzgl9f+vwWmqxIvrKHwUnQliJ3BLyjO8x2kqw5N/Tjh12orj1sfQ++8sMy6dXF4Ma/7i0sh6bAMXHnPpBAAPgx/ARH1j7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4BED100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFklEQVR4nGP8z4AbMOGRG5UclRxhkgCD/gE3CChK/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4BED100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiElEQVR4nGNgGARA7V8unM2ELmn47ylune0fccvpfpmG4KAbq861ErfOU/e5ccop/LuBxEMz1p7hNW5JXYYunKZavj3LgVOns9CNHzgl9f+vwWmqxIvrKHwUnQliJ3BLyjO8x2kqw5N/Tjh12orj1sfQ++8sMy6dXF4Ma/7i0sh6bAMXHnPpBAAPgx/ARH1j7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F9781FA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABf0lEQVR4nG2SMW4UQRBFX1V197BrrYDFEHEEAiKQEwICB0hchVsQIo5AyhG4AhIEBA4xEkJCskgskt2Z7iqC2Zld7K2s6vf/qn7dcLQEAL3Rj2V6Y3DrjNzyHHHIPFst3zxbzuECEEAYgJ6fXbSd2DTARlcTINK7O9vjNygnq4sXd6cuJWsHop+cDZtu6prutSJE3X6/3Ez7GjCT6Li3/vbk4Z6MAjgGyFb1ZRssZQcUETUAGcO9v1yspLbREKEN2UEI1vLx88+Ks48NIVBCsfN4L38yB6JA4JqR9vfLrxZDSRNUnXfm9P7Xp6elI83OAJoCGX+1uPY+Us0T+BCShYKn7qosk/R1pAxNCSoBWL3WjWkAHju4kJrjEv1aPnjnEiAxb1tDk0mx+rp9uoow7eK/p5KMPFj//vH4UVIp8z9JWMuDNgt//nax0SoxHBiNLEUME82Q8kGgorj2KqBpsCTDQiY+iCaviOCo2FCa1EBH9CrqkMKx0OYqWfs6x/4DLaSKiu4btoMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F5CDF670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST idx 3 which is a 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA70lEQVR4nMXQsWoCQRQF0JvBNNrGdjcgIR8gJJVrqRZCfkMkgn+QlEIIAcHaHzClVWySJkmXSgxqIbKCbcrLxRSbNe7M2uqr7syZefAecOTK9fTp78MLUs2ds9nJ+b71OPMfWzdXAALz9ZrSVCQpclp0bbiRpPVckmPlmUh268Ed2bDsfEVx2skCfsif9qkzxcsZAOCWYsHGDy+K/nuM2zmNuV5E6cQYc5/4+UDG0W07iTFfXlGhl45PJGelKGeQrOElgPFb8vJbqtWW0kYpG2qT8W7ZtdEP/zAcFbI2IniMsOkIAKD6zEGl6qXjweoXXfV/5XmKZEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F5C49040>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFklEQVR4nGP8z4AbMOGRG5UclRxhkgCD/gE3CChK/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E8313430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA70lEQVR4nMXQsWoCQRQF0JvBNNrGdjcgIR8gJJVrqRZCfkMkgn+QlEIIAcHaHzClVWySJkmXSgxqIbKCbcrLxRSbNe7M2uqr7syZefAecOTK9fTp78MLUs2ds9nJ+b71OPMfWzdXAALz9ZrSVCQpclp0bbiRpPVckmPlmUh268Ed2bDsfEVx2skCfsif9qkzxcsZAOCWYsHGDy+K/nuM2zmNuV5E6cQYc5/4+UDG0W07iTFfXlGhl45PJGelKGeQrOElgPFb8vJbqtWW0kYpG2qT8W7ZtdEP/zAcFbI2IniMsOkIAKD6zEGl6qXjweoXXfV/5XmKZEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72E8313430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACEUlEQVR4nF1SO2uUURA9M3fu3e/LYzcxRjD4KESxDRrUQoKFInYKwU4bkdhZ2fkrFGurdIKiKEQbCahBRDEgUQgECWaDrCbLZpPvcWcsshtXTzXDmTMcZg7QC2IAAAMkSBhMYIf/QADgQqfozP8D16shAsP1dDs6MoAVqZ0fC7NL0brS3j19F5eWvx6t7fbSw4WBhY3m8pFx/MOywhdI+e1+LyMzjySZ63qm7v50st7aarUaS/Onh3ecExsYJE4TeTBA1l79kR6iCWjXMAAE5feHkzU/+27r1OXGbXrZIcnIMJB9OsaNJ6+fy0Q+NfVx9tWXNgBU4AAamlxfX7k/Ogzvzl35Xl8Y7wMAyRDBpI3i2ZuZ6k82+Xay9P0JA2BxaiBEWbljRR1csttcr+Z9bQDGMDBFl9dqnDsxyrPqUJn/8gBMYiisBEm2mYNMD+i1G3sbiys+A8CIbIxoReo4lsiu3tzT/HBdWiA4hkW4YGhv11Rkn90a5blprAIGFRjI1MexFw9VB8vpkUrrHjXBCpg4RIvkQ/Xg3cEWsnR7I9ap3LmfRIScCPr0rBuuMorH8/2/HVg7b2FlyY6nZ05ccCU3LxVrZCUrABavLkbxi2H08wLKpMgMXEIBMiXAqRTeZZaosSl8LLohEhBIvRZIYx4imyIoyg7nAQLESxAIHAmj8jfMBMAD8JWAkAaEym7A/gCPYNeYAsLLtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4AED2E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST idx 4 which is a 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2klEQVR4nGNgGLzA6AGU4SYLZTAhJN3ZoQy/bgxJFi8Y64wWN7qko+V8KEtIiwvNRt03N3mgzAN/RNEkV3w3hWn8/xdNMuTTZRiz9+9eVlTJlX+yoCyFF7+cUOX4H/6BMdv+wM2AupZdegVMRJnhCppzOM9cFIKwxP7+zYaJskCo73eDt/YxMDDoKMv/Z/iPppNBc9XXP3/+/Hnx/PefP5wwQUa4tKEyAwPDGoaF0TDTsID6P3900exEAEZGhss4Jf8jOYcJXZKD4QdOKxlevMnHLbnZCbcclQAA/k48Hcv/z+EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F5C49C70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFklEQVR4nGP8z4AbMOGRG5UclRxhkgCD/gE3CChK/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4BF7430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2klEQVR4nGNgGLzA6AGU4SYLZTAhJN3ZoQy/bgxJFi8Y64wWN7qko+V8KEtIiwvNRt03N3mgzAN/RNEkV3w3hWn8/xdNMuTTZRiz9+9eVlTJlX+yoCyFF7+cUOX4H/6BMdv+wM2AupZdegVMRJnhCppzOM9cFIKwxP7+zYaJskCo73eDt/YxMDDoKMv/Z/iPppNBc9XXP3/+/Hnx/PefP5wwQUa4tKEyAwPDGoaF0TDTsID6P3900exEAEZGhss4Jf8jOYcJXZKD4QdOKxlevMnHLbnZCbcclQAA/k48Hcv/z+EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4BF7430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAByUlEQVR4nG2Tv2tUQRDHPzM7u+/eveSOxIgxiiAWKbSRQyxsTuwEwUIQsZKU9jb+A5Y2FoKdINiYtDYW/ihEsAup1EJQ0lwhMZz33tu1eO9+SNxqdr585/udmV0A4X8n6CLiZ5EAgmbTuztKdV7bqD4KapwTda4uC7U8AvhOVijASn42NAwFShJCfdWVDe16Og9A1FY0uc7DfiFA0u8vSgeQWlVBhidl0thayo8XjaVGN3XcszeHTacS+Dme+QLIbzxZ7nYcno3++y/XOgstSd7bC30RQcKJrb2dtQZs/cjgrdVJk9Cr7n+8GccLzCz/fLpwzgK6fu/rpd50RqCQXcatSKomcLD/x9sMlAjx17dtfyoirC49Xo3TLbR2Lx6+2t/2Sc22inhnd1RPu0/A8oVzm3d/dz98cleGrx9MRu0kLaYEMOhtxux5GoSnt8pdmfxTF1TBufXhj5f9Y9NMUgI+kxCjw9XJDh7lo3YZRqSSEqKP6MRJ7KqzylUNKEnRWlKKSa0SK8eTkgoAs8oqQF1MllIRwruR+LLBAFMPiDOHcOb2xlqYGxUMBwZqqA+5esAJCFj7nE0yU9DgpqtqCgMEOmCGX/gcfwE3M338X/YyfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F5C4C2E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST idx 5 which is a 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVR4nGNgGOzA9182My454cf//nHikgz8928pIw459tP//nni0mj6798vBI8JzVQGhl24NDIc+ffDAJec1b9/b5G4qMaaMjBMx2nq4n/vZHDJ2fz5dx+Zj2KsMBPDbnymmuKSk/nz7xKKALKxVkwMG3GamvnvlQhOnW4Mjz7ikmRVYfjxG5fkv9MMd1DtYUEw/9b8P4fTPdQEAJbDL46GK5NFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4AF9130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFklEQVR4nGP8z4AbMOGRG5UclRxhkgCD/gE3CChK/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4AF9130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVR4nGNgGOzA9182My454cf//nHikgz8928pIw459tP//nni0mj6798vBI8JzVQGhl24NDIc+ffDAJec1b9/b5G4qMaaMjBMx2nq4n/vZHDJ2fz5dx+Zj2KsMBPDbnymmuKSk/nz7xKKALKxVkwMG3GamvnvlQhOnW4Mjz7ikmRVYfjxG5fkv9MMd1DtYUEw/9b8P4fTPdQEAJbDL46GK5NFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F4BCAC70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABhklEQVR4nJ2SMYsUQRCFv6rqnpFd8WY510AwFDwwNhMU5CL/hn9H/BFibmKosUYigpGBp+ItiOipp7vTXWUws6u3bGQlTb2iqt6r17AzBAxTEBTQ7bpL7G4cm/87JG0Bnd778fTo56750k2fv3nQTMZsJJmHJ1a39jid+pitYTDE9mYv3z+cz9dQqgASEo4Vbjer+8uTdVEdSBCoFezLJGKyIZkACpB7MG2/vzhq/awAG6Z03evFzdm2zmGxt4fn6zfL/VgMhTTqDP31yZ8c5zhjgiENkPf3Py6uXSHZhq1kKlEhS7pLn53i46isUQGqprJafsjPFoUU2gRAjyQyBmg3O14eXMIEZDh20kiuFYhzN/JvIxVsYA9axas3lrAeSqfFcq1rQhQnrzy09p/T47dBLX9dVsgJES5eeHdyMNe2baejFk0OURARvfrq8im5VHpXH912rFrg+c7y+iP7ukT/PbwiSRKQtBFEN99DFRwpQRKRlkAcHXeG5CgopDpaE6DiBKB/ALUli7TppHR5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F72F5CDF670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fit_one_epoch(dataset):\n",
    "    txformer.fit(x=[dataset[\"tuples\"], dataset[\"masks\"]], y=dataset[\"target_pxs\"], epochs=1, batch_size=batch_size)\n",
    "\n",
    "# display:\n",
    "# - before mask\n",
    "# - mask\n",
    "# - after mask\n",
    "# - prediction\n",
    "def gen_image(dataset, idx):\n",
    "    img = np.zeros([28, 28])\n",
    "    mask = dataset[\"masks\"][idx]\n",
    "    erow, ecol = dataset[\"offsets\"][idx]\n",
    "\n",
    "    image_mask = np.array(mask_to_image_mask(mask[np.newaxis, :]), np.uint8)[0]\n",
    "    masked_image = np.copy(dataset[\"imgs\"][idx])\n",
    "    \n",
    "    print(\"MNIST idx\", idx, \"which is a\", y_train[idx])\n",
    "    \n",
    "    display_uint8_image(masked_image) # before mask\n",
    "    display_uint8_image(image_mask * 255) # mask\n",
    "    masked_image = masked_image * image_mask\n",
    "    display_uint8_image(masked_image) # after mask\n",
    "    \n",
    "    for row in range(28):\n",
    "        for col in range(28):\n",
    "            img_tups = np.copy(dataset[\"tuples\"][idx])\n",
    "            img_tups[:, 0] += erow\n",
    "            img_tups[:, 1] += ecol\n",
    "            img_tups[:, 0] -= row\n",
    "            img_tups[:, 1] -= col\n",
    "            mask_idx = row*28+col\n",
    "            targ_idx_mask = idxs_to_onehots(tf.constant([mask_idx]))\n",
    "            this_mask = tf.logical_and(mask, targ_idx_mask)\n",
    "            px = txformer([img_tups[np.newaxis, :, :], this_mask])\n",
    "            img[row, col] = np.clip(px[0, 0], 0, 255)\n",
    "            \n",
    "    display_float32_image(img)\n",
    "\n",
    "gen_image(test_dataset, 0)\n",
    "gen_image(test_dataset, 1)\n",
    "gen_image(test_dataset, 2)\n",
    "gen_image(test_dataset, 3)\n",
    "gen_image(test_dataset, 4)\n",
    "gen_image(test_dataset, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[\"masks\"] = tf.logical_not(test_dataset[\"masks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "Qc-55LXO8Dtl",
    "outputId": "47b797e1-67ca-440b-c252-7e961a14c6ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-03 17:02:38.932965: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 132/3750 [>.............................] - ETA: 4:01 - loss: 1370.1630 - mean_absolute_error: 21.3586 - lr: 0.0010"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9039/393480759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_9039/2112471466.py\u001b[0m in \u001b[0;36mfit_one_epoch\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtxformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuples\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"masks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target_pxs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# display:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# - before mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1196\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \"\"\"\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    334\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit_one_epoch(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_image(dataset, 0)\n",
    "gen_image(dataset, 1)\n",
    "gen_image(dataset, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Po6NnXshwaCj"
   },
   "outputs": [],
   "source": [
    "fit_one_epoch(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_image(dataset, 0)\n",
    "gen_image(dataset, 1)\n",
    "gen_image(dataset, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhSfq8VcPOEW"
   },
   "outputs": [],
   "source": [
    "fit_one_epoch(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DD2oRg5MMrmK"
   },
   "outputs": [],
   "source": [
    "gen_image(dataset, 3)\n",
    "gen_image(dataset, 0)\n",
    "gen_image(dataset, 5)\n",
    "gen_image(dataset, 2)\n",
    "gen_image(dataset, 13)\n",
    "gen_image(dataset, 10)\n",
    "gen_image(dataset, 15)\n",
    "gen_image(dataset, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNhU_P0QPWPt"
   },
   "outputs": [],
   "source": [
    "if not load_saved_model:\n",
    "    txformer.save_weights(\"./models/txformer-var-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txformer.save_weights(\"./models/txformer-square-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST conditional prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
