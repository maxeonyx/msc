{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx9vGgfSkcpL"
   },
   "source": [
    "\n",
    "# Conditional autoregressive transformer\n",
    "\n",
    "Train a transformer to predict missing pixel from mnist \n",
    "\n",
    "### plan\n",
    "\n",
    "* note to try padded mnist (relative encoding might require black padding???)\n",
    "* probably don't need positional encoding?\n",
    "* create transformer model\n",
    "* masking \n",
    "* randomised masking\n",
    "* relative position encoding (x - current_x, y - current_y, val)\n",
    "* train to predict when current pixel missing\n",
    "* train to predict when 10% are missing\n",
    "* train to predict when 90% are missing\n",
    "* train to predict when 99% are missing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"txformer-bigger-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3pbiscqn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3pbiscqn). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ethereal-puddle-33</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/maxeonyx/conditional-mnist\" target=\"_blank\">https://wandb.ai/maxeonyx/conditional-mnist</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/maxeonyx/conditional-mnist/runs/1euxdsjr\" target=\"_blank\">https://wandb.ai/maxeonyx/conditional-mnist/runs/1euxdsjr</a><br/>\n",
       "                Run data is saved locally in <code>/am/monterey/home1/clarkemaxw/conditional-mnist/wandb/run-20210930_072148-1euxdsjr</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Init weights and biases project\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "\n",
    "wandb.init(project='conditional-mnist', entity='maxeonyx')\n",
    "config = wandb.config\n",
    "config.learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve GPU 0 only (for VUW machines)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-30 07:15:39.413140: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-30 07:15:39.965954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6668 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:3b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "tf.constant([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "\n",
    "def display_uint8_image(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = image[:, :, 0]\n",
    "    if tf.is_tensor(image):\n",
    "        image = image.numpy()\n",
    "    display(Image.fromarray(image, \"L\"))\n",
    "\n",
    "def display_float32_image(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = image[:, :, 0]\n",
    "    if tf.is_tensor(image):\n",
    "        image = image.numpy()\n",
    "    display_uint8_image(image.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  1.0000000e+00  1.0000000e+00  1.0000000e+00]\n",
      " [ 7.0710683e-01  1.3921213e-01  2.4833918e-02  4.4166050e-03\n",
      "   7.0710677e-01  9.9026257e-01  9.9969161e-01  9.9999022e-01]\n",
      " [ 1.0000000e+00  2.7571312e-01  4.9652517e-02  8.8331243e-03\n",
      "  -4.3711388e-08  9.6123999e-01  9.9876654e-01  9.9996096e-01]\n",
      " [ 7.0710683e-01  4.0684462e-01  7.4440487e-02  1.3249470e-02\n",
      "  -7.0710677e-01  9.1349739e-01  9.9722546e-01  9.9991220e-01]\n",
      " [-8.7422777e-08  5.3005296e-01  9.9182546e-02  1.7665559e-02\n",
      "  -1.0000000e+00  8.4796453e-01  9.9506927e-01  9.9984396e-01]], shape=(5, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def idxs_to_onehots(idxs, depth=784):\n",
    "    onehots = tf.one_hot(idxs, depth, dtype=tf.bool, on_value=False, off_value=True)\n",
    "    return onehots\n",
    "\n",
    "# takes 2D tensor (batch and index list)\n",
    "def idxs_to_multihot(idxs, depth=784):\n",
    "    onehots = idxs_to_onehots(idxs, depth)\n",
    "    multihot = tf.math.reduce_all(onehots, axis=len(onehots.shape)-2)\n",
    "    return multihot\n",
    "\n",
    "def idxs_to_attention_mask(idxs):\n",
    "    multihot = idxs_to_multihot(idxs)\n",
    "    attn_mask = tf.logical_and(multihot[:, :, None], multihot[:, None, :])\n",
    "    return attn_mask\n",
    "\n",
    "def mask_to_image_mask(mask):\n",
    "    image_mask = tf.reshape(mask, [28, 28])\n",
    "    return image_mask\n",
    "\n",
    "# scale is the max-min of vals\n",
    "# for mnist it's 28 because thats the width and height of the images\n",
    "def positional_encoding(vals, dims, scale=1000):\n",
    "\n",
    "    i = tf.range(dims//2, dtype=tf.float32)\n",
    "    i = tf.expand_dims(i, -2)\n",
    "    \n",
    "    vals = tf.expand_dims(vals, -1)\n",
    "    \n",
    "    # the bit inside the sin / cos\n",
    "    rate = vals / tf.pow(scale, 2.*i/dims)\n",
    "    \n",
    "    sin = tf.sin(rate)\n",
    "    cos = tf.cos(rate)\n",
    "    \n",
    "#     # expand dims to allow alternating concat\n",
    "#     sin = tf.expand_dims(sin, -1)\n",
    "#     cos = tf.expand_dims(cos, -1)\n",
    "    \n",
    "    encoding = tf.concat([sin, cos], axis=-1)\n",
    "    \n",
    "#     encoding = tf.reshape(encoding, [-1, dims])\n",
    "    \n",
    "    return encoding\n",
    "\n",
    "print(positional_encoding(tf.constant([0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi]), 8))\n",
    "\n",
    "def img_to_tuples(img):\n",
    "    \n",
    "    height, width, chan = img.shape\n",
    "    length = height * width\n",
    "    vals = tf.reshape(img, [length])\n",
    "    vals = tf.cast(vals, tf.float32)\n",
    "    rows = tf.range(height, dtype=tf.float32)\n",
    "    cols = tf.range(width, dtype=tf.float32)\n",
    "    cols, rows = tf.meshgrid(rows, cols)\n",
    "    rows = tf.reshape(rows, [-1])\n",
    "    cols = tf.reshape(cols, [-1])\n",
    "    \n",
    "    # permute the order, to ensure the network uses the positional encoding and not the implicit locaiton\n",
    "    idxs = tf.range(length)\n",
    "    idxs = tf.random.shuffle(idxs)\n",
    "    \n",
    "    rows = tf.gather(rows, idxs)\n",
    "    cols = tf.gather(cols, idxs)\n",
    "    vals = tf.gather(vals, idxs)\n",
    "    \n",
    "    return vals, rows, cols\n",
    "\n",
    "def random_mask(n_masked_out=None):\n",
    "    \n",
    "    def call():\n",
    "        idxs = tf.range(784)\n",
    "        idxs = tf.random.shuffle(idxs)\n",
    "        if n_masked_out is None:\n",
    "            n = tf.random.uniform(shape=[], maxval=784, dtype=tf.int32)\n",
    "        else:\n",
    "            n = n_masked_out\n",
    "        idxs = idxs[:n]\n",
    "        return idxs_to_multihot(idxs)\n",
    "    \n",
    "    return call\n",
    "\n",
    "def random_square_mask(maxsize=28):\n",
    "    height = tf.random.uniform(shape=[], minval=1, maxval=maxsize, dtype=tf.int32)\n",
    "    width = tf.random.uniform(shape=[], minval=1, maxval=maxsize, dtype=tf.int32)\n",
    "    start_row = tf.random.uniform(shape=[], minval=0, maxval=maxsize-height, dtype=tf.int32)\n",
    "    start_col = tf.random.uniform(shape=[], minval=0, maxval=maxsize-width, dtype=tf.int32)\n",
    "    rows = tf.range(start_row, start_row + height)\n",
    "    cols = tf.range(start_col, start_col + width)\n",
    "    cols, rows = tf.meshgrid(rows, cols)\n",
    "    idxs = rows*maxsize+cols\n",
    "    idxs = tf.reshape(idxs, [-1])\n",
    "    return idxs_to_multihot(idxs, depth=maxsize*maxsize)\n",
    "\n",
    "def random_offset():\n",
    "    return tf.random.uniform(shape=[2], maxval=28, dtype=tf.int32)\n",
    "    \n",
    "def display_mask(mask):\n",
    "    image_mask = np.array(mask_to_image_mask(mask), np.uint8)\n",
    "    image_mask = image_mask * 255\n",
    "    display_uint8_image(image_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "positions = tf.range(28, dtype=tf.float32)\n",
    "encodings = positional_encoding(positions, 16, scale=28)\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "im = ax.imshow(encodings)\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow.data data generator\n",
    "\n",
    "from tensorflow import data as td\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def make_dataset_generator(split='train'):\n",
    "    \n",
    "    def split_enumerate(i, data):\n",
    "        data[\"index\"] = i\n",
    "        return data\n",
    "    \n",
    "    def map_add(component, func):\n",
    "        def do(data):\n",
    "            data[component] = func()\n",
    "            return data\n",
    "        return do\n",
    "    \n",
    "    def add_tuples(data):\n",
    "        data['vals'], data['rows'], data['cols'] = img_to_tuples(data['image'])\n",
    "        return data\n",
    "    \n",
    "    def add_square_mask(data):\n",
    "        mask = data['mask']\n",
    "        square_mask = random_square_mask()\n",
    "        mask = tf.logical_and(mask, square_mask)\n",
    "        data['mask'] = mask\n",
    "        return data\n",
    "    \n",
    "    dataset = tfds.load('mnist', split=split, shuffle_files=True)\n",
    "    \n",
    "    # keep track of the index in the original MNIST\n",
    "    dataset = dataset.enumerate()\n",
    "    dataset = dataset.map(split_enumerate)\n",
    "    \n",
    "    # shuffle the digits\n",
    "    dataset = dataset.shuffle(60000)\n",
    "    # repeat the dataset infinitely\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    dataset = dataset.map(add_tuples)\n",
    "    \n",
    "    dataset = dataset.map(map_add('mask', random_mask(500)))\n",
    "    dataset = dataset.map(add_square_mask)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "dataset_train = make_dataset_generator()\n",
    "dataset_test = make_dataset_generator(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-30 07:15:42.161213: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (28, 28, 1)\n",
      "image dtype <dtype: 'uint8'>\n",
      "label shape ()\n",
      "label dtype <dtype: 'int64'>\n",
      "index shape ()\n",
      "index dtype <dtype: 'int64'>\n",
      "vals shape (784,)\n",
      "vals dtype <dtype: 'float32'>\n",
      "rows shape (784,)\n",
      "rows dtype <dtype: 'float32'>\n",
      "cols shape (784,)\n",
      "cols dtype <dtype: 'float32'>\n",
      "mask shape (784,)\n",
      "mask dtype <dtype: 'bool'>\n",
      "index tf.Tensor(17593, shape=(), dtype=int64) which is a tf.Tensor(6, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7klEQVR4nGNgoApgd/r8/28zgs+EJMeZsIvz36P72DU2/fnzZ4YkdjnhN3/+lIjisLHhz58/Yric8//v9zhccvF//2zHJefy7e+HQFySsX/+FqCLwf2ZwcDwBqckN+P/H+iSLHC3/n+1hoGBgYGBV4nhz1U0Vef/PGNgYGBgcDr9589b9GA6/+e9EgMDA+ehP3/+/G1Fk5z9528/AySYTvw9hyYZ+vv/305WhlN/v2vV/z+P7rT2v3/+bLT8++dIz5e/LeiSDPv+/Pnz5++fP3/+vMGMN9Z2qOSlSRhyDAysZp17//6524kz3gY3AABeK2wMKib60QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF5680F6E20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAm0lEQVR4nG2T2xKAIAgFl6b//+XtwUICmUmUw/VoAOD6RFHltbqVLLsd+LuiP8VW9jM7X+aVtscan+W+NLtUOlfRkoiTmJ0OfBmuQ6wYJCk9sPDEGRZuJGbeKCtExUIIjAskgiYBxL6H1i6Dqh9WB24wDr8C7acy6fO03YXWOIxBkgSZIK/xJhjB2cz3wOYgq/Kpn7R9P4B1LNEHHDmmerSAISUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF5680F6910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAR0lEQVR4nGNgoApgZ/iMU46TgeEPbp1/GBgYJLFLCeO18g8DgxgRLhtSQBuP3B9YMDFhlc7Bo/UvHrl6hvP4XNSCz0EjDAAAGc8Js+isQP0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4880EF2B0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(22288, shape=(), dtype=int64) which is a tf.Tensor(8, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA8klEQVR4nM2PMUtCYRSG3+I6WhlocmlxSRCLoF1IcqpfEEE2SVuTk7OjP8A9wZaS4I5BiyAURVNLpVxUEAuHhuDyQIMGaWd06F0O33m+95z3SP9MC1Ov1Jm732iqOrK+VgBgWLCcvquHrpS92zWcPs8xac3/yEcteC9FSsCFBQeZ1RYQHFpwrJeCuRPgMR4yWHIIBCcrBnJybRjVtwykRBng1ELa6QCw97u3OKnbV+uiMWP4geeuvNytOVNHQSscUm1m7OSGV5qSvuhPZXUkSctRedo4dnT59NdZhPfrN7hZMlamewB8HpiBNvuAl7XTzlvfUVBwe6w8SfYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4880EFD90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAuUlEQVR4nGWSSZbFMAwCS3n//leuXliT3VkkHkASBBAFFERAyHcYvQ8MMBcSjSJLNE889eaZu0SepUN2mC956v8IsvPzxNHQY9y9s733ZXf5Um6elOAbaGuzmO1WK1ZXG1H1H62nGEDVKfZjZs/hcZ+Q+dYs0U7lCC5DS5ueKeffjWftnwsN+KXHsa086chYZKmJ0XgLSmSaGliuLqxbtYPksmWf+PBWrTdEtf9OeNs1x4lq0CLcTP8AX97mQYa6HNQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4880EFD90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkElEQVR4nNWOIQ7CQBREXwgWBAZdgyoNSRMO0FT2HkgcqrpH6Y3qSdZhiyCkkyC2DYL/KwiGUT/7Mm8H/iCXOShOX2q3wTMCtc0CNzZI3hgJOYvk16ZPpyze55Ir9HYnaXxnHueY7BDEE6fYAZzdqStopdJCAnhA9omOADsGRzpmbbylUXuvzMYegGJe+6u8AFnBKa65B7bQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4880EF580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(6959, shape=(), dtype=int64) which is a tf.Tensor(6, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7ElEQVR4nMXPP0tCYRTH8R/dCG+hUJANBaFul6aKcHCooAh6AeLa5itwcdJNcDCam6OpegNNd7lN0V5NLgri4h/wqw33WtfrU2P+tvN8OM85R/qP1Cfj8m+21oembbYdF6D2XS+FMZeVRMfYeNYFuDGa0wK4XzXiPsDg3GipVwDPaJsvAN6udFGZwzyAZ1vXveGoFEUX4MpaB3jb9t+mdzpJSc2tRluSnGdnBk/Skt73in6VOZYkLftV7FSScpFRQedK1nhCkMNPQvk4mNWjMN5GWhOPP/YQj34cu5taNz8/dqNQBeDp8q/lFpovwFR8j+ckj0YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4A865AEB0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAvUlEQVR4nGWSQZYFIQgDK75//yvXLATFHnshNhASAAQQVBGsD4hkWwQAA0h2QiX2kQOw4YBt8hyr3L2qHM/t8/tgKF6fPhzG81h6yg6fhyiyTFliJKkkxR8Gkym/MdMyDyP/dcXuzYXs6jfSJ/rb3ssVZKF5wrKZIAaJD9lCCax+mcoTU7Ndg3MgBVzeFnF09IQ/A5iCfLsxZT/0PcswdgFWQ5cQBTOqz524IG8vR4nPNkyqB2vNBazo9Lr/Aazx4lQekrR+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4A873DAF0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAlklEQVR4nM2QOw6BQRRGT0zDAlQ0liU6pQ3Yg1ql0GmUlvGr1ArWITmJYmR+zKPlZpK5uSffdx/w+1BGZTIFYNOQPvp88Ekg7Goq8Fhl1prNLiBdkY3PDSGIXdxxXeTL1z/5ql8B2IKY2YtwMKasgLcjBAMsEAiZ1P7lY98xuXPLmiYz3Wd7JLfCLYZo477zONCpTP8hnuvvPB3UjsxQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4880EF2E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(22313, shape=(), dtype=int64) which is a tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAhElEQVR4nMWRQRYCIQxDMz7vZW5mPVmYk8UFZQa1uNSsoP+lDQX4m0iEzBo6FQWLAa3SGYGQ7aI3ez/K1mJyDlhT2l5CRJ3qpHm61LyEBHBbhJEln4m22XQE2fAhKhfMLFznEHuvtvZu8ySkdzj77XEH2j5e8uoUoHJ5+vLdgCyCJfqlnmRpZne5OucLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4880EFA00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAjklEQVR4nJWSSw7DMAgFx1Hvf+XpArCRSlKFBbaB9/gZARREBIwnZakAQ4UlAKSTo88lELIJ2pHYSnt0+spkT90MO7oz/BTSpLfxVvRwD8T3PvbEBvmw/tTi7G5beYlk4TJvd7gHYmfmvuYZ9Ty8u4DLHO5U7EU2MSLDvlw1q/PL7F0KWmnOKisqkdGefAEiM5d7zrZN9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4880EF2E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAPElEQVR4nO3QsQ0AIQwEMMNkjMZmP1roI0EDLxpcJrqLFK5pdNpsHUKkWQUdyrQ3h9LNZ8fquRu+f2rPGvnSB37wp3rZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4880EF520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(11081, shape=(), dtype=int64) which is a tf.Tensor(6, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA60lEQVR4nNXQMUtCURiH8T+SoRC2mDV0BwdJ/QBNDg1B1BbimvQJQsIPcCcHpzZBkBbpC0Qtji061Jq1uCmICQXqJZ50cPFee7eW3u2cH885nCP90eTmmZVVyGeb5z+FDSvMArtWmZRqY6u8hYxlJ182Rj16FyEDK/BoHXrsMT0ybOcJXCu8h2HCsNyEWUqSFC4mA7b3AlNJKjYHjMt+PITZtvIND4DWcnPlm+ufl+UD9W++3S2tla8lJs/XMUW6XPkxPQK4i0uOy3s8kJ5+AHSbDz0orb3FKXQAwKsG75Sk6H7lDdpnv9B/mAVoImShTFGTyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4A865AF70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAtElEQVR4nHWSUQ4EIQhDH2bvf+XuB1BczDqJTrS0UAAANIf87ZU3qiN/cgN1iFAh+1lSPhcywXqIE3mFNHVeXTiso1bZudFM9fKxUoACAhEbLu26LS3XtDxxxAqEsEKIeOxcJj5+/JM8NlMKW375dIWNsyBOcPnqFYUcAlvbbGfYIlCWVMTaMt0rT1MPgAaF5wKrz3RM38YQ/eyni7AHVymf9iAAdcJFFEwzVMMgB8/068njC3Bu11Jr9S50AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4A865AF40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAg0lEQVR4nGNgoBKwYdDEKcfG8LcOn96/eKXY8Mgi28mEIvWZgRmXLs6fpDiGCasqIjQi68TjQwYGhh+qeCS/47bw7w+o4ViM/4vFXiQH3WBgYLiI1VQNBoa/fxkYRBgYZBkYbmO3+OZSBoa/DIUYErKhDAx/IbbyYNHHCaG8sBo6+AEA5ygeiYRR4ZEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4A865AFD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (28, 28, 1)\n",
      "image dtype <dtype: 'uint8'>\n",
      "label shape ()\n",
      "label dtype <dtype: 'int64'>\n",
      "index shape ()\n",
      "index dtype <dtype: 'int64'>\n",
      "vals shape (784,)\n",
      "vals dtype <dtype: 'float32'>\n",
      "rows shape (784,)\n",
      "rows dtype <dtype: 'float32'>\n",
      "cols shape (784,)\n",
      "cols dtype <dtype: 'float32'>\n",
      "mask shape (784,)\n",
      "mask dtype <dtype: 'bool'>\n",
      "index tf.Tensor(5121, shape=(), dtype=int64) which is a tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzUlEQVR4nM2QLQ7CQBCF3zQcobVgqW01WHSx+B6CWk6AQoMGJBZSuQkKCFdYTYKa2UX0L6Vdh+CtmEm+zL6ZB/yvRnFRTdRloeYMADLpgakRBSCWZnJQw7G1RwCJ7XFcidEA8BDVdRTWEYC5cAOrb7eE9RWAT8hr6FWNtYeyPjswJ9rHAAKidxx8efp3FlbL3UtYOP3eaHoyUjylwu4xs7OwsNx67iy0EbNwwgvroYsFppWP14KJbSXbhuQROaE1ZU6OSd+5rC88ccKf6QN/o1SThAO4bgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF478053700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAtUlEQVR4nG2SWQ7EMAhD7ar3v/LrB/toqjQLAWNMJIT6QxLrXLbyyrs99z3Esu3sgJOH6xPBOdZKIpz8DbTg4bLaefhXVkasdAeWNlLeSXcOCxZY5ML24ECwJLdv7Izn5ExtzYqMswjHhCQfQkvKqOfdQBRQZPgRl0UVsGpwOAVWB47g2wCwQFvDtDBio2wpkl6NNrLkQi91zkNJqGHeLa1+jWvd37bOv15vlwR60t/FPqjJyHwgQdxU2MavtwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF478053C70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAf0lEQVR4nGNgGNqgGr+0EYzBhCn3F7e2a1jkNKHGBWHV8e8vzCV9cDG4nUz/10Fs/HMDU5KB5boxAwNDNSPjN2PsrqlazMDA8PcPDrf+Y/iHxGNBlvr7n4nhPw5tDAx4Q4DhIMNLObJ0puExlICdDAxV+DXjAiJ/GWzJ00kKAABDBR1pTFC5fQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4780532B0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(1328, shape=(), dtype=int64) which is a tf.Tensor(5, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAwElEQVR4nGNgGOQgpE0Bp5z/1/8NCB4LspSqVhznf5sNDAxHb518gaaN69o/OPh4JwVVp6EGA8OWzv8MDAyM/+WdhNGt3PivFadzuK7c4cQpGfFvBwqfCZlzmGEvbsmfDN44TWUQePveGrfsin8nOXBKSlz6twyXnQxf3zO8xKlz1r8b4piiifoMDAx8u/99Dcai5VQ/h1TZw3/fq7GZt+vHuVv//t0MwWpZ/It/369ZcqOJMkJpafnv53G6k8oAAIUaRcdDVVPxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF478053A60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAlElEQVR4nJ2S0QrDMAwDT/n/f749OE7b0WSwUChYsU61i7wehY10PtU43ntTnu+iAu6oCowNNOzFA/HE+ynbz5t2sj0i/Wvoq9NRQ7zBSspV1Y6gCvr8lEu+qgEMSFxrZBVwBm/cvFBWtnpDzd8kZm6v7WxckyKx3h2kdLUMexV24lDXs0bQCOwBrLSPmY+vkhIKIx9wcYKlTKI9CgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF478053820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUElEQVR4nGNgGO7AH6/sR4YUBgYmHJL8DMLUdw99wUl8kv+WkWvsDXE8ksFYxE5BLPxejSLKAqE+MDAwMDDcVsdu3It/DNdw2iVthcchVAYARokNuQKPei0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4780534C0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(7488, shape=(), dtype=int64) which is a tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAn0lEQVR4nGNgGHmA29CNDbsMo8XCF//+TWLHJme78d+rDpuyf1ZY5Dz/XGqQY2BgXLQTi+Tb1awMDAwMDPVfxJFEWSCUyrffDAwMDAzv37zB7eB9u1EcCWcVKgrL82v+XfiDgYGBgeHV9ZdHEKr0f/z79+/fn9+/fx+/+fv37287lyMZIfPj3/9/V5GdgwxsL/y76oXTMUwCHLhdOqwBADkSNuwJVKjhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF478053340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAv0lEQVR4nH2S0Y7EMAgDx9X9/y/PPhAI3ZUulVoKAdsAKAgoUqetx4QKYeww1mPHxn0K2bZ4/ttGeAJA6hW07FOjAVfdrhxz3MHAJBp4KtBuaToZqu6qvj4XvBAHlCvmKLgZRmJJsXlBDMX0lv3Cvi3B5TkXs8UVBA3klFocJ/svmItUdE6DlorXWfNyFDdDXrwPYYf3XJnrh9+4u82robU9M6Ai8JrAKBxud5vWkvgtZav60TmN+jdrRKxVLB0fVQXXV/09A/0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4780530D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAVklEQVR4nGNgGAVEgo0MDB0MDP9wScsxMDAu2olNZjWU/oLH8LwHzHhkd2MXLmRYysDwh4GBgWHSJHQ5/R8Qp/7+fZyBgYHhGx7TsYCr+CQ5SDNr2AAAWA8RSC6KjEwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4780535E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(5961, shape=(), dtype=int64) which is a tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAx0lEQVR4nGNgGLRA/UkjbsnKfyfRhZjgLHc4S9oPQ+fNf9kQBvPuf5boOhkYOCCUqTODJ6akIIQyZmDYjibJy8HwDMIyZziO7jSnf/8kGRgYGBhEHv0rRHfPrH+P2RgYGBgYCv49F8DwCsPRXwwMDAwMegznmaEiLAhJ1QIGOUcGBh0G87p8DGPhYCYDus4ONmOGK2febWK4JbgX3T1wwPz2lzFOSb9/X+FsJnTJ698Z+XDqZHjzLwynTmRAouT2vw/waaACAACqWDfQiKKWoQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF478053EB0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAArUlEQVR4nHWTSxLAIAhDk97/zq8LEFBbhxkt3xCohFIkCURcSt1mjnc6Xaf98afdQpLvaKrGT+o8z0eYFqLDWHAsicNoWcLkx14UUjLFjqgJQXp8dhr9/xA0LZwuXI87vGsEALTRXrPrcU5AprvtS+RIWCk+cMGgu0c1ahVhABVImbY96rshJ+2dOuma6qLQ2Y+xMCY0slDMJLYtRyzj0BXYwVPvUZZav8FqIeQFNhOzc0DtXm8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4780532E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAbElEQVR4nGNgGN7AD4/cbgZLnHIWDP+aICwmTEljBqbtOHUuYjiKRQsEiDD8gzEx1cRgswov+MdQwMDAcJ6BgYFhInYF/xgQNiIBpQWXGRgYEoWF35JoI3FA9Sv5erE5Fwbe4NX524x8W4kCACQDE8pvpFvnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF478053730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(5588, shape=(), dtype=int64) which is a tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7UlEQVR4nGNgGBrAdZoTbskZf6+jicz94gplybx85oUqZ33u7xYIi33m+cm8KHJ8N/5eFmFgYGBg4Gj6uxrNUIu/P7MgLP3Pf/1R5fSe/02CsDj7Pl0SRpWc8H2/OIQV+/e4EqqcwLWXClBm7YP3qJL+WblQluucH29tUDUuvApjXfz7dz2qXOjZm3wccsySofZP/vy9z4wq+f/v1yun38x88vfv37/309H82PX9Lwy8QZJjhFAW8hEMDNcEGdwVVO8xYAdBm+wlGZH4LMiSX2UePsehT/nM/gAcUgyCx8vRhZjgrP/nbuLSR2UAAK0OWRGUMqi9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4780536A0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAsklEQVR4nGWRWRYEIQgDi77/nWs+lED3qM8VkxAAEcAzs5uCuUyYr1h1YlCEBxCFgjshFHUeoUqsy27vQzgMN2IUnTiXmNM7k77D6U/ejhjvUpZ1EA+3wQ3DBo4zd1w9O/3mncgLnkz0D9EASdsXD6l62dKzswnzx7YX+JOCZGmAMohLWhfaSJ+2lfz51Gcdt23O/tdJfezqQqSyr6aRYi6W022L5ruTzxbwOnx2W5ed6Q8Vleo2II+W4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF478053C70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAf0lEQVR4nGNgGCJgGj7JvwwMDAxMSAJzv8BYMgwv0VWf+wtjzTzPwIsixcfw9zKU2cSwGtOiLBQbkYAeMucSurbv+8UhjFgMEwWQOe/RrctFsN/aYDoH5hh01zAwMDBwMDDj1MBwGsZIR5f5zvAX5jkMOQYL3CYOGBCYGkAnmwD5mxnD3ZkIVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF478053700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dataset_summary(d):\n",
    "    for el in d.take(1):\n",
    "        for name, v in el.items():\n",
    "            print(name, \"shape\", v.shape)\n",
    "            print(name, \"dtype\", v.dtype)\n",
    "\n",
    "    for el in d.take(5):\n",
    "        print(\"index\", el[\"index\"], \"which is a\", el[\"label\"])\n",
    "        display_uint8_image(el[\"image\"])\n",
    "        display_mask(el[\"mask\"])\n",
    "        display_uint8_image(tf.reshape(el[\"image\"], [28, 28]) * tf.cast(mask_to_image_mask(el[\"mask\"]), tf.uint8))\n",
    "\n",
    "dataset_summary(dataset_train)\n",
    "dataset_summary(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Maths\n",
    "\n",
    "Dimensions $N$, $D$, $E$ and $B$.\n",
    "\n",
    "- $N = 784$ is the number of inputs.\n",
    "- $D$ is the width of the _key_ $K$ and _query_ $Q$ vectors.\n",
    "- $E$ is the width of the _value_ vectors $V$.\n",
    "- There is also a (or multiple) batch dimension(s) $B$.\n",
    "\n",
    "$K$ is $B \\times N \\times D$ dimensional.\n",
    "$Q$ is $B \\times N \\times D$ dimensional.\n",
    "$V$ is $B \\times N \\times E$ dimensional.\n",
    "Because it is self-attention, $K$ and $Q$ have the same length $N$, and the attention matrix is square.\n",
    "The attention matrix is $A = Q \\cdot K^T$, and is $B \\times N \\times N$ dimensional. Formally:\n",
    "$$\n",
    "A_{b,i,j} = \\sum_d Q_{b,i,d} K_{b,j,d}\n",
    "$$\n",
    "\n",
    "We do softmax normalization along the columns $j$ of the attention matrix (such that each _row_ $i$ sums to 1). The result is the attention weights. Formally:\n",
    "$$\n",
    "\\bar{A}_{b,i,j} = \\frac{e^{A_{b,i,j}}}{\\sum_{j'} e^{A_{b,i,j'}}}\n",
    "$$\n",
    "\n",
    "The output $O$ of the attention layer is $B \\times N \\times E$ dimensional. It is obtained by the attention weights multiplied by the value vectors $V$. $A$ is $B \\times N \\times N$ dimensional and $V$ is $B \\times N \\times E$ dimensional.\n",
    "$$\n",
    "    O_{b,i,e} = \\sum_j A_{b,i,j} V_{b,j,e}\n",
    "$$\n",
    "\n",
    "Often the dimensions $E = D$ because this allows multiple attention layers in sequence, but this need not be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5noipvB9oe8v"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def multi_head_attention(n_heads, n_kq_dim, n_val_dim):\n",
    "    \n",
    "    k_dense = layers.Dense(n_kq_dim, activation='linear')\n",
    "    q_dense = layers.Dense(n_kq_dim, activation='linear')\n",
    "    \n",
    "    \n",
    "    \n",
    "    softmax = layers.Softmax(axis=-1)\n",
    "    \n",
    "    val_dense = layers.Dense(n_val_dim, activation='relu')\n",
    "    \n",
    "    def call(inputs, mask):\n",
    "        \n",
    "        k = k_dense(inputs)\n",
    "        q = q_dense(inputs)\n",
    "        \n",
    "        scores = tf.matmul(query, key, transpose_b=True)\n",
    "        weights = softmax(scores, mask)\n",
    "        \n",
    "        vals = val_dense(inputs)\n",
    "        \n",
    "        vals = tf.expand_dims(-1)\n",
    "        weights = tf.expand_dims(-2)\n",
    "        \n",
    "        outputs = tf.reduce_sum(vals * weights)\n",
    "        \n",
    "        \n",
    "        vals *= mask\n",
    "        \n",
    "\n",
    "def transformer_block(n_embed_dim, n_heads, n_dense_dim, dropout_rate):\n",
    "    attn = layers.MultiHeadAttention(num_heads=n_heads, key_dim=n_embed_dim)\n",
    "    dense_net_1 = layers.Dense(n_dense_dim, activation='relu')\n",
    "    dense_net_2 = layers.Dense(n_embed_dim)\n",
    "    layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "    layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "    dropout1 = layers.Dropout(dropout_rate)\n",
    "    dropout2 = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(inputs, masks, include_residual):\n",
    "        mask = tf.logical_and(masks[:, :, None], masks[:, None, :])\n",
    "        attn_output = attn(inputs, inputs, attention_mask=mask)\n",
    "        attn_output = dropout1(attn_output)\n",
    "        if include_residual:\n",
    "            attn_output = inputs + attn_output\n",
    "        # mask outputs. important! without, model learns magic powers (can detect and use verrrrrrry small numbers which are not literally 0)\n",
    "#         attn_output = attn_output * tf.expand_dims(tf.cast(masks, tf.float32), -1)\n",
    "        attn_output = layernorm1(attn_output)\n",
    "        dense_output = dense_net_1(attn_output)\n",
    "        dense_output = dense_net_2(dense_output)\n",
    "        dense_output = dropout2(dense_output)\n",
    "        return layernorm2(attn_output + dense_output)\n",
    "    \n",
    "    return call\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "-Xi5wBCwEVHp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x7ff44457f5e0> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7ff44457f3a0> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    }
   ],
   "source": [
    "def model(batch_size):\n",
    "\n",
    "    # no batch size to start makes it simpler\n",
    "    n_embd = 32\n",
    "    pointwise_feedforward_dim = 8000\n",
    "\n",
    "    vals = keras.Input(shape=[784], name='vals', batch_size=batch_size)\n",
    "    rows = keras.Input(shape=[784], name='rows', batch_size=batch_size)\n",
    "    cols = keras.Input(shape=[784], name='cols', batch_size=batch_size)\n",
    "    mask = keras.Input(shape=[784], name='mask', batch_size=batch_size, dtype=tf.bool)\n",
    "    \n",
    "    print(vals.shape)\n",
    "    print(rows.shape)\n",
    "    print(cols.shape)\n",
    "    print(mask.shape)\n",
    "    \n",
    "    rows_pos_enc = positional_encoding(rows, n_embd//2)\n",
    "    cols_pos_enc = positional_encoding(cols, n_embd//2)\n",
    "    \n",
    "    print(rows_pos_enc.shape)\n",
    "    print(cols_pos_enc.shape)\n",
    "    \n",
    "    pos_enc = tf.concat([rows_pos_enc, cols_pos_enc], axis=-1)\n",
    "    print(pos_enc.shape)\n",
    "    \n",
    "    # produce images of the attention/relevance/contribution for each output.\n",
    "\n",
    "    # make it smaller\n",
    "    # - less heads\n",
    "    # - less dense layers\n",
    "    # - smaller layer sizes'\n",
    "    \n",
    "    # look at standard transformer structure again.\n",
    "    # what is the expected training time?\n",
    "    \n",
    "    # simple setup -> build up.\n",
    "    \n",
    "    # literature / other task at the same time\n",
    "    # have enough to get help from supervisors in discussion\n",
    "    # start writing\n",
    "    \n",
    "    # make n_embd-dimensional input embeddings per pixel from [x, y, v]\n",
    "    # embedding\n",
    "    \n",
    "#     rows = tf.expand_dims(rows, -1)\n",
    "#     cols = tf.expand_dims(cols, -1)\n",
    "    \n",
    "#     m = tf.concat([vals,rows,cols], axis=-1)\n",
    "    \n",
    "    m = layers.Reshape((784, 1))(vals)\n",
    "#     m = layers.Concatenate()([m, rows_pos_enc, cols_pos_enc])\n",
    "    m = layers.Dense(pointwise_feedforward_dim, activation='relu')(m)\n",
    "    m = layers.Dense(n_embd, activation=None)(m)\n",
    "    \n",
    "#     print(m.shape)\n",
    "    \n",
    "    m = m + pos_enc\n",
    "    \n",
    "    m = transformer_block(n_embed_dim=n_embd, n_heads=8, n_dense_dim=pointwise_feedforward_dim, dropout_rate=0.1)(m, masks=mask, include_residual=True)\n",
    "    m = transformer_block(n_embed_dim=n_embd, n_heads=8, n_dense_dim=pointwise_feedforward_dim, dropout_rate=0.1)(m, masks=mask, include_residual=True)\n",
    "#     m = transformer_block(n_embed_dim=n_embd, n_heads=2, n_dense_dim=pointwise_feedforward_dim, dropout_rate=0.1)(m, masks=mask, include_residual=True)\n",
    "#     m = transformer_block(n_embed_dim=n_embd, n_heads=2, n_dense_dim=pointwise_feedforward_dim, dropout_rate=0.1)(m, masks=mask, include_residual=True)\n",
    "    \n",
    "    m = layers.Flatten()(m)\n",
    "    \n",
    "    m = layers.Dense(784, activation='relu')(m)\n",
    "\n",
    "    image = layers.Reshape((28, 28, 1), name='image')(m)\n",
    "    \n",
    "    model = keras.Model(inputs=[vals, rows, cols, mask], outputs=[image])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rOqsXnxifpG",
    "outputId": "e1fee0a6-197b-4ca4-92a0-1d23c1906133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 784)\n",
      "(8, 784)\n",
      "(8, 784)\n",
      "(8, 784)\n",
      "(8, 784, 16)\n",
      "(8, 784, 16)\n",
      "(8, 784, 32)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "rows (InputLayer)               [(8, 784)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cols (InputLayer)               [(8, 784)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_10 (TFOpLambda)  (8, 784, 1)          0           rows[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_11 (TFOpLambda)  (8, 784, 1)          0           cols[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "vals (InputLayer)               [(8, 784)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_10 (TFOpLambda) (8, 784, 8)          0           tf.expand_dims_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_11 (TFOpLambda) (8, 784, 8)          0           tf.expand_dims_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (8, 784, 1)          0           vals[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sin_10 (TFOpLambda)     (8, 784, 8)          0           tf.math.truediv_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.cos_10 (TFOpLambda)     (8, 784, 8)          0           tf.math.truediv_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sin_11 (TFOpLambda)     (8, 784, 8)          0           tf.math.truediv_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.cos_11 (TFOpLambda)     (8, 784, 8)          0           tf.math.truediv_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (8, 784, 8000)       16000       reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_15 (TFOpLambda)       (8, 784, 16)         0           tf.math.sin_10[0][0]             \n",
      "                                                                 tf.math.cos_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_16 (TFOpLambda)       (8, 784, 16)         0           tf.math.sin_11[0][0]             \n",
      "                                                                 tf.math.cos_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(8, 784)]           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (8, 784, 32)         256032      dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_17 (TFOpLambda)       (8, 784, 32)         0           tf.concat_15[0][0]               \n",
      "                                                                 tf.concat_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_8 (Sli (8, 784, 1)          0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_9 (Sli (8, 1, 784)          0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_11 (TFOpLa (8, 784, 32)         0           dense_21[0][0]                   \n",
      "                                                                 tf.concat_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.logical_and_4 (TFOpLamb (8, 784, 784)        0           tf.__operators__.getitem_8[0][0] \n",
      "                                                                 tf.__operators__.getitem_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (8, 784, 32)         33568       tf.__operators__.add_11[0][0]    \n",
      "                                                                 tf.__operators__.add_11[0][0]    \n",
      "                                                                 tf.math.logical_and_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (8, 784, 32)         0           multi_head_attention_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_12 (TFOpLa (8, 784, 32)         0           tf.__operators__.add_11[0][0]    \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (8, 784, 32)         64          tf.__operators__.add_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (8, 784, 8000)       264000      layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (8, 784, 32)         256032      dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (8, 784, 32)         0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_13 (TFOpLa (8, 784, 32)         0           layer_normalization_8[0][0]      \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_10 (Sl (8, 784, 1)          0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_11 (Sl (8, 1, 784)          0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (8, 784, 32)         64          tf.__operators__.add_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.logical_and_5 (TFOpLamb (8, 784, 784)        0           tf.__operators__.getitem_10[0][0]\n",
      "                                                                 tf.__operators__.getitem_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (8, 784, 32)         33568       layer_normalization_9[0][0]      \n",
      "                                                                 layer_normalization_9[0][0]      \n",
      "                                                                 tf.math.logical_and_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (8, 784, 32)         0           multi_head_attention_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_14 (TFOpLa (8, 784, 32)         0           layer_normalization_9[0][0]      \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (8, 784, 32)         64          tf.__operators__.add_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (8, 784, 8000)       264000      layer_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (8, 784, 32)         256032      dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (8, 784, 32)         0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_15 (TFOpLa (8, 784, 32)         0           layer_normalization_10[0][0]     \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (8, 784, 32)         64          tf.__operators__.add_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (8, 25088)           0           layer_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (8, 784)             19669776    flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "image (Reshape)                 (8, 28, 28, 1)       0           dense_26[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,049,264\n",
      "Trainable params: 21,049,264\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "lr_metric = get_lr_metric(optimizer)\n",
    "\n",
    "txformer = model(batch_size)\n",
    "txformer.compile(optimizer=optimizer, loss={ \"image\": keras.losses.MeanSquaredError() })\n",
    "\n",
    "load_saved_model = False\n",
    "if load_saved_model:\n",
    "    txformer.load_weights(f\"./models/{model_name}\")\n",
    "\n",
    "txformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "fzuSaIstGU0A",
    "outputId": "765dc0e1-e241-4363-8f90-c06fe21ea4e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# display:\n",
    "# - before mask\n",
    "# - mask\n",
    "# - after mask\n",
    "# - prediction\n",
    "def gen_image(dataset, n=1):\n",
    "    \n",
    "    dataset = dataset.batch(n)\n",
    "    \n",
    "    for batch in dataset.take(1):\n",
    "        outputs = txformer(batch)\n",
    "        for i in range(n):\n",
    "            print(\"index\", batch[\"index\"][i], \"which is a\", batch[\"label\"][i])\n",
    "            display_uint8_image(batch[\"image\"][i])\n",
    "            display_mask(batch[\"mask\"][i])\n",
    "            display_uint8_image(tf.reshape(batch[\"image\"][i], [28, 28]) * tf.cast(mask_to_image_mask(batch[\"mask\"][i]), tf.uint8))\n",
    "            display_float32_image(outputs[i])\n",
    "        \n",
    "def image_performance_test():\n",
    "    gen_image(dataset_test, n=3)\n",
    "\n",
    "def fit_one_epoch(dataset):\n",
    "    dataset = dataset.map(lambda data: (data, data['image']))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(10000)\n",
    "    txformer.fit(dataset, epochs=1, steps_per_epoch=4000, batch_size=batch_size, callbacks=[WandbCallback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(1239, shape=(), dtype=int64) which is a tf.Tensor(7, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/ElEQVR4nGNgGEqAEVOIhZPh10+silkkzTb8/XueHYuUSPbqv3///v37Vw9hLKsOA8MnVgtPBl11qKqXUnANBX///n354e/fv//+QkELXI7rCUwMJnlSGeIABgaGEEmoqhtX/m/jtohheHD/KVxnytK/f/9unmOqIszAIHTp79+/yciOZJaQkGCDMMO+/f37Vx97mLid/vv371VhmKdRJXmNGf8zXHmLXZLn/3+Ga/Oxmyp55e/fr7OwyzGY/v3796UGdjm5XX//fsoSxC6Z/O/v3yfKOEw99e/v37sSCD4TsqQEAwPDt084dIpPQzUWNZkwcjH8+45DJ0kAAH2Fcm00Z3qhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF444628190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAArElEQVR4nG2SSRIDMQgDhSv//3LnABjhZA6eMqvaECKEVMd8KPxOX1DIYhEIC8vjXBuBVangTmH5Op1yXCfd6BoZ723fCISjlO2YLdxFkmGFHhZwyVvtqWIYiz+O6V0wNBBV3l303zFHwkHRmI/WbmgvtZQ0CG+qxKfvvgU56/xhPK53TZ8Vx8DqyYds1TO7natf0/JH8M+b2hoi6ZBL/V+z79ZMlSWNGcSM4wsv7rZ5KZzS6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF444283D90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAgElEQVR4nGNgGOqAl4Edn/R53LJ/Gf4icw0ZDNGkUXkvUbgtKLy/fxn+/oWrPAlhsDAwMDD8ZWZmYGBgYIZKMjPcR2hLYWD4y7B5jil2GxkkGCRwuh0NXCVWIc2BHMNfhk945P/ilvqHR9sj/Lb+ZXiijOAxokpyM/z7jl87cQAAyDceJFw8d78AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF444051E20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAqUlEQVR4nG2SSwLEMAhCeWTuf+ZZWH9ps4qEoKiSJGueHSFDvziw088yehh4fc9vuAIazUcCZwjjVyG4Qk/tpwIkh5YfLZrlqm/AyyWtVwQ4StW05yYhsgmODCzBfatWTJa1Pb07Lzboq3k71ReYl/PBG420chKSARismtAaSPTmTIQo0CW0a/Evw9OL4Olg788clJnLExHb0pVNtUe9D71uTR8O7tSX/B+D3ADqDZM/3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF414757940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(110, shape=(), dtype=int64) which is a tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABBElEQVR4nM3QIUtDYRTG8X8QVFbEsKIyk8iGRVwdMsV9g32B9SusrZoUhDXNgmmrWgRXTIIatCmCbVe8ekGuDOdzNsM03PddFXzSgR8PnHPg32dh59Y+NsZJhbVQJr0u+nbQD9+VtI6+lPdsKzYpKkPo42ws00sOKp8erl6aDeISULWOWzyWdLUJ0FDg2G5PSooAExfPk2mbux/tAtTVda8wJdujMVItbZmHgbV+puGhU6zJnpYBpto6m3GKd+oHAIVTdYpOMSvtAyy1FeXcGwOpBKxESsqucW4G2Xo0jEuerfekauPx90Pp7Eky6a057Vvmpnct657M+wQFNTP5/Fj6i3wDA8p+YMG2xf8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4443C7340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAsElEQVR4nJ2SSRLEMAgDW/7/nzUHVueQSo0vdgFGC4DBxoANYIirH1T2KjsYZFCXgKXMdxfjvKvuRLEVIQtkdOF7oN10KuXOTA7LSWfAZbL3kSgRyQYhkAbRG/lSUZHFqOWtgNk2nuAig92pVFyK1tcbNMNu4z02X4QX9BLhTS5/h0OKmqdXQ7KFjZr3817yocEfpzZxXJnxnFrJ2MaceA76xMJBz0FpidqpbhyepAc/PhS1fWw6EEEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4546C6160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAi0lEQVR4nM3PIQoCYRCG4ScYBM8gmgy7VatFcA9i1+xxrHoMq4ewiSAIFkFnwaBF/n+Nsm8a+HhnvqH19GGWSypjCMOseAvbzTPSYK6OuLzVhCsMqHIra0ybqx7AOg3uESbQ2Z+bdU7JwbD6jLH4jnrvOg2EI+jmfozHEsoGE0a7Xz3bQRkUxd/OvQA3ICNhlxU5SgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF414757940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAqklEQVR4nG2SQYIEIQgDq+L//7wHbUB3OCggJFGEtiCA7L1thgZkuXMKxgXkqRRP8qynBYe/w3RhAJKMaGrw82zcW32X+zEJEgdKHqWPt1myW1rd05H1g76wIqy74fGOtMo4vIpnyuuGCCpDXebZlJaCeiZbXCO/pGDX1VOMk7VP/8/kZIx8r74nqxfqADB1/V92RnN8x/Y2pDeP9FFlEe4r1ue8X25+Gv4Ad9AA5VDxWhsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF444628190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(9762, shape=(), dtype=int64) which is a tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5UlEQVR4nGNgGMyg4rkATjmJd3/1UQSYkNhRrDfScOo0/XkZwmDlRdfJKed7ZgKE6baBEVUb07p//+5CdLDf+KeBKqn7798LQwjT/t99dhQ5tvp/n6FyHKv+rUHVyPvvXzWU6fHvXwqExQIVcWVgSAxjeMr7lE9aiuHIZlRJfgYGJQYGXQjn50tUyU3zExk+/N+sw8DAoMu6Ei0AGJg1csVkGRgYGAx+n2BmQNXJ8PfGDQjDk/nJX3SdMKD3+0MQLjmGhn9HcMrx3v+PCAEmNEkl+f9HcUoyMLz/gdNYxtwTOOWoBQD7fj+JiquTSQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF444051E20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAtElEQVR4nF2SyxZFIQhCN+f//5k7KAxvg5YPIlHBgME45nGOZ+bYD+ibOEB3/vLgijsMMc3hCN4Ne8ChurcAo/Fia3JeVQzLiGR0ubW9ohJf6F1dhHuo7re7AXwXKgQCq/Q9ETH8BA1tzWaasKpzT+DNqZDlCiwr/xpkBfglejO3EKWzoz/L4TTme66xbIyOQvH11AQ6hqN0jaE7X8swYxix/4sx+0InelPD1E9YHAn1g7XFP9lx4E5XTNgZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4442996D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAj0lEQVR4nGNgGMyggkEAp5zEO7xar5JlIaccw9FkGIcRVY4JmfMPTaPuPwYGQ7gcO6pkPR6NSMCDgSEFVSSIgYHhIgPDYYZtDK+xavz37x/DPwaGf3BJFoQUExMDAwPTGYbf7BjamDVyoazfuJ2D1616EMdhBw14NDLcxyOnj881DP8YMnHKMTKcwKuXGgAAAVceWtQpTm0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF444051E20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAt0lEQVR4nHWSW44EMQgDq5y9/5V7P8iDTM9EUUuAsXEaILQTCAjzAyIHNJOD61jXCYgHeSgm/SE/CEtCi7gKjotkt2jLLLnD521o5dPJBowZ5ptLwKCImNcYdf7udCbzlgC1HB9b4yLjtri78JmlB4Rno5+fva9wpdJLDZMWu8WJ5w3zozPb1KpJEG//k2MOsOaoR1kifSVq2vFB8CEfGSEQXxboo+tmSfvRlxXLonur+qbu1ankP5R3BPcaofHpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4146C5AC0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_performance_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "Qc-55LXO8Dtl",
    "outputId": "47b797e1-67ca-440b-c252-7e961a14c6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/4000 [..............................] - ETA: 4:11 - loss: 6266.4692WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0104s vs `on_train_batch_end` time: 0.0517s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0104s vs `on_train_batch_end` time: 0.0517s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 794/4000 [====>.........................] - ETA: 3:09 - loss: 4779.4297"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_920032/3908081262.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_920032/830877545.py\u001b[0m in \u001b[0;36mfit_one_epoch\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtxformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWandbCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1196\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \"\"\"\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    334\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit_one_epoch(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x7ff44457f5e0> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(8363, shape=(), dtype=int64) which is a tf.Tensor(3, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3UlEQVR4nNWSoW/CQBjFXxfUZncWzVnswvRwgCTT/ScqweKbIJELVKLRJFVlmSu2bCiSYr53NzEKyfUqkHufubzfvXzvkgP+k4Lq8D4LVgAwH36tSvdWLKwm0y5U60+ay4QXr1XB7/5jB4AeDmDhQqBMAZyPPYUfXzsVLk4Ujn1sZGhodrU6AIAthVLEXobor+uh7aXdyU4o7PqzAKY0V/jgwsRa3QhVELjWTZvmnU9Lw6huR9sRoJfCzJOxDNVbYbh/rjNNyXMKPzqeoD7Q0N13+yYvrzZJ0uZn3KVfBSFsQKMBlZUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF454190970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAArElEQVR4nH2SWRKAIAxDE+9/5+dHV5xBBEa6pCHUWBJyLh27hBAxBWELe/gkQJRhvJnRx8juGckEwGQGlrQRGz5jq3ybh8uyFT40iQ7eND+si9NUdOxI8ScnijHGagVVkd5VQr256tiZ29S3RCgao2ELsC6b6a3bR6LDytOnwHCWcodSr5ms8/WrivZYjG+Dfz++u6TnnmhdM3dHUG/ZYg6xkmz6pBpt+u1QUrz6j85Nh9xzqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF41463D850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAe0lEQVR4nNXOsQ3CUAyE4U9vB4ZIG5agpkSpWYJBYB9KWhA7wArPgQZQJOIUCCFxje37bZ35S3WwY54tRFWJ4xuYDfr1o5ancUXboubRDSxTXK1G/T5wal5zGbBDuan259HDTQ8u+Uch2pxOqkbOFhMMPs38obqtL/55B3nNGwiPj+puAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF41463B700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABZklEQVR4nMWSvUvDQBjG39zl7tImbUyLVSgOfkApdCiCYycXXQQFBftPiLP4Fzh0cHdRCiKiIIIIgujS0UFxEHHRgl9tWtM2zaWJg/3wsovPdHc/nuflfTiA/9a0eJUGx8ztvIH2Vnnjq3oXhCnd0KNEiTdfP4/T9wAAgPpQCauKgohLdG2O/DzJPTYVNdQQazdtxhVEQXRKYZXK1nu5Ut1uIy8uzpwZi/ltEyQJI2KeBWKHwl7tEBZcTKjbZYNYpvl0EbCmMgqzAZhmiBO2fJRMqDv+RaCE7ITSVHhiWG45lbfTgPPGKno2x+Bj4nRgMtBQTuUuTo5waj9X7ZLgTGavAZC326FbjuuUxNgXyHkh7XKlENpUSL/RLkxh95ydAF13OXI7GRFinyzRfD5SYLLjQEOEpnUVixhFdYO3PqzKkwjLdWj5sIZss7ZvPvRm9lcZHzV0ldn1Axjo1zeBNJMc+xH+XN+/5XT3s4432wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF41463D580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(4650, shape=(), dtype=int64) which is a tf.Tensor(5, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABHklEQVR4nGNgoD9gROHxK7rcLJb4FnYHQx1z2MZL//7+/fv3701XiAgLQtJkOZSx6bXJ1WeokvEzGT78mvyf4fusn3/jlJ6hmnr87wlxNIuYoLTQ+scMH1/icHXD379/L+Ly0ue/f/++0WBQxyq58O/fv39X1z+3wiYp3f9s7t+/f/99vTvTEC6IEkLBMvb6MqwMDGqYIQQBDttvLNqCy2UMDMKR9xsmMTAwoAQfDLxdreX3CIlf6s2M4PDGf/u7AUky+m8EjOmVfPnvX6gkxNin/5d4bHnxONrA/r8QMwMDw7M1yPbU/fn79+/fv3////379+/fx2gBVfn479+/f//++/v36oYNOlBBeCDoJV4wYDC4L9Ry5wNuX9IBAAARBXbXznXlBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF41463B700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAq0lEQVR4nGWSQRbEIAxCiW/uf+U/CzESu9CmEgLSSpIkvINLSbCQJKqPVLuXW50VvNj24/ItwNEJ5MBmASKYCLEkaqtTwS6vR6yZdK+H0q/Ds+0e8KINMCmLo1udSgykyeMyLs8sbHGMdU2p7tSww8kwTBrwQL653zT4JPXb6I4yIaRa0DdVDby6y8LD6DjLa14/wXiDD85w5B8k433RR+8z+HJbJ8XIj+/yDxPdxl1HSEwHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF41463D850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAcElEQVR4nGNgGMQgbOMlnHLmDH///iPH0ON/T+CUW49X59+/F/HJvtHAIbOQgYHhL0P9cysc8nMZ/jL8+4rP5rt43UVNUIpdmImBgYGB4Rl+vX8YQhjkGVbhVvCX4e9/vCb8xSqqx8DAwLAfv930AAB0lR0hpniXJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF41463D580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABZklEQVR4nMWSvUvDQBjG39zl7tImbUyLVSgOfkApdCiCYycXXQQFBftPiLP4Fzh0cHdRCiKiIIIIgujS0UFxEHHRgl9tWtM2zaWJg/3wsovPdHc/nuflfTiA/9a0eJUGx8ztvIH2Vnnjq3oXhCnd0KNEiTdfP4/T9wAAgPpQCauKgohLdG2O/DzJPTYVNdQQazdtxhVEQXRKYZXK1nu5Ut1uIy8uzpwZi/ltEyQJI2KeBWKHwl7tEBZcTKjbZYNYpvl0EbCmMgqzAZhmiBO2fJRMqDv+RaCE7ITSVHhiWG45lbfTgPPGKno2x+Bj4nRgMtBQTuUuTo5waj9X7ZLgTGavAZC326FbjuuUxNgXyHkh7XKlENpUSL/RLkxh95ydAF13OXI7GRFinyzRfD5SYLLjQEOEpnUVixhFdYO3PqzKkwjLdWj5sIZss7ZvPvRm9lcZHzV0ldn1Axjo1zeBNJMc+xH+XN+/5XT3s4432wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF41463B6D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index tf.Tensor(6772, shape=(), dtype=int64) which is a tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAgElEQVR4nGNgGNRA5/2/DeoILhOKpBLvf58wXJIMDAwM6/FJZuKTZMEnyYBP8gw+yeNEGosK1v75e4gNh5zu37//dyPxWVBk/zP8e4TExbBzAy5JKwaG9zdwSRozMHy4jUvyFpoVKJIvGRh+45S8wMAwA6ckOkCRvOl2CJ9aagEAfWkcePP7yPkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4444AAEE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAu0lEQVR4nG2SQRJDIQhDX/70/ldOFxDB37pwFElIEGxqmXPE51pbRw2e6MG4E1yvNk6KPbxOdqU2LNApk/BFUGWeCqs1SIBAB7poUqKqP61HTQaWWYb9FjG3CY3vmI5fT/zXWPZY9wIX7R/9Vw+ux93RCzDWX928wulm/qvXJ12QkQWgG7e5dptFoepflHe5zvn03SoveUuoRx8soXG96zfp+qceUHj6omt0wdIZ0ikQIowflGHS6rNA8AUKCeNC6scdQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4546C3EE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAb0lEQVR4nGNgGNzg/T8GdQSPCVVSkIkhDKfOPwx/kHhMGPJTKXQZdjsZUnHL/v2DU8oPn6lrcetjYGBgYNiNXxon+MPgi8RDCaF0BgaGG2QZWoLGRzH25R+G6zh16jIw5OMxGDUQ0OLzEDFOoxQAALfaEzOxZEewAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF41463B790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABZklEQVR4nMWSvUvDQBjG39zl7tImbUyLVSgOfkApdCiCYycXXQQFBftPiLP4Fzh0cHdRCiKiIIIIgujS0UFxEHHRgl9tWtM2zaWJg/3wsovPdHc/nuflfTiA/9a0eJUGx8ztvIH2Vnnjq3oXhCnd0KNEiTdfP4/T9wAAgPpQCauKgohLdG2O/DzJPTYVNdQQazdtxhVEQXRKYZXK1nu5Ut1uIy8uzpwZi/ltEyQJI2KeBWKHwl7tEBZcTKjbZYNYpvl0EbCmMgqzAZhmiBO2fJRMqDv+RaCE7ITSVHhiWG45lbfTgPPGKno2x+Bj4nRgMtBQTuUuTo5waj9X7ZLgTGavAZC326FbjuuUxNgXyHkh7XKlENpUSL/RLkxh95ydAF13OXI7GRFinyzRfD5SYLLjQEOEpnUVixhFdYO3PqzKkwjLdWj5sIZss7ZvPvRm9lcZHzV0ldn1Axjo1zeBNJMc+xH+XN+/5XT3s4432wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF4444AAC70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7ff44457f3a0> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    }
   ],
   "source": [
    "image_performance_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Po6NnXshwaCj"
   },
   "outputs": [],
   "source": [
    "fit_one_epoch(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_performance_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhSfq8VcPOEW"
   },
   "outputs": [],
   "source": [
    "fit_one_epoch(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DD2oRg5MMrmK"
   },
   "outputs": [],
   "source": [
    "image_performance_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNhU_P0QPWPt"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not load_saved_model:\n",
    "    txformer.save_weights(f\"./models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_image(dataset_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)\n",
    "fit_one_epoch(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    gen_image(dataset_test, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not load_saved_model:\n",
    "    txformer.save_weights(f\"./models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST conditional prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
