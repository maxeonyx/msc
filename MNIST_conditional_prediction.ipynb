{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx9vGgfSkcpL"
   },
   "source": [
    "\n",
    "# Conditional autoregressive transformer\n",
    "\n",
    "Train a transformer to predict missing pixel from mnist \n",
    "\n",
    "### plan\n",
    "\n",
    "* note to try padded mnist (relative encoding might require black padding???)\n",
    "* probably don't need positional encoding?\n",
    "* create transformer model\n",
    "* masking \n",
    "* randomised masking\n",
    "* relative position encoding (x - current_x, y - current_y, val)\n",
    "* train to predict when current pixel missing\n",
    "* train to predict when 10% are missing\n",
    "* train to predict when 90% are missing\n",
    "* train to predict when 99% are missing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QOGwXO1EUsAz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaxeonyx\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">summer-blaze-13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/maxeonyx/conditional-mnist\" target=\"_blank\">https://wandb.ai/maxeonyx/conditional-mnist</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/maxeonyx/conditional-mnist/runs/1haehak2\" target=\"_blank\">https://wandb.ai/maxeonyx/conditional-mnist/runs/1haehak2</a><br/>\n",
       "                Run data is saved locally in <code>/am/monterey/home1/clarkemaxw/conditional-mnist/wandb/run-20210917_175354-1haehak2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "wandb.init(project='conditional-mnist', entity='maxeonyx')\n",
    "config = wandb.config\n",
    "config.learning_rate = 0.01\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def display_uint8_image(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = image[:, :, 0]\n",
    "    if tf.is_tensor(image):\n",
    "        image = image.numpy()\n",
    "    display(Image.fromarray(image, \"L\"))\n",
    "\n",
    "def display_float32_image(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = image[:, :, 0]\n",
    "    if tf.is_tensor(image):\n",
    "        image = image.numpy()\n",
    "    display_uint8_image(image.astype(np.uint8))\n",
    "\n",
    "\n",
    "model_name = \"txformer-bigger-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idxs_to_onehots(idxs):\n",
    "    onehots = tf.one_hot(idxs, depth=784, dtype=tf.bool, on_value=False, off_value=True)\n",
    "    return onehots\n",
    "\n",
    "# takes 2D tensor (batch and index list)\n",
    "def idxs_to_multihot(idxs):\n",
    "    onehots = idxs_to_onehots(idxs)\n",
    "    multihot = tf.math.reduce_all(onehots, axis=len(onehots.shape)-2)\n",
    "    return multihot\n",
    "\n",
    "def idxs_to_attention_mask(idxs):\n",
    "    multihot = idxs_to_multihot(idxs)\n",
    "    attn_mask = tf.logical_and(multihot[:, :, None], multihot[:, None, :])\n",
    "    return attn_mask\n",
    "\n",
    "def mask_to_image_mask(masks):\n",
    "    image_masks = tf.reshape(masks, [-1, 28, 28])\n",
    "    return image_masks\n",
    "\n",
    "def img_to_tuples(img):\n",
    "    height, width, chan = img.shape\n",
    "    vals = tf.reshape(img, [width*height, chan])\n",
    "    vals = tf.cast(vals, tf.float32)\n",
    "    rows = tf.range(height, dtype=tf.float32)\n",
    "    cols = tf.range(width, dtype=tf.float32)\n",
    "    cols, rows = tf.meshgrid(rows, cols)\n",
    "    rows = tf.reshape(rows, [-1, 1])\n",
    "    cols = tf.reshape(cols, [-1, 1])\n",
    "    tups = tf.concat([vals, rows, cols], axis=-1)\n",
    "    return tups\n",
    "\n",
    "def random_mask():\n",
    "    idxs = tf.range(784)\n",
    "    idxs = tf.random.shuffle(idxs)\n",
    "    n = tf.random.uniform(shape=[], maxval=784, dtype=tf.int32)\n",
    "    idxs = idxs[:n]\n",
    "    return idxs_to_multihot(idxs)\n",
    "\n",
    "def random_offset():\n",
    "    return tf.random.uniform(shape=[2], maxval=28, dtype=tf.int32)\n",
    "    \n",
    "def display_mask(mask):\n",
    "    image_mask = np.array(mask_to_image_mask(mask[np.newaxis, :]), np.uint8)[0]\n",
    "    image_mask = image_mask * 255\n",
    "    display_uint8_image(image_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: <_OptionsDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {image: (28, 28, 1), label: (), tuples: (784, 3), mask: (784,), offset: (2,), target_px: (1,)}, types: {image: tf.uint8, label: tf.int64, tuples: tf.float32, mask: tf.bool, offset: tf.int32, target_px: tf.float32}>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow.data data generator\n",
    "\n",
    "from tensorflow import data as td\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def make_dataset_generator(split='train'):\n",
    "    \n",
    "    dataset = tfds.load('mnist', split=split, shuffle_files=True)\n",
    "    \n",
    "    print(\"Start:\", dataset)\n",
    "    \n",
    "    # shuffle the digits\n",
    "    dataset = dataset.shuffle(60000)\n",
    "    # repeat the dataset infinitely\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    def map_just(component, func):\n",
    "        def do(data):\n",
    "            data[component] = func(data[component])\n",
    "            return data\n",
    "        return do\n",
    "    \n",
    "    def map_add(component, func):\n",
    "        def do(data):\n",
    "            data[component] = func()\n",
    "            return data\n",
    "        return do\n",
    "    \n",
    "    def add_tuples(data):\n",
    "        data['tuples'] = img_to_tuples(data['image'])\n",
    "        return data\n",
    "    \n",
    "    def offset_tuples(data):\n",
    "        offset = tf.cast(data['offset'], tf.float32)\n",
    "        data['tuples'] = tf.stack([\n",
    "            data['tuples'][:, 0],\n",
    "            data['tuples'][:, 1] + offset[0],\n",
    "            data['tuples'][:, 1] + offset[1],\n",
    "        ], axis=-1)\n",
    "        return data\n",
    "    \n",
    "    def add_target_px_val(data):\n",
    "        offset = data['offset']\n",
    "        data['target_px'] = tf.cast(data['image'][offset[0],offset[1]], tf.float32)\n",
    "        return data\n",
    "    \n",
    "    dataset = dataset.map(add_tuples)\n",
    "    # data['image'][:, 0] are vals\n",
    "    # data['image'][:, 1] are rows\n",
    "    # data['image'][:, 2] are cols\n",
    "    dataset = dataset.map(map_add('mask', random_mask))\n",
    "    dataset = dataset.map(map_add('offset', random_offset))\n",
    "    dataset = dataset.map(offset_tuples)\n",
    "    dataset = dataset.map(add_target_px_val)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "make_dataset_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qr9uxXbhzo9g",
    "outputId": "158a591e-46a3-4307-e49a-12b0052586f3"
   },
   "outputs": [],
   "source": [
    "# reformat MNIST data into (x, y, val) tuples\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(\n",
    "    path='mnist.npz'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# [row, col, value] tuples\n",
    "def mnist_to_rcv_tuples(dataset):\n",
    "    # positional encoding is just indices as floats\n",
    "    x_idx = np.arange(dataset.shape[1]).astype(np.float32)\n",
    "    y_idx = np.arange(dataset.shape[2]).astype(np.float32)\n",
    "\n",
    "    # make 28x28 cartesian product and repeat N times\n",
    "    idxs = np.transpose([np.repeat(y_idx, len(x_idx)),np.tile(x_idx, len(y_idx))])\n",
    "    \n",
    "    all_idxs = np.tile(idxs.reshape(-1), dataset.shape[0]).reshape(-1,784,2)\n",
    "    # pixel data as float between 0 and 255\n",
    "    all = dataset.astype(np.float32).reshape(-1, 784, 1)\n",
    "    \n",
    "    big = np.dstack((all_idxs, all))\n",
    "    \n",
    "    return big\n",
    "\n",
    "def random_offset_tuples(dataset, dataset_y, min_masked_px=0, max_masked_px=784, random_squares=True):\n",
    "    tuples = mnist_to_rcv_tuples(dataset)\n",
    "    offsets = np.random.randint(0, 28, [dataset.shape[0], 2])\n",
    "    mask_sizes = np.random.randint(min_masked_px, max_masked_px, [dataset.shape[0]])\n",
    "    tuples[:, :, 0] -= offsets[:, 0, np.newaxis] # row (y) offset\n",
    "    tuples[:, :, 1] -= offsets[:, 1, np.newaxis] # col (x) offset\n",
    "    target_idxs = offsets[:, 0] * 28 + offsets[:, 1]\n",
    "    \n",
    "    # permutations \n",
    "    masks = np.ones([dataset.shape[0], 784], dtype=np.bool_)\n",
    "    for i in range(dataset.shape[0]):\n",
    "        # shuffle tuples\n",
    "        tup_shuffle_idxs = np.random.permutation(784)\n",
    "        tuples[i] = tuples[i, tup_shuffle_idxs]\n",
    "        \n",
    "        idxs = np.random.permutation(784)\n",
    "                           \n",
    "        n_mask_px = np.random.randint(min_masked_px, max_masked_px)\n",
    "        # n mask plus always mask the target idx\n",
    "        mask_idxs = np.concatenate([idxs[:n_mask_px], target_idxs[i:i+1]])\n",
    "        \n",
    "        if random_squares:\n",
    "            # random square cut out of the masks\n",
    "            start_row, start_col = np.random.randint(0, 28, [2])\n",
    "            end_row = np.random.randint(start_row, 28)\n",
    "            end_col = np.random.randint(start_col, 28)\n",
    "            height, width = abs(end_row - start_row), abs(end_col - start_col)\n",
    "            square_row_idxs, square_col_idxs = np.indices([height, width])\n",
    "            square_row_idxs += start_row\n",
    "            square_col_idxs += start_col\n",
    "            square_mask_idxs = square_row_idxs * 28 + square_col_idxs\n",
    "            square_mask_idxs = square_mask_idxs.reshape(-1)\n",
    "            \n",
    "            mask_idxs = np.concatenate([mask_idxs, square_mask_idxs])\n",
    "            \n",
    "        masks[i:i+1] = idxs_to_multihot(mask_idxs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    target_pxs = dataset[np.arange(dataset.shape[0]), offsets[:, 0], offsets[:, 1]].astype(np.float32)\n",
    "    return {\n",
    "        \"digits\": tf.cast(dataset_y, tf.uint8),\n",
    "        \"imgs\": tf.cast(dataset, tf.uint8),\n",
    "        \"tuples\": tf.cast(tuples, tf.float32),\n",
    "        \"offsets\": offsets,\n",
    "        \"target_pxs\": target_pxs,\n",
    "        \"target_idxs\": target_idxs,\n",
    "        \"masks\": tf.cast(masks, tf.bool)\n",
    "    }\n",
    "\n",
    "def load_to_tensorflow(file):\n",
    "    dataset = np.load(file)\n",
    "    return { k: tf.constant(v) for k, v in dataset.items() }\n",
    "    \n",
    "load_saved_dataset = True\n",
    "if not load_saved_dataset:\n",
    "    train_dataset = random_offset_tuples(x_train, y_train)\n",
    "    test_dataset = random_offset_tuples(x_test, y_test)\n",
    "    # give very few pixels\n",
    "    full_masks_dataset = random_offset_tuples(x_test, y_test, min_masked_px=770, max_masked_px=784, random_squares=True)\n",
    "    np.savez(\"train_dataset.npz\", **train_dataset)\n",
    "    np.savez(\"test_dataset.npz\", **test_dataset)\n",
    "    np.savez(\"full_masks_dataset.npz\", **full_masks_dataset)\n",
    "else:\n",
    "    train_dataset = load_to_tensorflow(\"train_dataset.npz\")\n",
    "    test_dataset = load_to_tensorflow(\"test_dataset.npz\")\n",
    "    full_masks_dataset = load_to_tensorflow(\"full_masks_dataset.npz\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits shape (60000,)\n",
      "imgs shape (60000, 28, 28)\n",
      "tuples shape (60000, 784, 3)\n",
      "offsets shape (60000, 2)\n",
      "target_pxs shape (60000,)\n",
      "target_idxs shape (60000,)\n",
      "masks shape (60000, 784)\n",
      "index 0 which is a tf.Tensor(5, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D804FD9A0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA20lEQVR4nGWT0Y7EMAgDx2j//5dnH4Ake1dVTVXA2IaCCooAOEe/CKgbts8OfSIQmWcGIhJiMIaBhYBk7/1ohGDHYyyAhAQOvoKRggzFEIiZPEilwfaycc3q8fRdga29CXBqm1LLg2oqF3dSE6R8W7ZlOSR/Wy4JQayu85ZmRNGOXDHrTnNKPVQHxPRkut68PWc2QErPmMbmNYjdAV8ph2CBOWKyKxMB68cfg+nJqlQbcinFI7Z1tmXcZrMLH/9oudnmn0MPPOULmpnW8Kg0wvHnlN2ZvX/BbAryBcZtru4wtWhWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0EB015A760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkUlEQVR4nGNgGMyAWYhBiKFjvdSy/wz1mLJ/GRj+MjAw/P3E4IBN8i8DQyxDEIM6VpO3MXzEaSs3gzZ5zt3HRJ4+BgaGhwtwywV++ItHp+4uhr/TcMoKxDL83Y1H99+feOQQTDSPPf3LwPBrGy5df/8y+OE08hi6WQwMDEIwBieGlDkOg5gYGBgYAv/iCxiqAwBJ2iPB90o+gAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80464A90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1 which is a tf.Tensor(0, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D804FD640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAASklEQVR4nGNgwAT/cdC4wf//RCnDoRlD63+89v8nwk2YWolzHaYqZLeQ60OSbWUiQR8xjsKnBqccrXyLzXSc4U4dq/6jcknQiQwAZFMg4sTfbUAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D804FD0D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAMklEQVR4nGNgGAzgL17ZP6QbyEW+VjzgHVVNoxwUEKtwFx65h7gkDEhwCaWAuvFEIwAAvvAHJXSbl/MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D804FD9A0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2 which is a tf.Tensor(4, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nGNgGArA+YU6AwMDAwMTAwMDg10gqqTpGQaEpEMQihyTohwjgndnMYqk9L9FSDqZUE2dw3AbIaknjirJz7AbIenFiSInrsjwFCGpznAVWbJH/NZnCIuFgYGBgeE0XIbPI8aNofkDsqQQAwODPpOzDFs00/eTP1nOQlUyMjAwTEv/8IiBQY/xz7drJ88cfPlEkI0BoTProRUDA8OjjddOMDAwMKSJ3mPACVb+64QxmbBIb8AnyYBHklEVj+R/JjySDJb4jMVj5/b/OB1IJQAAg3ksR3QPgSAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80412F40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1UlEQVR4nF2SSXLAQAgDW1P+/5c7B5aQXGyDQUiCGIEgANlXJKAoKFSF0t/pRwBj9S5Oly9kVwUQQbygnUMfmAYIaIBobPgZ0cGiZgeZypkmOh01A2teEQD4ikUG1hjcTPcU82G/+sofx6MWpfKGJxItHUZC+CQiM2q8klRnujeEYDb+Iu6q2rcyGF6twUCSgSkf14Ve6kTL/sCdqH/pCtvGvozjL398YX1S+WcZ8Lrq7nVI+8b6HNQGyFtlWOJbYsR3ju7CUqaYM3SYh8n7e/a9+t73DyxH1KjJQcaYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80464E50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmUlEQVR4nGNgGBLghToSJxBNcgsSuw5NbuYlDQTnDqqc9D8og4mBgYGBaTGK5FMGZEklVJ3HmCwQnAoM18oidKqjyiz+d+MxgjefwRnO5mNg+PEPVXEohJrA8JGBYTOq1LS/bxnOn//779eHY/0MMqwMv1Bkyxk2MmzcCOWkoXsbFXTik7TEI/cPjxwBkEC+Vjzg30yaGIsAADPRJErHCwHIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80464A90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 3 which is a tf.Tensor(1, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVR4nGNgGPyg5u9/e1xyCV9+/7WDMJkwJOXZcRvq8ub3ZXkO7HI2T37/jsOlcfbfv3txyYn8/f3aCYecwtm/v+twacz4/XcHPw65gA+/D4rjMvTv37/zcRk6/ffv3+o45Azu/v69BpfGV79/H+HBJfn39+9IXHLz///9K4/Lxid/v/fgCHAGh99/76CLYcYnNskbx/ApoyoAAGeYO0QsY6cRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D804FD640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2ElEQVR4nF2SSRLAIAgEe/j/nzsHEK2kKkbDMgvGCNyF0B9DAaHPkIC9FylE0rEOpOuJMUxhQHJgchHuMylE9n3XuInGLY+kCwEoEW2ikDhohNRR0JxXIogr/AKdbZsADXw6TEzr0A+jdw2hK5UhMrqTPG0jj49RwFSfHSV6iIfRn+vBtZBY3Won0bCaMcHuMOlLWV3J14gLUnGb5bRPOqeeselMBUIkz836zVyo3MtwaCctkCL7c5xAzGPzzDLbtVkU2E4+oZniMf4Z9oGPqXF5bsXcdgXhA7M3jTFKLpWiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80464E50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAm0lEQVR4nGNgGPyghuG/PU7JL78Z7CAsJgy5eh7chrq8YWCQxyFn84ThN06Ns//+3YtLTuTvbwYnHHIKZxl+1+HSmMHAsIMfh1wAw++DuPQpMPz9Ox+XJAPDbwZ1HDIGDL9xe5HhN8MRnEH3l4EhElWEEcH8/4+BGVUSHisGT/796udAlWSBMQTEGTjRLUKOzzu43crwF58kNQEALx0k0yx+GJAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80464E50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits shape (10000,)\n",
      "imgs shape (10000, 28, 28)\n",
      "tuples shape (10000, 784, 3)\n",
      "offsets shape (10000, 2)\n",
      "target_pxs shape (10000,)\n",
      "target_idxs shape (10000,)\n",
      "masks shape (10000, 784)\n",
      "index 0 which is a tf.Tensor(7, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVR4nGNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kJuHrgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DBFA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAv0lEQVR4nHWSQRIEIQgDO5T//3L2gIA6tXNwQCCEoDAIjAwgI5w2KgPaqAABIBAyUjogucE+dfnFTmV36aMLBBaDkazQqrIJed/IC8DqYEEKO9niblkA3pTv24ctgH2yvIJ79k9x9IyqykyVUrRX3r+qXX40Eak07warWo5Ks414CF5CxQbKnVZGv4SDixoxf0MoBfYsE+JdyDGjwjXJxAtl2PpOEOAAt6zORzsbt3yLdviPtuPKKHaHHqc0NvgHW3BYQeWgadoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DBB20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAvElEQVR4nGNgGDaAEcaY/2Ppizs4FP379+/fx2MMx44xHDt2jMEETdajaPHjfw///fv36+m/fz0QMRaY5I4dDAxOZ0wZGH7cui50D6czgv9eFMIlJ8bwPxjKZMKQzP7HeBOXRuuf/+xgbBZ0SS92nI5hYDjLYIVTru4fbn3evz/glBO+y7AMlxzz6X+3cWpU+/fPF5ec/AOGYkZckq0MGHGFAJ/+/UOVRArbSh6Gu19QJFGC76LzO5zGYgAAX809SeOcNxwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DBFD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1 which is a tf.Tensor(2, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4nGNgoAlgRDBLOPVCGKYfX4xN2cq/f//+/fv3lhwOuat9G/7+rcKUM/n195ICDwPbub89mJK+vy9JMjAwVP3464jFWHkhBgYGhot/sUoyMDAwMJR+/3uMC4ecz/e/z+2R+EwormJjWHkQh8YN3/7O58EhJ/nq70tlXK459vdvLy45vx9/9+IyVPgEHo1tf/+uxaWR4cffv5LoYixIbKHfDAwMH3+z8jMIFjIw/C3/hix5iYGBgWH1c/FwCPdFKzwlrPNHqPrzj2HTGYYjxxHJpIyVgUE7nIFh3gOGdddxuWyAAQCfcVM+FkfDOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DBA00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXElEQVR4nJ2SQQ7AIAgEN/3/n6cHkgYBLcJBwYXBECQz3Cn4XC16jtgnZcO7EN8aRriTirGvoAW/qz3jTsozDvocPatt1NQpv0Ogjd+tmYWeQ42kuZGnLznNZ/ACbNYy0iAKdmkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DB8E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAKElEQVR4nGNgGGDwlyxdv7CIMcEYjAyS5LpmFNAMrCOs5C+ZqYFOAAAKfgS8jCod8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DB9D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2 which is a tf.Tensor(1, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiElEQVR4nGNgGARA7V8unM2ELmn47ylune0fccvpfpmG4KAbq861ErfOU/e5ccop/LuBxEMz1p7hNW5JXYYunKZavj3LgVOns9CNHzgl9f+vwWmqxIvrKHwUnQliJ3BLyjO8x2kqw5N/Tjh12orj1sfQ++8sMy6dXF4Ma/7i0sh6bAMXHnPpBAAPgx/ARH1j7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DBC10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAeUlEQVR4nI2RSxKAIAxDo/e/83PhAE1bxA4OEPKpIEkoFGne1XuO0emUyZ1IbWMYw61NVnXknRvcghdFEldwzlYwQY87ZC5xhQN9/TlmQXsleCunV8kWez7NqlV8POq8lU4UAxr1+sIhPxrftOCairTACGfyobY76gH6pGKh3Fpu0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DB820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAJUlEQVR4nGNgGPTgzwDYyU2uxsN45P7h1clBrpX4wHVaGDpSAQDlGAOovrtGhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DBA30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 3 which is a tf.Tensor(0, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA70lEQVR4nMXQsWoCQRQF0JvBNNrGdjcgIR8gJJVrqRZCfkMkgn+QlEIIAcHaHzClVWySJkmXSgxqIbKCbcrLxRSbNe7M2uqr7syZefAecOTK9fTp78MLUs2ds9nJ+b71OPMfWzdXAALz9ZrSVCQpclp0bbiRpPVckmPlmUh268Ed2bDsfEVx2skCfsif9qkzxcsZAOCWYsHGDy+K/nuM2zmNuV5E6cQYc5/4+UDG0W07iTFfXlGhl45PJGelKGeQrOElgPFb8vJbqtWW0kYpG2qT8W7ZtdEP/zAcFbI2IniMsOkIAKD6zEGl6qXjweoXXfV/5XmKZEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DBB20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAvUlEQVR4nG2SSZbFIAwDS37//ldWLzwBHTYJRvJQIAMgo/mbtdGPFWBAqaxvb0ICVaxkqpQOg3CbLEOF4JeGp6wMyHc36waQnBn+6TZyxeXOm77HVMmIy6Oa1Vn+KvVkV+AaGrBy3HYF55B2A8qapat5sEftBl9mTzcyIk46WpORj0PT/POSzB5qidl1vTGXlXOeNP08k5tjdA9i/Odhw1LRXXEMLyeitnrRfJa8IZS88KOPd777GDxnimr4D4EKXDuUnXcKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DB8B0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3ElEQVR4nMXRMU4CURSF4RPFBlppZ0yMK7AGSqRgJWQKdkBrYkfiCmgspDJUQEeC7AAS2qGy0u7PCRQyE+fhWOKtbt6X+3LPe9I/V+3ZisvwDtQrsfrij1vngF+S5m9mAIPus5NKbpMLSfr4iq3LcK61NdKwq4EI7WaH0WNVilM++1fFFMLTa0lSgrgN8T069ssTtPN+tfeogE/kayRYxcl1ZvXWDqdRgJmC1ChGWWfptsBbkHNjdzqy9/aP1Y7VBwMyMAwxFt8Pn85UDVFNCVDpZ495bT9EJXiuOgDZqG4X8xttmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D803DBEB0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits shape (10000,)\n",
      "imgs shape (10000, 28, 28)\n",
      "tuples shape (10000, 784, 3)\n",
      "offsets shape (10000, 2)\n",
      "target_pxs shape (10000,)\n",
      "target_idxs shape (10000,)\n",
      "masks shape (10000, 784)\n",
      "index 0 which is a tf.Tensor(7, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVR4nGNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kJuHrgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80464E50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAJElEQVR4nGP4z0BLQEvTqW42bYNi8AB6+vM/3W3ECTAdQaKzALksCPgPtpfvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80464E50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAGElEQVR4nGNgGAUw4DzQDhgF9AWVpCkHAKfDAL1syFHEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D804FD730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1 which is a tf.Tensor(2, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4nGNgoAlgRDBLOPVCGKYfX4xN2cq/f//+/fv3lhwOuat9G/7+rcKUM/n195ICDwPbub89mJK+vy9JMjAwVP3464jFWHkhBgYGhot/sUoyMDAwMJR+/3uMC4ecz/e/z+2R+EwormJjWHkQh8YN3/7O58EhJ/nq70tlXK459vdvLy45vx9/9+IyVPgEHo1tf/+uxaWR4cffv5LoYixIbKHfDAwMH3+z8jMIFjIw/C3/hix5iYGBgWH1c/FwCPdFKzwlrPNHqPrzj2HTGYYjxxHJpIyVgUE7nIFh3gOGdddxuWyAAQCfcVM+FkfDOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80412F40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAJUlEQVR4nGNgoAD8p5oimgJyXDDwriYBDCnH0gP8x8slWg5NAQBFkgj4R4Sf/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80412F40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFUlEQVR4nGNgoDUoobkNo2AU0AMAAEbDAHUIfaHRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80464E50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2 which is a tf.Tensor(1, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiElEQVR4nGNgGARA7V8unM2ELmn47ylune0fccvpfpmG4KAbq861ErfOU/e5ccop/LuBxEMz1p7hNW5JXYYunKZavj3LgVOns9CNHzgl9f+vwWmqxIvrKHwUnQliJ3BLyjO8x2kqw5N/Tjh12orj1sfQ++8sMy6dXF4Ma/7i0sh6bAMXHnPpBAAPgx/ARH1j7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80412250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAIUlEQVR4nGNgIBH8J1XDwIAh4kxcYKCcj8PeoROatHQpAF1QBftXCfoXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D804FDE80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAABPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80412F10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 3 which is a tf.Tensor(0, shape=(), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA70lEQVR4nMXQsWoCQRQF0JvBNNrGdjcgIR8gJJVrqRZCfkMkgn+QlEIIAcHaHzClVWySJkmXSgxqIbKCbcrLxRSbNe7M2uqr7syZefAecOTK9fTp78MLUs2ds9nJ+b71OPMfWzdXAALz9ZrSVCQpclp0bbiRpPVckmPlmUh268Ed2bDsfEVx2skCfsif9qkzxcsZAOCWYsHGDy+K/nuM2zmNuV5E6cQYc5/4+UDG0W07iTFfXlGhl45PJGelKGeQrOElgPFb8vJbqtWW0kYpG2qT8W7ZtdEP/zAcFbI2IniMsOkIAKD6zEGl6qXjweoXXfV/5XmKZEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D804FD670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAL0lEQVR4nGNgYGBg+M+ADv5jFx4oMHhcMngAKWGCWy2NQpYEY4lUSrFDiTCAgBIACyEL9WkTpM8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80412FD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAHUlEQVR4nGNgGAXDHzzDKfObNhZS39i1VDeRZAAAd78Diq9z22QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F0D80412FD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dataset_summary(d):\n",
    "    for name, v in d.items():\n",
    "        print(name, \"shape\", v.shape)\n",
    "\n",
    "    for i in range(4):\n",
    "        print(\"index\", i, \"which is a\", d[\"digits\"][i])\n",
    "        display_uint8_image(d[\"imgs\"][i])\n",
    "        display_mask(d[\"masks\"][i])\n",
    "        display_uint8_image(tf.constant(d[\"imgs\"][i]) * tf.cast(mask_to_image_mask(d[\"masks\"][np.newaxis, i])[0], tf.uint8))\n",
    "\n",
    "dataset_summary(train_dataset)    \n",
    "dataset_summary(test_dataset)\n",
    "dataset_summary(full_masks_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# f_masks = np.array([29, 31, 754, 752])\n",
    "# print(f_masks)\n",
    "# f_masks = idxs_to_multihot(f_masks)\n",
    "# print(f_masks)\n",
    "# display_mask(f_masks)\n",
    "\n",
    "# t_masks = np.indices([784])\n",
    "# print(t_masks)\n",
    "# t_masks = idxs_to_multihot(t_masks)\n",
    "# print(t_masks)\n",
    "# display_mask(t_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fNNZdCnizvLU",
    "outputId": "8472bdb9-66be-4f7a-8b8a-66ac282bb160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784, 3) (10000, 2) (10000,)\n",
      "tf.Tensor(\n",
      "[[ 18. -15.   0.]\n",
      " [  0. -20.   0.]\n",
      " [ 13.  -7. 240.]\n",
      " ...\n",
      " [  6.  -5.  83.]\n",
      " [ -3.  -9.   0.]\n",
      " [  2. -22.   0.]], shape=(784, 3), dtype=float32)\n",
      "tf.Tensor([ 5 23], shape=(2,), dtype=int64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_dataset[\"tuples\"].shape, test_dataset[\"offsets\"].shape, test_dataset[\"target_pxs\"].shape)\n",
    "print(test_dataset[\"tuples\"][0])\n",
    "print(test_dataset[\"offsets\"][0])\n",
    "print(test_dataset[\"target_pxs\"][0])\n",
    "\n",
    "# actual training dataset is 784 x,y,v tuples, but with the spatial location changed so the the pixel to predict is in the center\n",
    "# and the pixel value to predict removed (via masking)\n",
    "\n",
    "# then, can mask more and more stuff and compare performance\n",
    "\n",
    "# we can also use the model in an \"iterative\" mode to generate images, in an arbitrary order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "W3nKMxnPe6cc"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5. 3.]\n",
      " [1. 4.]\n",
      " [1. 6.]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.11920292 0.         0.880797  ]\n",
      " [0.18242551 0.         0.81757444]\n",
      " [0.5        0.         0.5       ]], shape=(3, 3), dtype=float32)\n",
      "(1, 3, 2)\n",
      "(3, 3, 1)\n",
      "(3, 3, 2)\n",
      "tf.Tensor(\n",
      "[[[0.5960146  0.35760877]\n",
      "  [0.         0.        ]\n",
      "  [0.880797   5.2847824 ]]\n",
      "\n",
      " [[0.91212755 0.54727656]\n",
      "  [0.         0.        ]\n",
      "  [0.81757444 4.9054465 ]]\n",
      "\n",
      " [[2.5        1.5       ]\n",
      "  [0.         0.        ]\n",
      "  [0.5        3.        ]]], shape=(3, 3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0.5960146  0.35760877]\n",
      "  [0.         0.        ]\n",
      "  [0.880797   5.2847824 ]]\n",
      "\n",
      " [[0.91212755 0.54727656]\n",
      "  [0.         0.        ]\n",
      "  [0.81757444 4.9054465 ]]\n",
      "\n",
      " [[2.5        1.5       ]\n",
      "  [0.         0.        ]\n",
      "  [0.5        3.        ]]], shape=(3, 3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.4768116 5.642391 ]\n",
      " [1.729702  5.452723 ]\n",
      " [3.        4.5      ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# attention manual calculation example\n",
    "\n",
    "m = tf.constant([[5, 3], [1, 2]], dtype=tf.float32)\n",
    "val = tf.constant([[5, 3], [1, 4], [1, 6]], dtype=tf.float32)\n",
    "print(val)\n",
    "mask = tf.constant([1, 0, 1], dtype=tf.float32)\n",
    "wei = tf.constant([[1, 2, 3], [0.5, 2, 2], [1, 3, 1]], dtype=tf.float32)\n",
    "wei = keras.layers.Softmax()(wei, mask)\n",
    "print(wei)\n",
    "val = tf.expand_dims(val, -3)\n",
    "print(val.shape)\n",
    "wei = tf.expand_dims(wei, -1)\n",
    "print(wei.shape)\n",
    "x = val * wei\n",
    "print(x.shape)\n",
    "print(x)\n",
    "mask = tf.expand_dims(mask, -1)\n",
    "# x = x * mask\n",
    "print(x)\n",
    "x = tf.reduce_sum(x, axis=-2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Maths\n",
    "\n",
    "Dimensions $N$, $D$, $E$ and $B$.\n",
    "\n",
    "- $N = 784$ is the number of inputs.\n",
    "- $D$ is the width of the _key_ $K$ and _query_ $Q$ vectors.\n",
    "- $E$ is the width of the _value_ vectors $V$.\n",
    "- There is also a (or multiple) batch dimension(s) $B$.\n",
    "\n",
    "$K$ is $B \\times N \\times D$ dimensional.\n",
    "$Q$ is $B \\times N \\times D$ dimensional.\n",
    "$V$ is $B \\times N \\times E$ dimensional.\n",
    "Because it is self-attention, $K$ and $Q$ have the same length $N$, and the attention matrix is square.\n",
    "The attention matrix is $A = Q \\cdot K^T$, and is $B \\times N \\times N$ dimensional. Formally:\n",
    "$$\n",
    "A_{b,i,j} = \\sum_d Q_{b,i,d} K_{b,j,d}\n",
    "$$\n",
    "\n",
    "We do softmax normalization along the columns $j$ of the attention matrix (such that each _row_ $i$ sums to 1). The result is the attention weights. Formally:\n",
    "$$\n",
    "\\bar{A}_{b,i,j} = \\frac{e^{A_{b,i,j}}}{\\sum_{j'} e^{A_{b,i,j'}}}\n",
    "$$\n",
    "\n",
    "The output $O$ of the attention layer is $B \\times N \\times E$ dimensional. It is obtained by the attention weights multiplied by the value vectors $V$. $A$ is $B \\times N \\times N$ dimensional and $V$ is $B \\times N \\times E$ dimensional.\n",
    "$$\n",
    "    O_{b,i,e} = \\sum_j A_{b,i,j} V_{b,j,e}\n",
    "$$\n",
    "\n",
    "Often the dimensions $E = D$ because this allows multiple attention layers in sequence, but this need not be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5noipvB9oe8v"
   },
   "outputs": [],
   "source": [
    "\n",
    "# example from keras docs https://keras.io/examples/nlp/text_classification_with_transformer/\n",
    "# uses built-in MultiHeadAttention https://keras.io/api/layers/attention_layers/multi_head_attention/\n",
    "\n",
    "# class TransformerBlock(layers.Layer):\n",
    "#     def __init__(self, n_embed_dim, n_heads, n_dense_dim, dropout_rate, **kwargs):\n",
    "#         super(TransformerBlock, self).__init__(**kwargs)\n",
    "#         self.att = layers.MultiHeadAttention(num_heads=n_heads, key_dim=n_embed_dim)\n",
    "#         self.dense_net = keras.Sequential([\n",
    "#             layers.Dense(n_dense_dim, activation='relu'),\n",
    "#             layers.Dense(n_embed_dim),\n",
    "#         ])\n",
    "#         self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "#         self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "#         self.dropout1 = layers.Dropout(dropout_rate)\n",
    "#         self.dropout2 = layers.Dropout(dropout_rate)\n",
    "    \n",
    "#     def call(self, inputs, masks, is_training):\n",
    "#         # make mask 2D\n",
    "#         mask = tf.logical_and(masks[:, :, None], masks[:, None, :])\n",
    "#         attn_output = self.att(inputs, inputs, attention_mask=mask)\n",
    "#         attn_output = self.dropout1(attn_output, training=is_training)\n",
    "#         out1 = self.layernorm1(inputs + attn_output)\n",
    "#         dense_output = self.dense_net(out1)\n",
    "#         dense_output = self.dropout2(dense_output, training=is_training)\n",
    "#         return self.layernorm2(out1 + dense_output)\n",
    "\n",
    "\n",
    "def multi_head_attention(n_heads, n_kq_dim, n_val_dim):\n",
    "    \n",
    "    k_dense = layers.Dense(n_kq_dim, activation='linear')\n",
    "    q_dense = layers.Dense(n_kq_dim, activation='linear')\n",
    "    \n",
    "    \n",
    "    \n",
    "    softmax = layers.Softmax(axis=-1)\n",
    "    \n",
    "    val_dense = layers.Dense(n_val_dim, activation='relu')\n",
    "    \n",
    "    def call(inputs, mask):\n",
    "        \n",
    "        k = k_dense(inputs)\n",
    "        q = q_dense(inputs)\n",
    "        \n",
    "        scores = tf.matmul(query, key, transpose_b=True)\n",
    "        weights = softmax(scores, mask)\n",
    "        \n",
    "        vals = val_dense(inputs)\n",
    "        \n",
    "        vals = tf.expand_dims(-1)\n",
    "        weights = tf.expand_dims(-2)\n",
    "        \n",
    "        outputs = tf.reduce_sum(vals * weights)\n",
    "        \n",
    "        \n",
    "        vals *= mask\n",
    "        \n",
    "\n",
    "def transformer_block(n_embed_dim, n_heads, n_dense_dim, dropout_rate):\n",
    "    attn = layers.MultiHeadAttention(num_heads=n_heads, key_dim=n_embed_dim)\n",
    "    dense_net_1 = layers.Dense(n_dense_dim, activation='relu')\n",
    "    dense_net_2 = layers.Dense(n_embed_dim)\n",
    "    layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "    layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "    dropout1 = layers.Dropout(dropout_rate)\n",
    "    dropout2 = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(inputs, masks, include_residual):\n",
    "        mask = tf.logical_and(masks[:, :, None], masks[:, None, :])\n",
    "        attn_output = attn(inputs, inputs, attention_mask=mask)\n",
    "        attn_output = dropout1(attn_output)\n",
    "        if include_residual:\n",
    "            attn_output = inputs + attn_output\n",
    "        # mask outputs. important! without, model learns magic powers (can detect and use verrrrrrry small numbers which are not literally 0)\n",
    "        attn_output = attn_output * tf.expand_dims(tf.cast(masks, tf.float32), -1)\n",
    "        attn_output = layernorm1(attn_output)\n",
    "        dense_output = dense_net_1(attn_output)\n",
    "        dense_output = dense_net_2(dense_output)\n",
    "        dense_output = dropout2(dense_output)\n",
    "        return layernorm2(attn_output + dense_output)\n",
    "    \n",
    "    return call\n",
    "    \n",
    "\n",
    "# class TokenAndPositionEmbedding(layers.Layer):\n",
    "#     def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "#         super(TokenAndPositionEmbedding, self).__init__()\n",
    "#         self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "#         self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "#     def call(self, x):\n",
    "#         maxlen = tf.shape(x)[-1]\n",
    "#         positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "#         positions = self.pos_emb(positions)\n",
    "#         x = self.token_emb(x)\n",
    "#         return x + positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfcvlCuCLUbM",
    "outputId": "d4d6f3de-eef7-4cb5-b6db-ae0ac89603ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([True, False]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-Xi5wBCwEVHp"
   },
   "outputs": [],
   "source": [
    "def model(batch_size):\n",
    "\n",
    "    # no batch size to start makes it simpler\n",
    "    n_embd = 20\n",
    "\n",
    "    data_input = keras.Input(shape=[784, 3], batch_size=None)\n",
    "    mask_input = keras.Input(shape=[784], batch_size=None, dtype=tf.bool)\n",
    "    m = data_input\n",
    "\n",
    "    # make n_embd-dimensional input embeddings per pixel from [x, y, v]\n",
    "    m = layers.Dense(30, activation='relu')(m)\n",
    "    m = layers.Dense(n_embd, activation='relu')(m)\n",
    "    m = transformer_block(n_embed_dim=n_embd, n_heads=12, n_dense_dim=n_embd, dropout_rate=0.1)(m, masks=mask_input, include_residual=False)\n",
    "    m = transformer_block(n_embed_dim=n_embd, n_heads=12, n_dense_dim=n_embd, dropout_rate=0.1)(m, masks=mask_input, include_residual=False)\n",
    "    m = layers.Flatten()(m)\n",
    "    m = layers.Dense(10, activation='relu')(m)\n",
    "    m = layers.Dense(1, activation=None)(m)\n",
    "\n",
    "    model = keras.Model(inputs=[data_input, mask_input], outputs=[m])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAoKvpfStPPH",
    "outputId": "9a668532-642d-4a64-8044-13ed1fb53daa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvcc\n",
      "Fri Sep 17 17:54:13 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.31       Driver Version: 465.31       CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "|  0%   32C    P2    40W / 225W |   6934MiB /  7982MiB |      7%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:AF:00.0 Off |                  N/A |\n",
      "|  0%   27C    P8    23W / 225W |      0MiB /  7982MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:D8:00.0 Off |                  N/A |\n",
      "|  0%   30C    P8    16W / 225W |    110MiB /  7982MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    624461      C   ...l-mnist/env/bin/python3.8     6931MiB |\n",
      "|    2   N/A  N/A    623413      C   ...isushehu/myenv/bin/python      107MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rOqsXnxifpG",
    "outputId": "e1fee0a6-197b-4ca4-92a0-1d23c1906133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 784, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 784, 30)      120         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 784, 1)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 1, 784)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 784, 20)      620         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.logical_and (TFOpLambda (None, 784, 784)     0           tf.__operators__.getitem[0][0]   \n",
      "                                                                 tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 784, 20)      19940       dense_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 tf.math.logical_and[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 784)          0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 784, 20)      0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims (TFOpLambda)     (None, 784, 1)       0           tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 784, 20)      0           dropout[0][0]                    \n",
      "                                                                 tf.expand_dims[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 784, 20)      40          tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 784, 20)      420         layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 784, 20)      420         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 784, 20)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 784, 20)      0           layer_normalization[0][0]        \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 784, 1)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (None, 1, 784)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 784, 20)      40          tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.logical_and_1 (TFOpLamb (None, 784, 784)     0           tf.__operators__.getitem_2[0][0] \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 784, 20)      19940       layer_normalization_1[0][0]      \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "                                                                 tf.math.logical_and_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_1 (TFOpLambda)          (None, 784)          0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 784, 20)      0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_1 (TFOpLambda)   (None, 784, 1)       0           tf.cast_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 784, 20)      0           dropout_2[0][0]                  \n",
      "                                                                 tf.expand_dims_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 784, 20)      40          tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 784, 20)      420         layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 784, 20)      420         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 784, 20)      0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 784, 20)      0           layer_normalization_2[0][0]      \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 784, 20)      40          tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 15680)        0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           156810      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            11          dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 199,281\n",
      "Trainable params: 199,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size=16\n",
    "\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "lr_metric = get_lr_metric(optimizer)\n",
    "\n",
    "txformer = model(batch_size)\n",
    "txformer.compile(optimizer=optimizer, loss='mse', metrics=['MeanAbsoluteError', lr_metric])\n",
    "\n",
    "def fit_one_epoch(dataset):\n",
    "    txformer.fit(x=[dataset[\"tuples\"], dataset[\"masks\"]], y=dataset[\"target_pxs\"], epochs=1, batch_size=batch_size, callbacks=[WandbCallback()])\n",
    "\n",
    "load_saved_model = False\n",
    "if load_saved_model:\n",
    "    txformer.load_weights(f\"./models/{model_name}\")\n",
    "\n",
    "txformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "fzuSaIstGU0A",
    "outputId": "765dc0e1-e241-4363-8f90-c06fe21ea4e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# display:\n",
    "# - before mask\n",
    "# - mask\n",
    "# - after mask\n",
    "# - prediction\n",
    "def gen_image(dataset, idx):\n",
    "    img = np.zeros([28, 28])\n",
    "    mask = dataset[\"masks\"][idx]\n",
    "    erow, ecol = dataset[\"offsets\"][idx]\n",
    "\n",
    "    image_mask = np.array(mask_to_image_mask(mask[np.newaxis, :]), np.uint8)[0]\n",
    "    masked_image = np.copy(dataset[\"imgs\"][idx])\n",
    "    \n",
    "    print(\"MNIST idx\", idx, \"which is a\", y_train[idx])\n",
    "    \n",
    "    display_uint8_image(masked_image) # before mask\n",
    "    display_uint8_image(image_mask * 255) # mask\n",
    "    masked_image = masked_image * image_mask\n",
    "    display_uint8_image(masked_image) # after mask\n",
    "    \n",
    "    for row in range(28):\n",
    "        for col in range(28):\n",
    "            img_tups = np.copy(dataset[\"tuples\"][idx])\n",
    "            img_tups[:, 0] += erow\n",
    "            img_tups[:, 1] += ecol\n",
    "            img_tups[:, 0] -= row\n",
    "            img_tups[:, 1] -= col\n",
    "            mask_idx = row*28+col\n",
    "            targ_idx_mask = idxs_to_onehots(tf.constant([mask_idx]))\n",
    "            this_mask = tf.logical_and(mask, targ_idx_mask)\n",
    "            px = txformer([img_tups[np.newaxis, :, :], this_mask])\n",
    "            img[row, col] = np.clip(px[0, 0], 0, 255)\n",
    "            \n",
    "    display_float32_image(img)\n",
    "\n",
    "def image_performance_test():\n",
    "    gen_image(test_dataset, 0)\n",
    "    gen_image(test_dataset, 1)\n",
    "    gen_image(test_dataset, 2)\n",
    "    \n",
    "    # full masks dataset as sanity test\n",
    "    gen_image(full_masks_dataset, 0)\n",
    "    gen_image(full_masks_dataset, 1)\n",
    "    gen_image(full_masks_dataset, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_performance_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "Qc-55LXO8Dtl",
    "outputId": "47b797e1-67ca-440b-c252-7e961a14c6ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-17 17:54:14.550416: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/3750 [..............................] - ETA: 5:07 - loss: 6688.9473 - mean_absolute_error: 43.1090 - lr: 0.0010WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0094s vs `on_train_batch_end` time: 0.0609s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0094s vs `on_train_batch_end` time: 0.0609s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 230/3750 [>.............................] - ETA: 4:32 - loss: 6027.0557 - mean_absolute_error: 52.4925 - lr: 0.0010"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_624461/2710463546.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_624461/3426161408.py\u001b[0m in \u001b[0;36mfit_one_epoch\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtxformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuples\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"masks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target_pxs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWandbCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mload_saved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conditional-mnist/env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit_one_epoch(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_performance_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Po6NnXshwaCj"
   },
   "outputs": [],
   "source": [
    "fit_one_epoch(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_performance_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhSfq8VcPOEW"
   },
   "outputs": [],
   "source": [
    "fit_one_epoch(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DD2oRg5MMrmK"
   },
   "outputs": [],
   "source": [
    "image_performance_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNhU_P0QPWPt"
   },
   "outputs": [],
   "source": [
    "if not load_saved_model:\n",
    "    txformer.save_weights(f\"./models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    gen_image(test_dataset, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST conditional prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
