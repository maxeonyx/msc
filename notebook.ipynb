{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a247b8c3-1a9d-42c1-bc9a-41c99ed78357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# print(physical_devices)\n",
    "assert len(physical_devices) == 1, \"Did not see the expected number of GPUs\"\n",
    "# to allow other tensorflow processes to use the gpu\n",
    "# https://stackoverflow.com/a/60699372/7989988\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "from IPython.display import display\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import enlighten\n",
    "import tensorflow_probability as tfp\n",
    "# from dotmap import DotMap\n",
    "from box import Box as DotMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8586c67e-f8cb-40d8-a136-b72c0f1de74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=bool, numpy=array([ True,  True, False])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([1., 2, 3]) < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9d8b7f-1fa3-4787-8eb7-a341e673ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import training\n",
    "import datasets\n",
    "import vizualization\n",
    "import schedules\n",
    "import create_dataset\n",
    "\n",
    "# todo\n",
    "# - combine shuffled and unshuffled datasets into same thing\n",
    "# - add extra shuffled indices and noise\n",
    "# - add \"noise fraction\" parameter which can be changed the same way as the \"n\" parameter.\n",
    "# - add different amounts of noise to the data and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9664a41e-2373-4007-ad5b-04367635212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DotMap({\n",
    "    'ds': 'hands',\n",
    "    'distributed': False,\n",
    "    'minibatch_size': 8,\n",
    "    'n_steps': 50000,\n",
    "    'test_size': 300,\n",
    "    'test_minibatch_size': 25,\n",
    "    'test_interval': 500,\n",
    "    'test_n_shuf': [392, 1, 64, 128, 256],\n",
    "    'test_n_seq': [392, 1, 128, 256, 512],\n",
    "    'test_autoregressive': False,\n",
    "    'display_images': True,\n",
    "    'display_image_interval': 500,\n",
    "    'dont_display_until_loss': 0.48,\n",
    "    'bg_color': [1.0, 0.4, 0.6],\n",
    "    'lr_schedule': ['constant', 0.0004],\n",
    "    'lr_warmup': 100,\n",
    "    'grad_accum_steps': None, #['exponential', 1, 4],\n",
    "    'max_accum_steps': 4,\n",
    "    'use_wandb': False,\n",
    "    'wandb_log_interval': 10,\n",
    "    'loss_window_size': 80,\n",
    "    'kmeans_batch_size': 1000,\n",
    "    'mixed_float': False,\n",
    "})\n",
    "\n",
    "# need to change for multiworkerstrategy\n",
    "if config.distributed:\n",
    "    config.num_devices = len(physical_devices)\n",
    "else:\n",
    "    config.num_devices = 1\n",
    "config.global_batch_size = config.minibatch_size * config.num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fee847f8-c7e5-4889-af95-b4e635213d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forcing generation of a fresh dataset to \"./cached_dataset/\" ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| datasets.py:324 in make_datasets() at 10:12:47.686\n",
      "ic| datasets.py:346 in make_datasets() at 10:12:47.744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'manipnet/Data/SimpleVisualizer/Assets/BVH/wineglass3_2/rightHand.bvh'>, <tf.Tensor: shape=(), dtype=int32, numpy=8000>, <tf.Tensor: shape=(8000, 23), dtype=float32, numpy=\n",
      "array([[-153.593   ,   13.43651 ,  -42.00934 , ...,  167.1838  ,\n",
      "         -30.63354 ,   52.14901 ],\n",
      "       [-153.6917  ,   13.69398 ,  -41.72995 , ...,  167.0725  ,\n",
      "         -29.95093 ,   53.39282 ],\n",
      "       [-153.6931  ,   13.86723 ,  -41.52698 , ...,  167.0263  ,\n",
      "         -29.72571 ,   54.29317 ],\n",
      "       ...,\n",
      "       [ -76.4584  ,  -78.03699 ,  -51.57129 , ...,  150.5776  ,\n",
      "          -2.118958,   12.46723 ],\n",
      "       [ -75.01645 ,  -78.0997  ,  -53.06293 , ...,  150.7132  ,\n",
      "          -2.264648,   12.90956 ],\n",
      "       [ -73.41113 ,  -78.03735 ,  -54.68829 , ...,  150.9352  ,\n",
      "          -2.807251,   12.95555 ]], dtype=float32)>, <tf.Tensor: shape=(), dtype=bool, numpy=True>)\n",
      "Not using gradient accumulation\n"
     ]
    }
   ],
   "source": [
    "# idea is to not have to re-run this cell for subsequent training runs unless the centroids change\n",
    "\n",
    "ds_configs = DotMap({\n",
    "    'mnist': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_gamma',\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'image_size': (28, 28),\n",
    "    },\n",
    "    'mnist_7x7': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_7x7_gamma',\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'mnist_7x7_contin': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': None,\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'mnist_binary_7x7': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_7x7_gamma',\n",
    "        'n_colors': 2,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'celeb': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'celeb_a',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_colors': 16,\n",
    "        'n_split_distribution': 'mnist_gamma',\n",
    "        'n_color_dims': 3,\n",
    "        'image_size': (218, 178),\n",
    "        'rescale': (32, 39),\n",
    "    },\n",
    "    'hands': {\n",
    "        'type': 'hands',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'shuffle': 'joints',\n",
    "        'n_dof': 23,\n",
    "        'n_frames': 30,\n",
    "        'n_split_distribution': None,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "    },\n",
    "})\n",
    "\n",
    "config.dataset = ds_configs[config.ds]\n",
    "config.dataset.discrete = not config.dataset.continuous\n",
    "\n",
    "if config.dataset.type == 'image':\n",
    "    dataset, metadata = tfds.load(config.dataset.tfds_name, with_info=True, as_supervised=True)\n",
    "    ds_train_original = dataset['train'].map(datasets.ignore_label)\n",
    "    ds_test_original = dataset['test'].map(datasets.ignore_label)\n",
    "    centroids = datasets.find_centroids(config, ds_train_original)\n",
    "    if config.dataset.rescale:\n",
    "        config.dataset.image_size = config.dataset.rescale\n",
    "    config.dataset.seq_length = config.dataset.image_size[0]*config.dataset.image_size[1]*config.dataset.n_color_dims\n",
    "elif config.dataset.type == 'hands':\n",
    "    dataset = create_dataset.tf_dataset(force=True)\n",
    "    centroids = None\n",
    "    # ignore left hands\n",
    "    print(next(iter(dataset)))\n",
    "    dataset = dataset.filter(datasets.is_right_hand)\n",
    "    dataset = dataset.map(datasets.ignore_metadata)\n",
    "\n",
    "    # TODO: split test and train\n",
    "    ds_train_original = dataset\n",
    "    ds_test_original = dataset\n",
    "\n",
    "    config.dataset.seq_length = config.dataset.n_dof * config.dataset.n_frames\n",
    "    \n",
    "if config.dataset.n_split_distribution == 'mnist_gamma':\n",
    "    gamma_dist, gamma_name = datasets.mnist_gamma_distribution()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "elif config.dataset.n_split_distribution == 'mnist_7x7_gamma':\n",
    "    gamma_dist, gamma_name = datasets.gamma_distribution_7x7()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "elif config.dataset.n_split_distribution == 'mnist_12x12_gamma':\n",
    "    gamma_dist, gamma_name = datasets.gamma_distribution_12x12()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "else:\n",
    "    gamma_dist, gamma_name = None, None\n",
    "\n",
    "\n",
    "ds = datasets.Datasets(config, ds_train_original, ds_test_original, centroids, gamma_dist)\n",
    "viz = vizualization.Viz(config, ds, centroids)\n",
    "ds_train, ds_test = ds.make_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "462f03d4-5dbc-4c9e-b1a5-2f70381fbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset.type == 'image':\n",
    "    display_colors, display_idxs, *_ = next(iter(ds_train))\n",
    "    if config.grad_accum_steps:\n",
    "        display_colors,display_idxs = display_colors[0],display_idxs[0]\n",
    "    if config.dataset.continuous:\n",
    "        display_colors = ds.reinvent_color_dim(display_colors)\n",
    "    viz.showSeq(display_colors, display_idxs, config.dataset.image_size, do_unquantize=config.dataset.discrete, max_images=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cffaf944-1a78-4029-99bd-04c99a9fbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset.type == 'image':\n",
    "    x_idx = tf.range(784)\n",
    "    pos_enc = models.pos_enc(n_dims=16, scale=100)\n",
    "    x = models.dual_positional_encoding((28,28), pos_enc)(x_idx)\n",
    "    x = x / 2. + 0.5\n",
    "    x = tf.expand_dims(tf.transpose(x), -1)\n",
    "    x_idx = tf.tile(x_idx[None, :], [16, 1])\n",
    "    viz.showSeq(x[:8], x_idx[:8], (28, 28), 8)\n",
    "    viz.showSeq(x[8:16], x_idx[8:16], (28, 28), 8)\n",
    "    viz.showSeq(x[16:24], x_idx[16:24], (28, 28), 8)\n",
    "    viz.showSeq(x[24:], x_idx[24:], (28, 28), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "636a3bbc-bc94-4fa4-9966-45fd3e96fa02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda10-hands-gpt-1layer-contin-bs1x1x8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model config\n",
    "config.model = DotMap({\n",
    "    'comment': '1layer',\n",
    "    'discrete': config.dataset.discrete,\n",
    "    'continuous': config.dataset.continuous,\n",
    "    'n_enc_a_layers': 1,\n",
    "    'n_enc_b_layers': 0,\n",
    "    'ffl_dim': 64,\n",
    "    'embd_dim': 64,\n",
    "    'n_dec_layers': 1,\n",
    "    'dec_dim': 400,\n",
    "    'n_heads': 8,\n",
    "    'dropout_rate': 0.1,\n",
    "    'use_idxs_input': True,\n",
    "    'architecture': 'gpt',\n",
    "    'use_relative_positions': False,\n",
    "    'activation': 'swish'\n",
    "})\n",
    "\n",
    "if config.model.continuous:\n",
    "    config.model.distribution = config.dataset.loss\n",
    "    config.model.n_dist_params = config.dataset.n_dist_params\n",
    "\n",
    "if config.dataset.type == 'image':\n",
    "    config.model.n_colors = config.dataset.n_colors\n",
    "    config.model.n_color_dims = config.dataset.n_color_dims\n",
    "    config.model.image_size = config.dataset.image_size\n",
    "    config.model.seq_len = config.dataset.image_size[0] * config.dataset.image_size[1]\n",
    "    config.model.position_embedding = 'pos_enc'\n",
    "else:\n",
    "    config.model.seq_len = config.dataset.n_frames * config.dataset.n_dof\n",
    "    config.model.n_frames = config.dataset.n_frames\n",
    "    config.model.n_dof = config.dataset.n_dof\n",
    "    config.model.position_embedding = 'pos_and_embd'\n",
    "    config.model.loc_scale = False\n",
    "    config.model.scalar = True\n",
    "    \n",
    "\n",
    "if config.distributed == False:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.transformer(config.model)\n",
    "    # Adam params taken from the linked notebook\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=schedules.learning_rate_schedule(config))\n",
    "\n",
    "if config.distributed:\n",
    "    ds_train = strategy.experimental_distribute_dataset(ds_train)\n",
    "\n",
    "config.training_mode = 'query_next'\n",
    "\n",
    "import socket\n",
    "model_name = models.model_name(config)\n",
    "print(model_name)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7c19055-3dc4-460b-bc73-7555ddf1b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/local/scratch/maxeonyx/msc-cgt-hands/manipnet/Data/SimpleVisualizer/Assets/BVH/bottle1_body1/rightHand.bvh\"\n",
    "\n",
    "dof = 23\n",
    "\n",
    "def generate_data(conditioning_data, window_frames, new_frames):\n",
    "    manager = enlighten.get_manager()\n",
    "    \n",
    "    # model = tf.keras.models.load_model(\n",
    "    #     \"/home/maxeonyx/msc/msc-cgt-hands/models/maxpc-hands-2layers-contin-bs1x1x8-righthand2\",\n",
    "    #     custom_objects={\n",
    "    #         'negloglik': training.negloglik,\n",
    "    #         'von_mises_loss': training.von_mises_loss\n",
    "    #     },\n",
    "    # )\n",
    "\n",
    "    conditioning_data = tf.cast(conditioning_data, tf.float32)\n",
    "\n",
    "    prev_frames = min(window_frames, conditioning_data.shape[0])\n",
    "    n_frames_to_predict = new_frames\n",
    "\n",
    "    counter = manager.counter(total=n_frames_to_predict*dof)\n",
    "    # wm.progress_begin(0, n_frames_to_predict*dof)\n",
    "\n",
    "    dof_idxs = tf.tile(tf.range(dof)[None, :], [prev_frames + 1, 1])\n",
    "    frame_idxs = tf.tile(tf.range(prev_frames + 1)[:, None], [1, dof]) * dof\n",
    "    idxs = dof_idxs + frame_idxs\n",
    "    idxs = tf.reshape(idxs, [-1])\n",
    "\n",
    "    def iteration(i, data):\n",
    "        tar_idx = prev_frames*dof + i + 1\n",
    "        inp_idxs = tf.range(i, prev_frames*dof + i)\n",
    "        inp = data[-prev_frames*dof:]\n",
    "        inp_len = tf.shape(inp_idxs)[0]\n",
    "        tar_len = 1\n",
    "        pred_params = model({\n",
    "            \"colors\": inp[None, :],\n",
    "            \"inp_idxs\": inp_idxs[None, :],\n",
    "            \"tar_idxs\": tar_idx[None, None],\n",
    "            \"enc_mask\": tf.zeros((inp_len, inp_len)),\n",
    "            \"dec_mask\": tf.zeros((tar_len, inp_len)),\n",
    "        })\n",
    "\n",
    "        loc = pred_params[:, :, 0]\n",
    "        # concentration = pred_params[:, :, 1]\n",
    "\n",
    "        # dist = tfp.distributions.VonMises(loc=loc, concentration=concentration)\n",
    "        # sample = dist.mean()\n",
    "        sample = loc\n",
    "        sample = tf.reshape(sample, [-1])\n",
    "        data = tf.concat([data, sample], axis=0)\n",
    "        return i+1, data\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=[tf.TensorSpec([None, dof])],\n",
    "    )\n",
    "    def do_batch(data):\n",
    "        inp_data = tf.reshape(data[-prev_frames:, :], [prev_frames*dof])\n",
    "        _i, out_data = tf.while_loop(\n",
    "            cond=lambda i, data: i < dof,\n",
    "            body=iteration,\n",
    "            loop_vars=[\n",
    "                tf.constant(0),\n",
    "                inp_data\n",
    "            ],\n",
    "            shape_invariants=[\n",
    "                tf.TensorShape([]),\n",
    "                tf.TensorShape([None]),\n",
    "            ],\n",
    "        )\n",
    "        return tf.reshape(out_data[-dof:], [1, dof])\n",
    "\n",
    "#    test_data = tf.cast(create_dataset.load_one_bvh_file(filename, convert_deg_to_rad=True), tf.float32)\n",
    "    generated_data = conditioning_data[:prev_frames, :]\n",
    "    for i in range(n_frames_to_predict):\n",
    "        result = do_batch(generated_data)\n",
    "        generated_data = tf.concat([generated_data, result], axis=0)\n",
    "        counter.update(incr=dof)\n",
    "        # wm.progress_update(i*dof)\n",
    "    counter.close()\n",
    "\n",
    "    return generated_data\n",
    "\n",
    "test_data = tf.cast(create_dataset.load_one_bvh_file(filename, convert_deg_to_rad=True), tf.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "171f56f2-d010-4072-8f19-8f20e5224886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/1000 [..............................] - ETA: 1:07 - loss: 8.3610e-05WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0334s vs `on_train_batch_end` time: 0.0335s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0334s vs `on_train_batch_end` time: 0.0335s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 7.4500e-05"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>100%|██████████████████████████████████████████████████████████████| 690/690 [00:02&lt;00:00, 334.88/s]</pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAADCCAYAAAAmeuk7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAATW0lEQVR4nO3dW4xd1X3H8d9/xuNxMKmCuVgW0EDASuSHQCTXooIHAiVy06hQqUKhF/GA5KpKKiKlqmhe0qaNRB+ahIc0lRsQrkgIqAnBSlELcpFoq4hiElquFRRRBctgE+4znss5+9+HswkD9fove53ZlzPz/UiW55w167LX2fv8Z59Z/1nm7gIAAGlTXQ8AAIC+I1gCAJBBsAQAIINgCQBABsESAIAMgiUAABkbxqlsZrsl3SJpWtK33f3m6PtnZjf77Clbxumy/6zrAUyoaN6i7KZJmu+1kKXV2DGshckZR8sncp+um8xY2jwzFude1WBh7rgjKg6WZjYt6ZuSrpL0oqRHzGy/uz+VqjN7yhZddOWNpV1OBG/iJAzaLO7PGrpagrxdnwr6XOfB0krfEYL5Lm8zXRS2Oca7mjWR793Eu2xTl03p9VhYLXzfKH2/CY6htL9x6pbUe/Ifv5GsMs7HsLskPefuz7v7kqTvSbp6jPYAAOilcYLl2ZJ+tuLxi/Vz72Fme8zsoJkdXF58e4zuAADoRuMLfNx9r7vvdPedM7OnNt0dAACrbpxgeUjSuSsen1M/BwDAmjLOathHJG03s/M1CpKflfQ7UYXhrPTGedNjdIn/p4MFLm0vYmrEGpm34gU3jSw2Kqw3Tp+B8sVvhW1OyCKWsepFt1dNjEUqPjlKXv/hgXRZcbB094GZfV7SP2uUOnKbuz9Z2h4AAH01Vp6lu98n6b5VGgsAAL3EX/ABACCDYAkAQAbBEgCADIIlAAAZYy3wOVm+QVo46/jLgNfKn1FuJCOhgb/H2cRSfSleWm5VVDEoK53UDv6mbFOpBekOC8sCTf391yYu8klJOWmqbtvnW/F0dzA3JaL3L+4sAQDIIFgCAJBBsAQAIINgCQBABsESAIAMgiUAABmtpo7YQNp0pIPtHtoUHF6YOhEoXh4+Sfk4TaRORNVKU1zG0ESfjaR5NLEjSabd1vUsVSNqt5GdPoI2e7WTSabuar+O0XXInSUAABkESwAAMgiWAABkECwBAMggWAIAkEGwBAAgg2AJAEBGu1t0ba60sOvtgopR8mKfkrdQyqI8rCa2dmq5v6Z4lf55t6rSB+lBmUrr5eYt7DOoF13/QT0rrBdve5Zuc5K2Nmtd39LrE3PKFl0AAIyBYAkAQAbBEgCADIIlAAAZBEsAADIIlgAAZLSaOjI1VemDmxfa7LJXphpYPl0Fy8qb6K8p0XFEpqfSFaeCtfzLw/TPiaVtSlIVpBYMg9SJ6LWyoM9BcByDMK0kXTYM2hwO0wON2pTitBMP2g3TVUrrFabARFs4eWk6ilSekhK2WViviTY7SH9Z7azCsYKlmb0g6S1JQ0kDd9+5GoMCAKBPVuPO8pPu/soqtAMAQC/xO0sAADLGDZYu6X4ze9TM9hzvG8xsj5kdNLODgzfmx+wOAID2jfsx7GXufsjMzpL0gJk94+4PrfwGd98raa8knbJ921r4K4cAgHVmrDtLdz9U/39E0j2Sdq3GoAAA6JPiO0sz2yxpyt3fqr/+lKSvRHWqakpvzW066b6iJelRdkR0GztOVoVHuxk0INoFYypIcygeZ27NdcvHH44nGEsVpBVYNG9BvdyJMzUd5R0EfUapDIHi3UOiY4xe/tJ0jEy7FtSN0jVK24x3FgnaLN1ZZIxrho2VGpCa02Cux/kYdquke2y019EGSd91938aoz0AAHqpOFi6+/OSLlrFsQAA0EukjgAAkEGwBAAgg2AJAEAGwRIAgIxWdx352KlHdf+l32qzy0ZEK9kjk/KTyfRYiTVpwy62HkiIXsNxXqe2z42FIK9oMZjuBZ8uLEu/ZSz4TLpDSXPVbFHdhSpdNl/Y5vwwXW8xOMb54cZ0vSpd71hQb1SeHutSFbweQb3FQXo8UZvLw3TZUlDWxA44UrwLThWkB1VBvWRa3cb0FTwp798AAHSGYAkAQAbBEgCADIIlAAAZBEsAADIIlgAAZLSaOrJBUzpjenObXQITb+jp5eyLPigqW/BhYVnU33KyTJI2Wbo8TB2ZSpdtqoI2g5STaCxROsqMBXMT9BfVk6SZqXR5lFYyFWxJMhWkak1XQYpE1GZQtmTptBIbpuulz6i6btBnlFYS1UullViQNcedJQAAGQRLAAAyCJYAAGQQLAEAyCBYAgCQQbAEACCj1dSRx189U9vv+MM2u0RKtAFIbtOR/mweguC1CFbON1Ivd17E7aZPurBeqSbaHGOznuDwM32WHUh5fy3Xyyg9juS0LabvH7mzBAAgg2AJAEAGwRIAgAyCJQAAGQRLAAAyCJYAAGS0mjpiGytNfXiuzS6R4FHqQEPLvCN9G8+kSO2eIElVsK6+GgaTWqXLvLDeqDwoi3IAgnoW9VlaLzoXw2MIynLaTp1pwqSMU+n3m+gQsneWZnabmR0xsydWPLfFzB4ws2fr/0876dECADAhTuRj2Nsl7X7fczdJOuDu2yUdqB8DALAmZYOluz8k6dX3PX21pH311/skXbO6wwIAoD9KF/hsdffD9dcvSdqa+kYz22NmB83s4PBNfl8JAJg8Y6+GdXdX8HtRd9/r7jvdfef0L20etzsAAFpXGixfNrNtklT/f2T1hgQAQL+Upo7sl3S9pJvr/+89kUo7Tn1F/37ZrYVdTr6pCUlrncpsEVAFC6yjulG9KswrQMqCD5Jl89UwqBe1mT5PF306qBe/nSz4TLJszjem61XpsrmgbCFocz6oNz+cLaq3WKWP/9gwXW9Unp6bqGxhmO5zKRjPYlBveZh+jReDskFYlj6nBlX8vjiM0qOCFKCitKqN6fehE0kduVPSjyV91MxeNLMbNAqSV5nZs5J+rX4MAMCalL2zdPfrEkVXrvJYAADopcn4XBAAgA4RLAEAyCBYAgCQQbAEACCDYAkAQEarW3S5XMuezv1a+9bzsaMJy57OC4vOtiirtQpyZZeCn6+XlM6zk6SlIEdzOcjRXG6kXrosOv5o27O4v/i+JCofhGVBbmOQv1haNgzL0nMzjLaLy2zt5oV1o9fKc9vJHQd3lgAAZBAsAQDIIFgCAJBBsAQAIINgCQBABsESAICMVlNHnnptqz7+gxvb7LIZwZJkWbD3UdsmZZxSPNY+yc1by8cRDifID4nrpY8hrJeZmuK6Qdk441n1el1o4nRr+VIc55KJXv84kSnR3lL6/pE7SwAAMgiWAABkECwBAMggWAIAkEGwBAAgg2AJAEBGq6kjmnL5B6L9DgCcjGDTkXhNfpSOEe3IEPYXlI3Rbml6SNhfaZtBtVBT6SiTlObSgNK0k5LMOe4sAQDIIFgCAJBBsAQAIINgCQBABsESAIAMgiUAABmtpo7MHq300b+db7NLTAoyitKCH2ltGKyB96AsqGdRvbDNzItY2m5QZtXqtxmWNdFfThXMa9Cul/YZHmPhhVo6p7k+c3WTwzl+vSNvH0vWyd5ZmtltZnbEzJ5Y8dyfmdkhM3us/vfpkgEDADAJTuRj2Nsl7T7O819394vrf/et7rAAAOiPbLB094ckvdrCWAAA6KVxFvh83sz+q/6Y9rTUN5nZHjM7aGYHlwf8vhIAMHlKg+W3JF0g6WJJhyX9deob3X2vu+90950zG04p7A4AgO4UBUt3f9ndh+5eSfo7SbtWd1gAAPRHUeqImW1z98P1w9+S9ET0/e/4yIWv6I4f7i3pElhV0+X7R/TKQrCsfj5YVb/g08myOU+/LSz4TLq/ajbdoaS5oDxqN6o3X21Mlw3L6r0d1Ds2TI8zKlsIyiRpfpAez2JQd3GQfq2WhunXeGmQLhtU6XuoQVBvOEzXq6KyaHcYSR7uVpMu8+HJ11v4i/uTVbLB0szulHS5pDPM7EVJX5Z0uZldrNEGMS9I+oNcOwAATKpssHT3647z9K0NjAUAgF7iz90BAJBBsAQAIINgCQBABsESAICMVncdefqNs/Qr9/9Rm12ibaUZGaWbMvQtA2SMzSWKFCyPlxSO08Kl+sFYMikAFtSNyqJ2w3rRMUavUwP1sto+b1oW3ZXl7tjCOS/lxz+nbDl9rnFnCQBABsESAIAMgiUAABkESwAAMgiWAABkECwBAMhoNXVEJtn0Gl8jjVZ5306nKHsisVx9LFPBBIRzE+zWEKzVNwuOIbfGP6jrwY/tFhyIB8cRDSc6b8J66aK4cIzztJHUiUjPrqnwsikca3ROpXBnCQBABsESAIAMgiUAABkESwAAMgiWAABkECwBAMhoNXVk9qjrwr2DNrtEn/RsSfqksCjPoQrSPIIyDaN6wVYepfWkOF9jGNQN2g2PMRpP4ZyGbZb2J8nDuRmWtRsdh0fHEaTqlI4zmJuwzUy7XnqMiT5f8rlkFe4sAQDIIFgCAJBBsAQAIINgCQBABsESAIAMgiUAABkESwAAMrJ5lmZ2rqS/l7RVo0y5ve5+i5ltkXSXpPMkvSDpWnd/LWrr/AuO6o67/mbcMaPHop++Mll4q97fWjEdbEM1F+SSLQYpaHOevvQXfDpZNl/NBvVm0h1KmgvqzlUbi/qMy4I2h1F/6bJjw/Qxzg2CuRnGb7ULQbvHBpuSZYuDdLtLw/TruDwIyoJ6w2H6ihsO0+dpVaXreVBvVB7UrYK60RtOot7iX/44WeVE3msGkr7o7jskXSLpc2a2Q9JNkg64+3ZJB+rHAACsOdlg6e6H3f0n9ddvSXpa0tmSrpa0r/62fZKuaWiMAAB06qQ+xTKz8yR9QtLDkra6++G66CWNPqY9Xp09ZnbQzA7+/OdNfBAHAECzTjhYmtmpkr4v6Qvu/ubKMh/9cb/j/obE3fe6+05333n66evhN0wAgLXmhKKXmc1oFCi/4+4/qJ9+2cy21eXbJB1pZogAAHQrGyzNzCTdKulpd//aiqL9kq6vv75e0r2rPzwAALp3Ilt0XSrp9yU9bmaP1c99SdLNku42sxsk/a+ka3MNPfP6Vl2y/8bCoa5x0S418crqfvXX9nGU6mK7sNI+g3pWuHTewrLCNtNFY40nPP5oTj09orheYdkYwvH0SPQaTweF6WSU8az2vNlS+iCywdLd/03pObqycEwAAEwMVtwAAJBBsAQAIINgCQBABsESAIAMgiUAABknkjqyamZml7XtgqMnXa8KloCXmpqUtdpjKJ21vs1MdBx9G2ukifN4Kdg9YhDtHhHsAjEYpMuqYAeIaGeJUd308Yc7T5SWBSkwpekxcZvpamFqjJRJV2kgBaZ0LIHis3uci7h0rKl6wSnMnSUAABkESwAAMgiWAABkECwBAMggWAIAkEGwBAAgw0b7NrfUmdlRjXYokaQzJL3SWueThblJY27SmJs05iaNuXnXh939zOMVtBos39Ox2UF339lJ5z3H3KQxN2nMTRpzk8bcnBg+hgUAIINgCQBARpfBcm+Hffcdc5PG3KQxN2nMTRpzcwI6+50lAACTgo9hAQDIIFgCAJDRSbA0s91m9t9m9pyZ3dTFGPrCzG4zsyNm9sSK57aY2QNm9mz9/2ldjrErZnaumT1oZk+Z2ZNmdmP9/LqfHzPbZGb/YWb/Wc/Nn9fPn29mD9fX1l1mtrHrsXbBzKbN7Kdm9qP6MfNSM7MXzOxxM3vMzA7Wz637ayqn9WBpZtOSvinp1yXtkHSdme1oexw9cruk3e977iZJB9x9u6QD9eP1aCDpi+6+Q9Ilkj5XnyvMj7Qo6Qp3v0jSxZJ2m9klkv5K0tfd/UJJr0m6obshdupGSU+veMy8vNcn3f3iFfmVXFMZXdxZ7pL0nLs/7+5Lkr4n6eoOxtEL7v6QpFff9/TVkvbVX++TdE2bY+oLdz/s7j+pv35Loze/s8X8yEferh/O1P9c0hWS/qF+fl3OjZmdI+k3JH27fmxiXnLW/TWV00WwPFvSz1Y8frF+Du/a6u6H669fkrS1y8H0gZmdJ+kTkh4W8yPpFx81PibpiKQHJP2PpNfdfVB/y3q9tr4h6U8kVfXj08W8rOSS7jezR81sT/0c11TGhq4HgJi7u5mt6/weMztV0vclfcHd3xzdKIys5/lx96Gki83sQ5LukfSxbkfUPTP7jKQj7v6omV3e8XD66jJ3P2RmZ0l6wMyeWVm4nq+pSBd3locknbvi8Tn1c3jXy2a2TZLq/490PJ7OmNmMRoHyO+7+g/pp5mcFd39d0oOSflXSh8zsnR+C1+O1damk3zSzFzT6Fc8Vkm4R8/IL7n6o/v+IRj9k7RLXVFYXwfIRSdvr1WkbJX1W0v4OxtFn+yVdX399vaR7OxxLZ+rfNd0q6Wl3/9qKonU/P2Z2Zn1HKTP7gKSrNPqd7oOSfrv+tnU3N+7+p+5+jrufp9F7y7+4++9qnc/LO8xss5l98J2vJX1K0hPimsrq5C/4mNmnNfq9wrSk29z9q60PoifM7E5Jl2u0Tc7Lkr4s6YeS7pb0yxptaXatu79/EdCaZ2aXSfpXSY/r3d8/fUmj31uu6/kxs49rtBBjWqMfeu9296+Y2Uc0uqPaIumnkn7P3Re7G2l36o9h/9jdP8O8jNTzcE/9cIOk77r7V83sdK3zayqHP3cHAEAGf8EHAIAMgiUAABkESwAAMgiWAABkECwBAMggWAIAkEGwBAAg4/8AeAyNB/SAKn8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 70s 69ms/step - loss: 7.4500e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f661efe2700>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_fig():\n",
    "    generated_data = generate_data(test_data, 30, 30)\n",
    "    _fig, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.imshow(tf.transpose(generated_data))\n",
    "    plt.show()\n",
    "\n",
    "class PlotCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gen_fig()\n",
    "        \n",
    "# model.compile(loss=training.von_mises_loss, optimizer=optimizer)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "ds_train_keras_fit = ds_train.map(training.ds_input_to_keras(config))\n",
    "model.fit(ds_train_keras_fit, steps_per_epoch=1000, epochs=1, callbacks=[PlotCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d62aed9f-9442-46ac-884e-2dd4be134cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>100%|██████████████████████████████████████████████████████████████| 690/690 [00:02&lt;00:00, 408.80/s]</pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5666655d-f24d-43c1-a085-a13d6df25fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_4 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/cuda10-hands-gpt-1layer-contin-bs1x1x8-may26-2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/cuda10-hands-gpt-1layer-contin-bs1x1x8-may26-2/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save(f\"models/{model_name}-may26-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1409c9e6-9857-49e0-863e-97d4060fe06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a110310-ed51-43cc-9a8c-e56544e98d55",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
