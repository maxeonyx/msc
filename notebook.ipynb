{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a247b8c3-1a9d-42c1-bc9a-41c99ed78357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 12:08:06.716774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 12:08:06.743738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 12:08:06.743954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# print(physical_devices)\n",
    "assert len(physical_devices) == 1, \"Did not see the expected number of GPUs\"\n",
    "# to allow other tensorflow processes to use the gpu\n",
    "# https://stackoverflow.com/a/60699372/7989988\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "from IPython.display import display\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import enlighten\n",
    "import tensorflow_probability as tfp\n",
    "# from dotmap import DotMap\n",
    "from box import Box as DotMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8586c67e-f8cb-40d8-a136-b72c0f1de74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 12:08:07.932297: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-28 12:08:07.933089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 12:08:07.933292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 12:08:07.933434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 12:08:08.362047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 12:08:08.362233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 12:08:08.362378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 12:08:08.362516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3486 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:26:00.0, compute capability: 7.5\n",
      "2022-04-28 12:08:08.362732: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=bool, numpy=array([ True,  True, False])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([1., 2, 3]) < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9d8b7f-1fa3-4787-8eb7-a341e673ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import training\n",
    "import datasets\n",
    "import vizualization\n",
    "import schedules\n",
    "import create_dataset\n",
    "\n",
    "# todo\n",
    "# - combine shuffled and unshuffled datasets into same thing\n",
    "# - add extra shuffled indices and noise\n",
    "# - add \"noise fraction\" parameter which can be changed the same way as the \"n\" parameter.\n",
    "# - add different amounts of noise to the data and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9664a41e-2373-4007-ad5b-04367635212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DotMap({\n",
    "    'ds': 'hands',\n",
    "    'distributed': False,\n",
    "    'minibatch_size': 8,\n",
    "    'n_steps': 50000,\n",
    "    'test_size': 300,\n",
    "    'test_minibatch_size': 25,\n",
    "    'test_interval': 500,\n",
    "    'test_n_shuf': [392, 1, 64, 128, 256],\n",
    "    'test_n_seq': [392, 1, 128, 256, 512],\n",
    "    'test_autoregressive': False,\n",
    "    'display_images': True,\n",
    "    'display_image_interval': 500,\n",
    "    'dont_display_until_loss': 0.48,\n",
    "    'bg_color': [1.0, 0.4, 0.6],\n",
    "    'lr_schedule': ['constant', 0.0004],\n",
    "    'lr_warmup': 100,\n",
    "    'grad_accum_steps': None, #['exponential', 1, 4],\n",
    "    'max_accum_steps': 4,\n",
    "    'use_wandb': False,\n",
    "    'wandb_log_interval': 10,\n",
    "    'loss_window_size': 80,\n",
    "    'kmeans_batch_size': 1000,\n",
    "    'mixed_float': False,\n",
    "})\n",
    "\n",
    "# need to change for multiworkerstrategy\n",
    "if config.distributed:\n",
    "    config.num_devices = len(physical_devices)\n",
    "else:\n",
    "    config.num_devices = 1\n",
    "config.global_batch_size = config.minibatch_size * config.num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee847f8-c7e5-4889-af95-b4e635213d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forcing generation of a fresh dataset to \"./cached_dataset/\" ...\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'manipnet/Data/SimpleVisualizer/Assets/BVH/torus_large2/rightHand.bvh'>, <tf.Tensor: shape=(), dtype=int32, numpy=8000>, <tf.Tensor: shape=(8000, 23), dtype=float32, numpy=\n",
      "array([[ 38.60198 ,   3.44385 , -80.29813 , ..., 160.6     ,  18.7621  ,\n",
      "         31.48688 ],\n",
      "       [ 37.93424 ,   2.427587, -77.95386 , ..., 160.2177  ,  18.48519 ,\n",
      "         31.1022  ],\n",
      "       [ 37.22429 ,   1.43739 , -75.59412 , ..., 159.8326  ,  18.24442 ,\n",
      "         30.71409 ],\n",
      "       ...,\n",
      "       [ -5.146515, -27.65384 , -29.83078 , ..., 159.1052  ,  16.87695 ,\n",
      "         34.4897  ],\n",
      "       [ -5.938782, -28.10406 , -29.86691 , ..., 159.3364  ,  16.52519 ,\n",
      "         35.28053 ],\n",
      "       [ -6.903107, -28.32141 , -29.78873 , ..., 159.1706  ,  16.74059 ,\n",
      "         35.72622 ]], dtype=float32)>, <tf.Tensor: shape=(), dtype=bool, numpy=True>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| datasets.py:302 in make_datasets() at 12:08:20.360\n",
      "ic| datasets.py:324 in make_datasets() at 12:08:20.437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using gradient accumulation\n"
     ]
    }
   ],
   "source": [
    "# idea is to not have to re-run this cell for subsequent training runs unless the centroids change\n",
    "\n",
    "ds_configs = DotMap({\n",
    "    'mnist': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_gamma',\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'image_size': (28, 28),\n",
    "    },\n",
    "    'mnist_7x7': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_7x7_gamma',\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'mnist_7x7_contin': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': None,\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'mnist_binary_7x7': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_7x7_gamma',\n",
    "        'n_colors': 2,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'celeb': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'celeb_a',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_colors': 16,\n",
    "        'n_split_distribution': 'mnist_gamma',\n",
    "        'n_color_dims': 3,\n",
    "        'image_size': (218, 178),\n",
    "        'rescale': (32, 39),\n",
    "    },\n",
    "    'hands': {\n",
    "        'type': 'hands',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'shuffle': 'joints',\n",
    "        'n_dof': 23,\n",
    "        'n_frames': 30,\n",
    "        'n_split_distribution': None,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "    },\n",
    "})\n",
    "\n",
    "config.dataset = ds_configs[config.ds]\n",
    "config.dataset.discrete = not config.dataset.continuous\n",
    "\n",
    "if config.dataset.type == 'image':\n",
    "    dataset, metadata = tfds.load(config.dataset.tfds_name, with_info=True, as_supervised=True)\n",
    "    ds_train_original = dataset['train'].map(datasets.ignore_label)\n",
    "    ds_test_original = dataset['test'].map(datasets.ignore_label)\n",
    "    centroids = datasets.find_centroids(config, ds_train_original)\n",
    "    if config.dataset.rescale:\n",
    "        config.dataset.image_size = config.dataset.rescale\n",
    "    config.dataset.seq_length = config.dataset.image_size[0]*config.dataset.image_size[1]*config.dataset.n_color_dims\n",
    "elif config.dataset.type == 'hands':\n",
    "    dataset = create_dataset.tf_dataset(force=True)\n",
    "    centroids = None\n",
    "    # ignore left hands\n",
    "    print(next(iter(dataset)))\n",
    "    dataset = dataset.filter(datasets.is_right_hand)\n",
    "    dataset = dataset.map(datasets.ignore_metadata)\n",
    "\n",
    "    # TODO: split test and train\n",
    "    ds_train_original = dataset\n",
    "    ds_test_original = dataset\n",
    "\n",
    "    config.dataset.seq_length = config.dataset.n_dof * config.dataset.n_frames\n",
    "    \n",
    "if config.dataset.n_split_distribution == 'mnist_gamma':\n",
    "    gamma_dist, gamma_name = datasets.mnist_gamma_distribution()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "elif config.dataset.n_split_distribution == 'mnist_7x7_gamma':\n",
    "    gamma_dist, gamma_name = datasets.gamma_distribution_7x7()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "elif config.dataset.n_split_distribution == 'mnist_12x12_gamma':\n",
    "    gamma_dist, gamma_name = datasets.gamma_distribution_12x12()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "else:\n",
    "    gamma_dist, gamma_name = None, None\n",
    "\n",
    "\n",
    "ds = datasets.Datasets(config, ds_train_original, ds_test_original, centroids, gamma_dist)\n",
    "viz = vizualization.Viz(config, ds, centroids)\n",
    "ds_train, ds_test = ds.make_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462f03d4-5dbc-4c9e-b1a5-2f70381fbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset.type == 'image':\n",
    "    display_colors, display_idxs, *_ = next(iter(ds_train))\n",
    "    if config.grad_accum_steps:\n",
    "        display_colors,display_idxs = display_colors[0],display_idxs[0]\n",
    "    if config.dataset.continuous:\n",
    "        display_colors = ds.reinvent_color_dim(display_colors)\n",
    "    viz.showSeq(display_colors, display_idxs, config.dataset.image_size, do_unquantize=config.dataset.discrete, max_images=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cffaf944-1a78-4029-99bd-04c99a9fbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset.type == 'image':\n",
    "    x_idx = tf.range(784)\n",
    "    pos_enc = models.pos_enc(n_dims=16, scale=100)\n",
    "    x = models.dual_positional_encoding((28,28), pos_enc)(x_idx)\n",
    "    x = x / 2. + 0.5\n",
    "    x = tf.expand_dims(tf.transpose(x), -1)\n",
    "    x_idx = tf.tile(x_idx[None, :], [16, 1])\n",
    "    viz.showSeq(x[:8], x_idx[:8], (28, 28), 8)\n",
    "    viz.showSeq(x[8:16], x_idx[8:16], (28, 28), 8)\n",
    "    viz.showSeq(x[16:24], x_idx[16:24], (28, 28), 8)\n",
    "    viz.showSeq(x[24:], x_idx[24:], (28, 28), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "636a3bbc-bc94-4fa4-9966-45fd3e96fa02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxpc-hands-2layers-contin-bs1x1x8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model config\n",
    "config.model = DotMap({\n",
    "    'comment': '2layers',\n",
    "    'discrete': config.dataset.discrete,\n",
    "    'continuous': config.dataset.continuous,\n",
    "    'n_enc_a_layers': 2,\n",
    "    'n_enc_b_layers': 2,\n",
    "    'ffl_dim': 64,\n",
    "    'embd_dim': 64,\n",
    "    'n_dec_layers': 1,\n",
    "    'dec_dim': 400,\n",
    "    'n_heads': 8,\n",
    "    'dropout_rate': 0.1,\n",
    "    'use_idxs_input': True,\n",
    "    'architecture': 'anp',\n",
    "    'use_relative_positions': False,\n",
    "    'activation': 'swish'\n",
    "})\n",
    "\n",
    "if config.model.continuous:\n",
    "    config.model.distribution = config.dataset.loss\n",
    "    config.model.n_dist_params = config.dataset.n_dist_params\n",
    "\n",
    "if config.dataset.type == 'image':\n",
    "    config.model.n_colors = config.dataset.n_colors\n",
    "    config.model.n_color_dims = config.dataset.n_color_dims\n",
    "    config.model.image_size = config.dataset.image_size\n",
    "    config.model.seq_len = config.dataset.image_size[0] * config.dataset.image_size[1]\n",
    "    config.model.position_embedding = 'pos_enc'\n",
    "else:\n",
    "    config.model.seq_len = config.dataset.n_frames * config.dataset.n_dof\n",
    "    config.model.n_frames = config.dataset.n_frames\n",
    "    config.model.n_dof = config.dataset.n_dof\n",
    "    config.model.position_embedding = 'pos_and_embd'\n",
    "    \n",
    "\n",
    "if config.distributed == False:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.transformer(config.model)\n",
    "    # Adam params taken from the linked notebook\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=schedules.learning_rate_schedule(config))\n",
    "\n",
    "if config.distributed:\n",
    "    ds_train = strategy.experimental_distribute_dataset(ds_train)\n",
    "\n",
    "config.training_mode = 'query_next'\n",
    "\n",
    "import socket\n",
    "model_name = models.model_name(config)\n",
    "print(model_name)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "171f56f2-d010-4072-8f19-8f20e5224886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "(None, None)\n",
      "(None, None, 2)\n",
      " 806/1000 [=======================>......] - ETA: 18s - loss: 0.2286"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/maxeonyx/msc/msc-cgt-hands/notebook.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxeonyx/msc/msc-cgt-hands/notebook.ipynb#ch0000008?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mtraining\u001b[39m.\u001b[39mvon_mises_loss, optimizer\u001b[39m=\u001b[39moptimizer)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxeonyx/msc/msc-cgt-hands/notebook.ipynb#ch0000008?line=1'>2</a>\u001b[0m ds_train_keras_fit \u001b[39m=\u001b[39m ds_train\u001b[39m.\u001b[39mmap(training\u001b[39m.\u001b[39mds_input_to_keras(config))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/maxeonyx/msc/msc-cgt-hands/notebook.ipynb#ch0000008?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(ds_train_keras_fit, steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///usr/lib/python3.10/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=951'>952</a>\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=952'>953</a>\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=953'>954</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=954'>955</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=955'>956</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=956'>957</a>\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss=training.von_mises_loss, optimizer=optimizer)\n",
    "ds_train_keras_fit = ds_train.map(training.ds_input_to_keras(config))\n",
    "model.fit(ds_train_keras_fit, steps_per_epoch=1000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62aed9f-9442-46ac-884e-2dd4be134cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaler = training.Evaluator(config, model, optimizer, viz, ds, ds_train, ds_test)\n",
    "\n",
    "# training_loop = training.TrainingLoop(config, evaler, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d115b-dc33-4894-aa46-824a0446e2d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# with strategy.scope():\n",
    "#     training_loop.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5666655d-f24d-43c1-a085-a13d6df25fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_4 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/maxpc-hands-2layers-contin-bs1x1x8-righthand4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/maxpc-hands-2layers-contin-bs1x1x8-righthand4/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save(f\"models/{model_name}-righthand4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec3144-404e-4772-92f1-7038a1772270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if config.dataset.type == 'image':\n",
    "#     evaler.process_batch(show_input=True)\n",
    "#     evaler.new_test_batch()\n",
    "#     evaler.process_batch(show_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c19055-3dc4-460b-bc73-7555ddf1b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/home/maxeonyx/msc/msc-cgt-hands/manipnet/Data/SimpleVisualizer/Assets/BVH/bottle1_body1/rightHand.bvh\"\n",
    "\n",
    "# manager = enlighten.get_manager()\n",
    "\n",
    "# dof = 23\n",
    "# prev_frames = 30\n",
    "# n_frames_to_predict = 600\n",
    "\n",
    "# counter = manager.counter(total=n_frames_to_predict)\n",
    "\n",
    "# dof_idxs = tf.tile(tf.range(dof)[None, :], [prev_frames + 1, 1])\n",
    "# frame_idxs = tf.tile(tf.range(prev_frames + 1)[:, None], [1, dof]) * dof\n",
    "# idxs = dof_idxs + frame_idxs\n",
    "# idxs = tf.reshape(idxs, [-1])\n",
    "\n",
    "# def iteration(i, data):\n",
    "#     tar_idx = prev_frames*dof + i + 1\n",
    "#     inp_idxs = tf.range(i, prev_frames*dof + i)\n",
    "#     inp = data[-prev_frames*dof:]\n",
    "#     inp_len = tf.shape(inp_idxs)[0]\n",
    "#     tar_len = 1\n",
    "#     params = model({\n",
    "#         \"colors\": inp[None, :],\n",
    "#         \"inp_idxs\": inp_idxs[None, :],\n",
    "#         \"tar_idxs\": tar_idx[None, None],\n",
    "#         \"enc_mask\": models.get_mask(models.MASK_NONE, inp_len, inp_len),\n",
    "#         \"dec_mask\": models.get_mask(models.MASK_NONE, inp_len, tar_len),\n",
    "#     })\n",
    "#     dist = tfp.layers.MixtureNormal(num_components = 3, event_shape=[])(params)\n",
    "#     sample = dist.sample()\n",
    "#     sample = tf.reshape(sample, [-1])\n",
    "#     data = tf.concat([data, sample], axis=0)\n",
    "#     return i+1, data\n",
    "\n",
    "# @tf.function(\n",
    "#     input_signature=[tf.TensorSpec([None, dof])],\n",
    "# )\n",
    "# def do_batch(data):\n",
    "#     inp_data = tf.reshape(data[-prev_frames:, :], [prev_frames*dof])\n",
    "#     _i, out_data = tf.while_loop(\n",
    "#         cond=lambda i, data: i < dof,\n",
    "#         body=iteration,\n",
    "#         loop_vars=[\n",
    "#             tf.constant(0),\n",
    "#             inp_data\n",
    "#         ],\n",
    "#         shape_invariants=[\n",
    "#             tf.TensorShape([]),\n",
    "#             tf.TensorShape([None]),\n",
    "#         ],\n",
    "#     )\n",
    "#     return tf.reshape(out_data[-dof:], [1, dof])\n",
    "\n",
    "# test_data = tf.cast(create_dataset.load_one_bvh_file(filename, convert_deg_to_rad=True), tf.float32)\n",
    "# generated_data = test_data[:prev_frames, :]\n",
    "# for i in counter(range(n_frames_to_predict)):\n",
    "#     result = do_batch(generated_data)\n",
    "#     generated_data = tf.concat([generated_data, result], axis=0)\n",
    "\n",
    "# counter.close()\n",
    "\n",
    "# print(generated_data)\n",
    "\n",
    "# import create_dataset\n",
    "# create_dataset.write_bvh_file(filename, generated_data.numpy(), convert_rad_to_deg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ffeacb-7ace-440f-9338-80db930ccf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# np.save(\"/home/maxeonyx/gen_data\", generated_data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1409c9e6-9857-49e0-863e-97d4060fe06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a110310-ed51-43cc-9a8c-e56544e98d55",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
