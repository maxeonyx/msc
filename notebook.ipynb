{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a247b8c3-1a9d-42c1-bc9a-41c99ed78357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# print(physical_devices)\n",
    "assert len(physical_devices) == 1, \"Did not see the expected number of GPUs\"\n",
    "# to allow other tensorflow processes to use the gpu\n",
    "# https://stackoverflow.com/a/60699372/7989988\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "from IPython.display import display\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import enlighten\n",
    "import tensorflow_probability as tfp\n",
    "# from dotmap import DotMap\n",
    "from box import Box as DotMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8586c67e-f8cb-40d8-a136-b72c0f1de74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=bool, numpy=array([ True,  True, False])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([1., 2, 3]) < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9d8b7f-1fa3-4787-8eb7-a341e673ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import training\n",
    "import datasets\n",
    "import vizualization\n",
    "import schedules\n",
    "import create_dataset\n",
    "\n",
    "# todo\n",
    "# - combine shuffled and unshuffled datasets into same thing\n",
    "# - add extra shuffled indices and noise\n",
    "# - add \"noise fraction\" parameter which can be changed the same way as the \"n\" parameter.\n",
    "# - add different amounts of noise to the data and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9664a41e-2373-4007-ad5b-04367635212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DotMap({\n",
    "    'ds': 'hands',\n",
    "    'distributed': False,\n",
    "    'minibatch_size': 8,\n",
    "    'n_steps': 50000,\n",
    "    'test_size': 300,\n",
    "    'test_minibatch_size': 25,\n",
    "    'test_interval': 500,\n",
    "    'test_n_shuf': [392, 1, 64, 128, 256],\n",
    "    'test_n_seq': [392, 1, 128, 256, 512],\n",
    "    'test_autoregressive': False,\n",
    "    'display_images': True,\n",
    "    'display_image_interval': 500,\n",
    "    'dont_display_until_loss': 0.48,\n",
    "    'bg_color': [1.0, 0.4, 0.6],\n",
    "    'lr_schedule': ['constant', 0.0004],\n",
    "    'lr_warmup': 100,\n",
    "    'grad_accum_steps': None, #['exponential', 1, 4],\n",
    "    'max_accum_steps': 4,\n",
    "    'use_wandb': False,\n",
    "    'wandb_log_interval': 10,\n",
    "    'loss_window_size': 80,\n",
    "    'kmeans_batch_size': 1000,\n",
    "    'mixed_float': False,\n",
    "})\n",
    "\n",
    "# need to change for multiworkerstrategy\n",
    "if config.distributed:\n",
    "    config.num_devices = len(physical_devices)\n",
    "else:\n",
    "    config.num_devices = 1\n",
    "config.global_batch_size = config.minibatch_size * config.num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee847f8-c7e5-4889-af95-b4e635213d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forcing generation of a fresh dataset to \"./cached_dataset/\" ...\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'manipnet/Data/SimpleVisualizer/Assets/BVH/wineglass3_2/rightHand.bvh'>, <tf.Tensor: shape=(), dtype=int32, numpy=8000>, <tf.Tensor: shape=(8000, 23), dtype=float32, numpy=\n",
      "array([[-153.593   ,   13.43651 ,  -42.00934 , ...,  167.1838  ,\n",
      "         -30.63354 ,   52.14901 ],\n",
      "       [-153.6917  ,   13.69398 ,  -41.72995 , ...,  167.0725  ,\n",
      "         -29.95093 ,   53.39282 ],\n",
      "       [-153.6931  ,   13.86723 ,  -41.52698 , ...,  167.0263  ,\n",
      "         -29.72571 ,   54.29317 ],\n",
      "       ...,\n",
      "       [ -76.4584  ,  -78.03699 ,  -51.57129 , ...,  150.5776  ,\n",
      "          -2.118958,   12.46723 ],\n",
      "       [ -75.01645 ,  -78.0997  ,  -53.06293 , ...,  150.7132  ,\n",
      "          -2.264648,   12.90956 ],\n",
      "       [ -73.41113 ,  -78.03735 ,  -54.68829 , ...,  150.9352  ,\n",
      "          -2.807251,   12.95555 ]], dtype=float32)>, <tf.Tensor: shape=(), dtype=bool, numpy=True>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| datasets.py:324 in make_datasets() at 12:36:47.083\n",
      "ic| datasets.py:346 in make_datasets() at 12:36:47.221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using gradient accumulation\n"
     ]
    }
   ],
   "source": [
    "# idea is to not have to re-run this cell for subsequent training runs unless the centroids change\n",
    "\n",
    "ds_configs = DotMap({\n",
    "    'mnist': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_gamma',\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'image_size': (28, 28),\n",
    "    },\n",
    "    'mnist_7x7': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_7x7_gamma',\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'mnist_7x7_contin': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': None,\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'mnist_binary_7x7': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_7x7_gamma',\n",
    "        'n_colors': 2,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'celeb': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'celeb_a',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_colors': 16,\n",
    "        'n_split_distribution': 'mnist_gamma',\n",
    "        'n_color_dims': 3,\n",
    "        'image_size': (218, 178),\n",
    "        'rescale': (32, 39),\n",
    "    },\n",
    "    'hands': {\n",
    "        'type': 'hands',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'shuffle': 'joints',\n",
    "        'n_dof': 23,\n",
    "        'n_frames': 30,\n",
    "        'n_split_distribution': None,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "    },\n",
    "    'hands_lstm': {\n",
    "        'type': 'hands',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'shuffle': 'joints',\n",
    "        'n_dof': 23,\n",
    "        'n_frames': 4000,\n",
    "        'n_split_distribution': None,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "        'resample_time': 10,\n",
    "    },\n",
    "})\n",
    "\n",
    "config.dataset = ds_configs[config.ds]\n",
    "config.dataset.discrete = not config.dataset.continuous\n",
    "\n",
    "if config.dataset.type == 'image':\n",
    "    dataset, metadata = tfds.load(config.dataset.tfds_name, with_info=True, as_supervised=True)\n",
    "    ds_train_original = dataset['train'].map(datasets.ignore_label)\n",
    "    ds_test_original = dataset['test'].map(datasets.ignore_label)\n",
    "    centroids = datasets.find_centroids(config, ds_train_original)\n",
    "    if config.dataset.rescale:\n",
    "        config.dataset.image_size = config.dataset.rescale\n",
    "    config.dataset.seq_length = config.dataset.image_size[0]*config.dataset.image_size[1]*config.dataset.n_color_dims\n",
    "elif config.dataset.type == 'hands':\n",
    "    dataset = create_dataset.tf_dataset(force=True)\n",
    "    centroids = None\n",
    "    # ignore left hands\n",
    "    print(next(iter(dataset)))\n",
    "    dataset = dataset.filter(datasets.is_right_hand)\n",
    "    dataset = dataset.map(datasets.ignore_metadata)\n",
    "\n",
    "    # TODO: split test and train\n",
    "    ds_train_original = dataset\n",
    "    ds_test_original = dataset\n",
    "\n",
    "    config.dataset.seq_length = config.dataset.n_dof * config.dataset.n_frames\n",
    "    \n",
    "if config.dataset.n_split_distribution == 'mnist_gamma':\n",
    "    gamma_dist, gamma_name = datasets.mnist_gamma_distribution()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "elif config.dataset.n_split_distribution == 'mnist_7x7_gamma':\n",
    "    gamma_dist, gamma_name = datasets.gamma_distribution_7x7()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "elif config.dataset.n_split_distribution == 'mnist_12x12_gamma':\n",
    "    gamma_dist, gamma_name = datasets.gamma_distribution_12x12()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "else:\n",
    "    gamma_dist, gamma_name = None, None\n",
    "\n",
    "\n",
    "ds = datasets.Datasets(config, ds_train_original, ds_test_original, centroids, gamma_dist)\n",
    "viz = vizualization.Viz(config, ds, centroids)\n",
    "ds_train, ds_test = ds.make_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462f03d4-5dbc-4c9e-b1a5-2f70381fbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset.type == 'image':\n",
    "    display_colors, display_idxs, *_ = next(iter(ds_train))\n",
    "    if config.grad_accum_steps:\n",
    "        display_colors,display_idxs = display_colors[0],display_idxs[0]\n",
    "    if config.dataset.continuous:\n",
    "        display_colors = ds.reinvent_color_dim(display_colors)\n",
    "    viz.showSeq(display_colors, display_idxs, config.dataset.image_size, do_unquantize=config.dataset.discrete, max_images=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cffaf944-1a78-4029-99bd-04c99a9fbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset.type == 'image':\n",
    "    x_idx = tf.range(784)\n",
    "    pos_enc = models.pos_enc(n_dims=16, scale=100)\n",
    "    x = models.dual_positional_encoding((28,28), pos_enc)(x_idx)\n",
    "    x = x / 2. + 0.5\n",
    "    x = tf.expand_dims(tf.transpose(x), -1)\n",
    "    x_idx = tf.tile(x_idx[None, :], [16, 1])\n",
    "    viz.showSeq(x[:8], x_idx[:8], (28, 28), 8)\n",
    "    viz.showSeq(x[8:16], x_idx[8:16], (28, 28), 8)\n",
    "    viz.showSeq(x[16:24], x_idx[16:24], (28, 28), 8)\n",
    "    viz.showSeq(x[24:], x_idx[24:], (28, 28), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "636a3bbc-bc94-4fa4-9966-45fd3e96fa02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda10-hands-gpt-1layer-contin-bs1x1x8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model config\n",
    "config.model = DotMap({\n",
    "    'comment': '1layer',\n",
    "    'discrete': config.dataset.discrete,\n",
    "    'continuous': config.dataset.continuous,\n",
    "    'n_enc_a_layers': 1,\n",
    "    'n_enc_b_layers': 0,\n",
    "    'ffl_dim': 64,\n",
    "    'embd_dim': 64,\n",
    "    'n_dec_layers': 1,\n",
    "    'dec_dim': 400,\n",
    "    'n_heads': 8,\n",
    "    'dropout_rate': 0.1,\n",
    "    'use_idxs_input': True,\n",
    "    'architecture': 'gpt',\n",
    "    'use_relative_positions': False,\n",
    "    'activation': 'swish'\n",
    "})\n",
    "\n",
    "if config.model.continuous:\n",
    "    config.model.distribution = config.dataset.loss\n",
    "    config.model.n_dist_params = config.dataset.n_dist_params\n",
    "\n",
    "if config.dataset.type == 'image':\n",
    "    config.model.n_colors = config.dataset.n_colors\n",
    "    config.model.n_color_dims = config.dataset.n_color_dims\n",
    "    config.model.image_size = config.dataset.image_size\n",
    "    config.model.seq_len = config.dataset.image_size[0] * config.dataset.image_size[1]\n",
    "    config.model.position_embedding = 'pos_enc'\n",
    "else:\n",
    "    config.model.seq_len = config.dataset.n_frames * config.dataset.n_dof\n",
    "    config.model.n_frames = config.dataset.n_frames\n",
    "    config.model.n_dof = config.dataset.n_dof\n",
    "    config.model.position_embedding = 'pos_and_embd'\n",
    "    config.model.loc_scale = False\n",
    "    config.model.scalar = True\n",
    "    \n",
    "\n",
    "if config.distributed == False:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.transformer(config.model)\n",
    "    # Adam params taken from the linked notebook\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=schedules.learning_rate_schedule(config))\n",
    "\n",
    "if config.distributed:\n",
    "    ds_train = strategy.experimental_distribute_dataset(ds_train)\n",
    "\n",
    "config.training_mode = 'query_next'\n",
    "\n",
    "import socket\n",
    "model_name = models.model_name(config)\n",
    "print(model_name)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c19055-3dc4-460b-bc73-7555ddf1b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/local/scratch/maxeonyx/msc-cgt-hands/manipnet/Data/SimpleVisualizer/Assets/BVH/bottle1_body1/rightHand.bvh\"\n",
    "\n",
    "dof = 23\n",
    "\n",
    "def generate_data(conditioning_data, window_frames, new_frames):\n",
    "    manager = enlighten.get_manager()\n",
    "    \n",
    "    # model = tf.keras.models.load_model(\n",
    "    #     \"/home/maxeonyx/msc/msc-cgt-hands/models/maxpc-hands-2layers-contin-bs1x1x8-righthand2\",\n",
    "    #     custom_objects={\n",
    "    #         'negloglik': training.negloglik,\n",
    "    #         'von_mises_loss': training.von_mises_loss\n",
    "    #     },\n",
    "    # )\n",
    "\n",
    "    conditioning_data = tf.cast(conditioning_data, tf.float32)\n",
    "\n",
    "    prev_frames = min(window_frames, conditioning_data.shape[0])\n",
    "    n_frames_to_predict = new_frames\n",
    "\n",
    "    counter = manager.counter(total=n_frames_to_predict*dof)\n",
    "    # wm.progress_begin(0, n_frames_to_predict*dof)\n",
    "\n",
    "    dof_idxs = tf.tile(tf.range(dof)[None, :], [prev_frames + 1, 1])\n",
    "    frame_idxs = tf.tile(tf.range(prev_frames + 1)[:, None], [1, dof]) * dof\n",
    "    idxs = dof_idxs + frame_idxs\n",
    "    idxs = tf.reshape(idxs, [-1])\n",
    "\n",
    "    def iteration(i, data):\n",
    "        tar_idx = prev_frames*dof + i + 1\n",
    "        inp_idxs = tf.range(i, prev_frames*dof + i)\n",
    "        inp = data[-prev_frames*dof:]\n",
    "        inp_len = tf.shape(inp_idxs)[0]\n",
    "        tar_len = 1\n",
    "        pred_params = model({\n",
    "            \"colors\": inp[None, :],\n",
    "            \"inp_idxs\": inp_idxs[None, :],\n",
    "            \"tar_idxs\": tar_idx[None, None],\n",
    "            \"enc_mask\": tf.zeros((inp_len, inp_len)),\n",
    "            \"dec_mask\": tf.zeros((tar_len, inp_len)),\n",
    "        })\n",
    "\n",
    "        loc = pred_params[:, :, 0]\n",
    "        # concentration = pred_params[:, :, 1]\n",
    "\n",
    "        # dist = tfp.distributions.VonMises(loc=loc, concentration=concentration)\n",
    "        # sample = dist.mean()\n",
    "        sample = loc\n",
    "        sample = tf.reshape(sample, [-1])\n",
    "        data = tf.concat([data, sample], axis=0)\n",
    "        return i+1, data\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=[tf.TensorSpec([None, dof])],\n",
    "    )\n",
    "    def do_batch(data):\n",
    "        inp_data = tf.reshape(data[-prev_frames:, :], [prev_frames*dof])\n",
    "        _i, out_data = tf.while_loop(\n",
    "            cond=lambda i, data: i < dof,\n",
    "            body=iteration,\n",
    "            loop_vars=[\n",
    "                tf.constant(0),\n",
    "                inp_data\n",
    "            ],\n",
    "            shape_invariants=[\n",
    "                tf.TensorShape([]),\n",
    "                tf.TensorShape([None]),\n",
    "            ],\n",
    "        )\n",
    "        return tf.reshape(out_data[-dof:], [1, dof])\n",
    "\n",
    "#    test_data = tf.cast(create_dataset.load_one_bvh_file(filename, convert_deg_to_rad=True), tf.float32)\n",
    "    generated_data = conditioning_data[:prev_frames, :]\n",
    "    for i in range(n_frames_to_predict):\n",
    "        result = do_batch(generated_data)\n",
    "        generated_data = tf.concat([generated_data, result], axis=0)\n",
    "        counter.update(incr=dof)\n",
    "        # wm.progress_update(i*dof)\n",
    "    counter.close()\n",
    "\n",
    "    return generated_data\n",
    "\n",
    "test_data = tf.cast(create_dataset.load_one_bvh_file(filename, convert_deg_to_rad=True), tf.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fcee4a5-49f8-443d-a2c1-0792eb208eaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     ax\u001b[38;5;241m.\u001b[39mimshow(tf\u001b[38;5;241m.\u001b[39mtranspose(reclustered_data))\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPlotCallback\u001b[39;00m(\u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mCallback):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m         gen_fig()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "def gen_fig():\n",
    "    generated_data = generate_data(test_data, 30, 30)\n",
    "    reclustered_data = ds.recluster(generated_data)\n",
    "    _fig, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.imshow(tf.transpose(reclustered_data))\n",
    "    plt.show()\n",
    "\n",
    "class PlotCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gen_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "171f56f2-d010-4072-8f19-8f20e5224886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0114"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>100%|██████████████████████████████████████████████████████████████| 690/690 [00:02&lt;00:00, 393.26/s]</pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 18s 15ms/step - loss: 0.0114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91e44095b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model.compile(loss=training.von_mises_loss, optimizer=optimizer)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "ds_train_keras_fit = ds_train.map(training.ds_input_to_keras(config))\n",
    "model.fit(ds_train_keras_fit, steps_per_epoch=1000, epochs=1, callbacks=[PlotCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d62aed9f-9442-46ac-884e-2dd4be134cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>100%|██████████████████████████████████████████████████████████████| 690/690 [00:02&lt;00:00, 389.59/s]</pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5666655d-f24d-43c1-a085-a13d6df25fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_4 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/cuda10-hands-gpt-1layer-contin-bs1x1x8-may26-2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/cuda10-hands-gpt-1layer-contin-bs1x1x8-may26-2/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save(f\"models/{model_name}-may26-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1409c9e6-9857-49e0-863e-97d4060fe06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample(pred_params):\n",
    "    mean = pred_params[:, :, 0]\n",
    "\n",
    "#        # sample from a distribution\n",
    "#        concentration = pred_params[:, :, 1]\n",
    "\n",
    "#        dist = tfp.distributions.VonMises(loc=loc, concentration=concentration)\n",
    "#        sample = dist.sample()\n",
    "\n",
    "    # point estimate\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845e4adc-0c0f-4a3b-bdd6-389c57a47a69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m conditioning_data \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\u001b[43mcreate_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mload_one_bvh_file(filename, convert_deg_to_rad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      2\u001b[0m conditioning_data\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "conditioning_data = tf.cast(create_dataset.load_one_bvh_file(filename, convert_deg_to_rad=True), tf.float32)\n",
    "conditioning_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a110310-ed51-43cc-9a8c-e56544e98d55",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
