{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a247b8c3-1a9d-42c1-bc9a-41c99ed78357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Found 0 GPUs instead of 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(physical_devices)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m expected_num_gpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(physical_devices) \u001b[38;5;241m==\u001b[39m expected_num_gpus, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(physical_devices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GPUs instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_num_gpus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# to allow other tensorflow processes to use the gpu\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# https://stackoverflow.com/a/60699372/7989988\u001b[39;00m\n\u001b[1;32m     15\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mset_memory_growth(physical_devices[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Found 0 GPUs instead of 1"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# print(physical_devices)\n",
    "expected_num_gpus = 1\n",
    "assert len(physical_devices) == expected_num_gpus, f\"Found {len(physical_devices)} GPUs instead of {expected_num_gpus}\"\n",
    "# to allow other tensorflow processes to use the gpu\n",
    "# https://stackoverflow.com/a/60699372/7989988\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "from IPython.display import display\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import enlighten\n",
    "import tensorflow_probability as tfp\n",
    "# from dotmap import DotMap\n",
    "from box import Box as DotMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586c67e-f8cb-40d8-a136-b72c0f1de74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant([1., 2, 3]) < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d8b7f-1fa3-4787-8eb7-a341e673ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import training\n",
    "import datasets\n",
    "import vizualization\n",
    "import schedules\n",
    "import create_dataset\n",
    "\n",
    "# todo\n",
    "# - combine shuffled and unshuffled datasets into same thing\n",
    "# - add extra shuffled indices and noise\n",
    "# - add \"noise fraction\" parameter which can be changed the same way as the \"n\" parameter.\n",
    "# - add different amounts of noise to the data and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664a41e-2373-4007-ad5b-04367635212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DotMap({\n",
    "    'ds': 'hands',\n",
    "    'distributed': False,\n",
    "    'minibatch_size': 8,\n",
    "    'n_steps': 50000,\n",
    "    'test_size': 300,\n",
    "    'test_minibatch_size': 25,\n",
    "    'test_interval': 500,\n",
    "    'test_n_shuf': [392, 1, 64, 128, 256],\n",
    "    'test_n_seq': [392, 1, 128, 256, 512],\n",
    "    'test_autoregressive': False,\n",
    "    'display_images': True,\n",
    "    'display_image_interval': 500,\n",
    "    'dont_display_until_loss': 0.48,\n",
    "    'bg_color': [1.0, 0.4, 0.6],\n",
    "    'lr_schedule': ['constant', 0.0004],\n",
    "    'lr_warmup': 100,\n",
    "    'grad_accum_steps': None, #['exponential', 1, 4],\n",
    "    'max_accum_steps': 4,\n",
    "    'use_wandb': False,\n",
    "    'wandb_log_interval': 10,\n",
    "    'loss_window_size': 80,\n",
    "    'kmeans_batch_size': 1000,\n",
    "    'mixed_float': False,\n",
    "})\n",
    "\n",
    "# need to change for multiworkerstrategy\n",
    "if config.distributed:\n",
    "    config.num_devices = len(physical_devices)\n",
    "else:\n",
    "    config.num_devices = 1\n",
    "config.global_batch_size = config.minibatch_size * config.num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee847f8-c7e5-4889-af95-b4e635213d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea is to not have to re-run this cell for subsequent training runs unless the centroids change\n",
    "\n",
    "ds_configs = DotMap({\n",
    "    'mnist': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_gamma',\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'image_size': (28, 28),\n",
    "    },\n",
    "    'mnist_7x7': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_7x7_gamma',\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'mnist_7x7_contin': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': None,\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'mnist_binary_7x7': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_7x7_gamma',\n",
    "        'n_colors': 2,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'celeb': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'celeb_a',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_colors': 16,\n",
    "        'n_split_distribution': 'mnist_gamma',\n",
    "        'n_color_dims': 3,\n",
    "        'image_size': (218, 178),\n",
    "        'rescale': (32, 39),\n",
    "    },\n",
    "    'hands': {\n",
    "        'type': 'hands',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'shuffle': 'joints',\n",
    "        'n_dof': 23,\n",
    "        'n_frames': 30,\n",
    "        'n_split_distribution': None,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "    },\n",
    "    'hands_lstm': {\n",
    "        'type': 'hands',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'shuffle': 'joints',\n",
    "        'n_dof': 23,\n",
    "        'n_frames': 4000,\n",
    "        'n_split_distribution': None,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "        'resample_time': 10,\n",
    "    },\n",
    "})\n",
    "\n",
    "config.dataset = ds_configs[config.ds]\n",
    "config.dataset.discrete = not config.dataset.continuous\n",
    "\n",
    "if config.dataset.type == 'image':\n",
    "    dataset, metadata = tfds.load(config.dataset.tfds_name, with_info=True, as_supervised=True)\n",
    "    ds_train_original = dataset['train'].map(datasets.ignore_label)\n",
    "    ds_test_original = dataset['test'].map(datasets.ignore_label)\n",
    "    centroids = datasets.find_centroids(config, ds_train_original)\n",
    "    if config.dataset.rescale:\n",
    "        config.dataset.image_size = config.dataset.rescale\n",
    "    config.dataset.seq_length = config.dataset.image_size[0]*config.dataset.image_size[1]*config.dataset.n_color_dims\n",
    "elif config.dataset.type == 'hands':\n",
    "    dataset = create_dataset.tf_dataset(force=True)\n",
    "    centroids = None\n",
    "    # ignore left hands\n",
    "    print(next(iter(dataset)))\n",
    "    dataset = dataset.filter(datasets.is_right_hand)\n",
    "    dataset = dataset.map(datasets.ignore_metadata)\n",
    "\n",
    "    # TODO: split test and train\n",
    "    ds_train_original = dataset\n",
    "    ds_test_original = dataset\n",
    "\n",
    "    config.dataset.seq_length = config.dataset.n_dof * config.dataset.n_frames\n",
    "    \n",
    "if config.dataset.n_split_distribution == 'mnist_gamma':\n",
    "    gamma_dist, gamma_name = datasets.mnist_gamma_distribution()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "elif config.dataset.n_split_distribution == 'mnist_7x7_gamma':\n",
    "    gamma_dist, gamma_name = datasets.gamma_distribution_7x7()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "elif config.dataset.n_split_distribution == 'mnist_12x12_gamma':\n",
    "    gamma_dist, gamma_name = datasets.gamma_distribution_12x12()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "else:\n",
    "    gamma_dist, gamma_name = None, None\n",
    "\n",
    "\n",
    "ds = datasets.Datasets(config, ds_train_original, ds_test_original, centroids, gamma_dist)\n",
    "viz = vizualization.Viz(config, ds, centroids)\n",
    "ds_train, ds_test = ds.make_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462f03d4-5dbc-4c9e-b1a5-2f70381fbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset.type == 'image':\n",
    "    display_colors, display_idxs, *_ = next(iter(ds_train))\n",
    "    if config.grad_accum_steps:\n",
    "        display_colors,display_idxs = display_colors[0],display_idxs[0]\n",
    "    if config.dataset.continuous:\n",
    "        display_colors = ds.reinvent_color_dim(display_colors)\n",
    "    viz.showSeq(display_colors, display_idxs, config.dataset.image_size, do_unquantize=config.dataset.discrete, max_images=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffaf944-1a78-4029-99bd-04c99a9fbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset.type == 'image':\n",
    "    x_idx = tf.range(784)\n",
    "    pos_enc = models.pos_enc(n_dims=16, scale=100)\n",
    "    x = models.dual_positional_encoding((28,28), pos_enc)(x_idx)\n",
    "    x = x / 2. + 0.5\n",
    "    x = tf.expand_dims(tf.transpose(x), -1)\n",
    "    x_idx = tf.tile(x_idx[None, :], [16, 1])\n",
    "    viz.showSeq(x[:8], x_idx[:8], (28, 28), 8)\n",
    "    viz.showSeq(x[8:16], x_idx[8:16], (28, 28), 8)\n",
    "    viz.showSeq(x[16:24], x_idx[16:24], (28, 28), 8)\n",
    "    viz.showSeq(x[24:], x_idx[24:], (28, 28), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a3bbc-bc94-4fa4-9966-45fd3e96fa02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model config\n",
    "config.model = DotMap({\n",
    "    'comment': '1layer',\n",
    "    'discrete': config.dataset.discrete,\n",
    "    'continuous': config.dataset.continuous,\n",
    "    'n_enc_a_layers': 1,\n",
    "    'n_enc_b_layers': 0,\n",
    "    'ffl_dim': 64,\n",
    "    'embd_dim': 64,\n",
    "    'n_dec_layers': 1,\n",
    "    'dec_dim': 400,\n",
    "    'n_heads': 8,\n",
    "    'dropout_rate': 0.1,\n",
    "    'use_idxs_input': True,\n",
    "    'architecture': 'gpt',\n",
    "    'use_relative_positions': False,\n",
    "    'activation': 'swish'\n",
    "})\n",
    "\n",
    "if config.model.continuous:\n",
    "    config.model.distribution = config.dataset.loss\n",
    "    config.model.n_dist_params = config.dataset.n_dist_params\n",
    "\n",
    "if config.dataset.type == 'image':\n",
    "    config.model.n_colors = config.dataset.n_colors\n",
    "    config.model.n_color_dims = config.dataset.n_color_dims\n",
    "    config.model.image_size = config.dataset.image_size\n",
    "    config.model.seq_len = config.dataset.image_size[0] * config.dataset.image_size[1]\n",
    "    config.model.position_embedding = 'pos_enc'\n",
    "else:\n",
    "    config.model.seq_len = config.dataset.n_frames * config.dataset.n_dof\n",
    "    config.model.n_frames = config.dataset.n_frames\n",
    "    config.model.n_dof = config.dataset.n_dof\n",
    "    config.model.position_embedding = 'pos_and_embd'\n",
    "    config.model.loc_scale = False\n",
    "    config.model.scalar = True\n",
    "    \n",
    "\n",
    "if config.distributed == False:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.lstm(config.model)\n",
    "    # Adam params taken from the linked notebook\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=schedules.learning_rate_schedule(config))\n",
    "\n",
    "if config.distributed:\n",
    "    ds_train = strategy.experimental_distribute_dataset(ds_train)\n",
    "\n",
    "config.training_mode = 'query_next'\n",
    "\n",
    "import socket\n",
    "model_name = models.model_name(config)\n",
    "print(model_name)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c19055-3dc4-460b-bc73-7555ddf1b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/local/scratch/maxeonyx/msc-cgt-hands/manipnet/Data/SimpleVisualizer/Assets/BVH/bottle1_body1/rightHand.bvh\"\n",
    "\n",
    "dof = 23\n",
    "\n",
    "def generate_data(conditioning_data, window_frames, new_frames):\n",
    "    manager = enlighten.get_manager()\n",
    "    \n",
    "    # model = tf.keras.models.load_model(\n",
    "    #     \"/home/maxeonyx/msc/msc-cgt-hands/models/maxpc-hands-2layers-contin-bs1x1x8-righthand2\",\n",
    "    #     custom_objects={\n",
    "    #         'negloglik': training.negloglik,\n",
    "    #         'von_mises_loss': training.von_mises_loss\n",
    "    #     },\n",
    "    # )\n",
    "\n",
    "    conditioning_data = tf.cast(conditioning_data, tf.float32)\n",
    "\n",
    "    prev_frames = min(window_frames, conditioning_data.shape[0])\n",
    "    n_frames_to_predict = new_frames\n",
    "\n",
    "    counter = manager.counter(total=n_frames_to_predict*dof)\n",
    "    # wm.progress_begin(0, n_frames_to_predict*dof)\n",
    "\n",
    "    dof_idxs = tf.tile(tf.range(dof)[None, :], [prev_frames + 1, 1])\n",
    "    frame_idxs = tf.tile(tf.range(prev_frames + 1)[:, None], [1, dof]) * dof\n",
    "    idxs = dof_idxs + frame_idxs\n",
    "    idxs = tf.reshape(idxs, [-1])\n",
    "\n",
    "    def iteration(i, data):\n",
    "        tar_idx = prev_frames*dof + i + 1\n",
    "        inp_idxs = tf.range(i, prev_frames*dof + i)\n",
    "        inp = data[-prev_frames*dof:]\n",
    "        inp_len = tf.shape(inp_idxs)[0]\n",
    "        tar_len = 1\n",
    "        pred_params = model({\n",
    "            \"colors\": inp[None, :],\n",
    "            \"inp_idxs\": inp_idxs[None, :],\n",
    "            \"tar_idxs\": tar_idx[None, None],\n",
    "            \"enc_mask\": tf.zeros((inp_len, inp_len)),\n",
    "            \"dec_mask\": tf.zeros((tar_len, inp_len)),\n",
    "        })\n",
    "\n",
    "        loc = pred_params[:, :, 0]\n",
    "        # concentration = pred_params[:, :, 1]\n",
    "\n",
    "        # dist = tfp.distributions.VonMises(loc=loc, concentration=concentration)\n",
    "        # sample = dist.mean()\n",
    "        sample = loc\n",
    "        sample = tf.reshape(sample, [-1])\n",
    "        data = tf.concat([data, sample], axis=0)\n",
    "        return i+1, data\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=[tf.TensorSpec([None, dof])],\n",
    "    )\n",
    "    def do_batch(data):\n",
    "        inp_data = tf.reshape(data[-prev_frames:, :], [prev_frames*dof])\n",
    "        _i, out_data = tf.while_loop(\n",
    "            cond=lambda i, data: i < dof,\n",
    "            body=iteration,\n",
    "            loop_vars=[\n",
    "                tf.constant(0),\n",
    "                inp_data\n",
    "            ],\n",
    "            shape_invariants=[\n",
    "                tf.TensorShape([]),\n",
    "                tf.TensorShape([None]),\n",
    "            ],\n",
    "        )\n",
    "        return tf.reshape(out_data[-dof:], [1, dof])\n",
    "\n",
    "#    test_data = tf.cast(create_dataset.load_one_bvh_file(filename, convert_deg_to_rad=True), tf.float32)\n",
    "    generated_data = conditioning_data[:prev_frames, :]\n",
    "    for i in range(n_frames_to_predict):\n",
    "        result = do_batch(generated_data)\n",
    "        generated_data = tf.concat([generated_data, result], axis=0)\n",
    "        counter.update(incr=dof)\n",
    "        # wm.progress_update(i*dof)\n",
    "    counter.close()\n",
    "\n",
    "    return generated_data\n",
    "\n",
    "test_data = tf.cast(create_dataset.load_one_bvh_file(filename, convert_deg_to_rad=True), tf.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcee4a5-49f8-443d-a2c1-0792eb208eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fig():\n",
    "    generated_data = generate_data(test_data, 30, 30)\n",
    "    reclustered_data = ds.recluster(generated_data)\n",
    "    _fig, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.imshow(tf.transpose(reclustered_data))\n",
    "    plt.show()\n",
    "\n",
    "class PlotCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gen_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f56f2-d010-4072-8f19-8f20e5224886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.compile(loss=training.von_mises_loss, optimizer=optimizer)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "ds_train_keras_fit = ds_train.map(training.ds_input_to_keras(config))\n",
    "model.fit(ds_train_keras_fit, steps_per_epoch=1000, epochs=1, callbacks=[PlotCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62aed9f-9442-46ac-884e-2dd4be134cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5666655d-f24d-43c1-a085-a13d6df25fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(f\"models/{model_name}-may26-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1409c9e6-9857-49e0-863e-97d4060fe06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample(pred_params):\n",
    "    mean = pred_params[:, :, 0]\n",
    "\n",
    "#        # sample from a distribution\n",
    "#        concentration = pred_params[:, :, 1]\n",
    "\n",
    "#        dist = tfp.distributions.VonMises(loc=loc, concentration=concentration)\n",
    "#        sample = dist.sample()\n",
    "\n",
    "    # point estimate\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e4adc-0c0f-4a3b-bdd6-389c57a47a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditioning_data = tf.cast(create_dataset.load_one_bvh_file(filename, convert_deg_to_rad=True), tf.float32)\n",
    "conditioning_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a110310-ed51-43cc-9a8c-e56544e98d55",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
