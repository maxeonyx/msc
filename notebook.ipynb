{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a247b8c3-1a9d-42c1-bc9a-41c99ed78357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 16:24:21.194005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 16:24:21.222326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 16:24:21.222527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# print(physical_devices)\n",
    "assert len(physical_devices) == 1, \"Did not see the expected number of GPUs\"\n",
    "# to allow other tensorflow processes to use the gpu\n",
    "# https://stackoverflow.com/a/60699372/7989988\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], False)\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "from IPython.display import display\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import enlighten\n",
    "import tensorflow_probability as tfp\n",
    "# from dotmap import DotMap\n",
    "from box import Box as DotMap\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8586c67e-f8cb-40d8-a136-b72c0f1de74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 16:24:22.096559: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-20 16:24:22.097257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 16:24:22.097451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 16:24:22.097587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 16:24:22.423297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 16:24:22.423472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 16:24:22.423611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 16:24:22.423746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3766 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:26:00.0, compute capability: 7.5\n",
      "2022-03-20 16:24:22.424007: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=bool, numpy=array([ True,  True, False])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([1., 2, 3]) < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9d8b7f-1fa3-4787-8eb7-a341e673ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import training\n",
    "import datasets\n",
    "import vizualization\n",
    "import schedules\n",
    "import create_dataset\n",
    "\n",
    "# todo\n",
    "# - combine shuffled and unshuffled datasets into same thing\n",
    "# - add extra shuffled indices and noise\n",
    "# - add \"noise fraction\" parameter which can be changed the same way as the \"n\" parameter.\n",
    "# - add different amounts of noise to the data and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9664a41e-2373-4007-ad5b-04367635212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DotMap({\n",
    "    'ds': 'hands',\n",
    "    'distributed': False,\n",
    "    'minibatch_size': 8,\n",
    "    'n_steps': 50000,\n",
    "    'test_size': 300,\n",
    "    'test_minibatch_size': 25,\n",
    "    'test_interval': 500,\n",
    "    'test_n_shuf': [392, 1, 64, 128, 256],\n",
    "    'test_n_seq': [392, 1, 128, 256, 512],\n",
    "    'test_autoregressive': False,\n",
    "    'display_images': True,\n",
    "    'display_image_interval': 500,\n",
    "    'dont_display_until_loss': 0.48,\n",
    "    'bg_color': [1.0, 0.4, 0.6],\n",
    "    'lr_schedule': ['constant', 0.0004],\n",
    "    'lr_warmup': 100,\n",
    "    'grad_accum_steps': None, #['exponential', 1, 4],\n",
    "    'max_accum_steps': 4,\n",
    "    'use_wandb': False,\n",
    "    'wandb_log_interval': 10,\n",
    "    'loss_window_size': 80,\n",
    "    'kmeans_batch_size': 1000,\n",
    "    'mixed_float': False,\n",
    "})\n",
    "\n",
    "# need to change for multiworkerstrategy\n",
    "if config.distributed:\n",
    "    config.num_devices = len(physical_devices)\n",
    "else:\n",
    "    config.num_devices = 1\n",
    "config.global_batch_size = config.minibatch_size * config.num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee847f8-c7e5-4889-af95-b4e635213d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| datasets.py:296 in make_datasets() at 16:24:23.211\n",
      "ic| datasets.py:318 in make_datasets() at 16:24:23.296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using gradient accumulation\n"
     ]
    }
   ],
   "source": [
    "# idea is to not have to re-run this cell for subsequent training runs unless the centroids change\n",
    "\n",
    "ds_configs = DotMap({\n",
    "    'mnist': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_gamma',\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'image_size': (28, 28),\n",
    "    },\n",
    "    'mnist_7x7': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_7x7_gamma',\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'mnist_7x7_contin': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': None,\n",
    "        'n_colors': 4,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'mnist_binary_7x7': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'mnist',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 60000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_split_distribution': 'mnist_7x7_gamma',\n",
    "        'n_colors': 2,\n",
    "        'n_color_dims': 1,\n",
    "        'rescale': (7, 7),\n",
    "    },\n",
    "    'celeb': {\n",
    "        'type': 'image',\n",
    "        'tfds_name': 'celeb_a',\n",
    "        'continuous': False,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "        'shuffle': True,\n",
    "        'n_colors': 16,\n",
    "        'n_split_distribution': 'mnist_gamma',\n",
    "        'n_color_dims': 3,\n",
    "        'image_size': (218, 178),\n",
    "        'rescale': (32, 39),\n",
    "    },\n",
    "    'hands': {\n",
    "        'type': 'hands',\n",
    "        'continuous': True,\n",
    "        'loss': 'gaussian',\n",
    "        'n_dist_params': 2, # gaussian dist has 2 params\n",
    "        'shuffle': 'joints',\n",
    "        'n_dof': 23,\n",
    "        'n_frames': 30,\n",
    "        'n_split_distribution': None,\n",
    "        'buffer_size': 10000,\n",
    "        'noise_fraction': None,\n",
    "    },\n",
    "})\n",
    "\n",
    "config.dataset = ds_configs[config.ds]\n",
    "config.dataset.discrete = not config.dataset.continuous\n",
    "\n",
    "if config.dataset.type == 'image':\n",
    "    dataset, metadata = tfds.load(config.dataset.tfds_name, with_info=True, as_supervised=True)\n",
    "    ds_train_original = dataset['train'].map(datasets.ignore_label)\n",
    "    ds_test_original = dataset['test'].map(datasets.ignore_label)\n",
    "    centroids = datasets.find_centroids(config, ds_train_original)\n",
    "    if config.dataset.rescale:\n",
    "        config.dataset.image_size = config.dataset.rescale\n",
    "    config.dataset.seq_length = config.dataset.image_size[0]*config.dataset.image_size[1]*config.dataset.n_color_dims\n",
    "elif config.dataset.type == 'hands':\n",
    "    dataset = create_dataset.tf_dataset()\n",
    "    centroids = None\n",
    "    ds_train_original = dataset.map(datasets.ignore_metadata)\n",
    "    ds_test_original = dataset.map(datasets.ignore_metadata)\n",
    "    config.dataset.seq_length = config.dataset.n_dof * config.dataset.n_frames\n",
    "    \n",
    "if config.dataset.n_split_distribution == 'mnist_gamma':\n",
    "    gamma_dist, gamma_name = datasets.mnist_gamma_distribution()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "elif config.dataset.n_split_distribution == 'mnist_7x7_gamma':\n",
    "    gamma_dist, gamma_name = datasets.gamma_distribution_7x7()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "elif config.dataset.n_split_distribution == 'mnist_12x12_gamma':\n",
    "    gamma_dist, gamma_name = datasets.gamma_distribution_12x12()\n",
    "    datasets.plot_distribution(config, gamma_dist, gamma_name)\n",
    "else:\n",
    "    gamma_dist, gamma_name = None, None\n",
    "\n",
    "\n",
    "ds = datasets.Datasets(config, ds_train_original, ds_test_original, centroids, gamma_dist)\n",
    "viz = vizualization.Viz(config, ds, centroids)\n",
    "ds_train, ds_test = ds.make_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462f03d4-5dbc-4c9e-b1a5-2f70381fbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset.type == 'image':\n",
    "    display_colors, display_idxs, *_ = next(iter(ds_train))\n",
    "    if config.grad_accum_steps:\n",
    "        display_colors,display_idxs = display_colors[0],display_idxs[0]\n",
    "    if config.dataset.continuous:\n",
    "        display_colors = ds.reinvent_color_dim(display_colors)\n",
    "    viz.showSeq(display_colors, display_idxs, config.dataset.image_size, do_unquantize=config.dataset.discrete, max_images=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cffaf944-1a78-4029-99bd-04c99a9fbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset.type == 'image':\n",
    "    x_idx = tf.range(784)\n",
    "    pos_enc = models.pos_enc(n_dims=16, scale=100)\n",
    "    x = models.dual_positional_encoding((28,28), pos_enc)(x_idx)\n",
    "    x = x / 2. + 0.5\n",
    "    x = tf.expand_dims(tf.transpose(x), -1)\n",
    "    x_idx = tf.tile(x_idx[None, :], [16, 1])\n",
    "    viz.showSeq(x[:8], x_idx[:8], (28, 28), 8)\n",
    "    viz.showSeq(x[8:16], x_idx[8:16], (28, 28), 8)\n",
    "    viz.showSeq(x[16:24], x_idx[16:24], (28, 28), 8)\n",
    "    viz.showSeq(x[24:], x_idx[24:], (28, 28), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "636a3bbc-bc94-4fa4-9966-45fd3e96fa02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxpc-hands-2layers-contin-bs1x1x8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model config\n",
    "config.model = DotMap({\n",
    "    'comment': '2layers',\n",
    "    'discrete': config.dataset.discrete,\n",
    "    'continuous': config.dataset.continuous,\n",
    "    'n_enc_a_layers': 2,\n",
    "    'n_enc_b_layers': 2,\n",
    "    'ffl_dim': 64,\n",
    "    'embd_dim': 64,\n",
    "    'n_dec_layers': 1,\n",
    "    'dec_dim': 400,\n",
    "    'n_heads': 8,\n",
    "    'dropout_rate': 0.1,\n",
    "    'use_idxs_input': True,\n",
    "    'architecture': 'anp',\n",
    "    'use_relative_positions': False,\n",
    "    'activation': 'swish'\n",
    "})\n",
    "\n",
    "if config.model.continuous:\n",
    "    config.model.distribution = config.dataset.loss\n",
    "    config.model.n_dist_params = config.dataset.n_dist_params\n",
    "\n",
    "if config.dataset.type == 'image':\n",
    "    config.model.n_colors = config.dataset.n_colors\n",
    "    config.model.n_color_dims = config.dataset.n_color_dims\n",
    "    config.model.image_size = config.dataset.image_size\n",
    "    config.model.seq_len = config.dataset.image_size[0] * config.dataset.image_size[1]\n",
    "    config.model.position_embedding = 'pos_enc'\n",
    "else:\n",
    "    config.model.seq_len = config.dataset.n_frames * config.dataset.n_dof\n",
    "    config.model.n_frames = config.dataset.n_frames\n",
    "    config.model.n_dof = config.dataset.n_dof\n",
    "    config.model.position_embedding = 'pos_and_embd'\n",
    "    \n",
    "\n",
    "if config.distributed == False:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.transformer(config.model)\n",
    "    # Adam params taken from the linked notebook\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=schedules.learning_rate_schedule(config))\n",
    "\n",
    "if config.distributed:\n",
    "    ds_train = strategy.experimental_distribute_dataset(ds_train)\n",
    "\n",
    "config.training_mode = 'query_next'\n",
    "\n",
    "import socket\n",
    "model_name = models.model_name(config)\n",
    "print(model_name)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "171f56f2-d010-4072-8f19-8f20e5224886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "(None, None)\n",
      "(None, None, 2)\n",
      "(None, None)\n",
      "(None, None, 2)\n",
      "1000/1000 [==============================] - 89s 85ms/step - loss: 0.9560\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.3295\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 0.1097\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: -0.0367\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 86s 86ms/step - loss: -0.1790\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: -0.3884\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: -0.6898\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: -0.9355\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 86s 86ms/step - loss: -1.0814\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: -1.2191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f356c8806a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=training.von_mises_loss, optimizer=optimizer)\n",
    "ds_train_keras_fit = ds_train.map(training.ds_input_to_keras(config))\n",
    "model.fit(ds_train_keras_fit, steps_per_epoch=1000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d62aed9f-9442-46ac-884e-2dd4be134cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaler = training.Evaluator(config, model, optimizer, viz, ds, ds_train, ds_test)\n",
    "\n",
    "# training_loop = training.TrainingLoop(config, evaler, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d75d115b-dc33-4894-aa46-824a0446e2d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# with strategy.scope():\n",
    "#     training_loop.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5666655d-f24d-43c1-a085-a13d6df25fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 16:38:51.391495: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_4 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/maxpc-hands-2layers-contin-bs1x1x8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/maxpc-hands-2layers-contin-bs1x1x8/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abec3144-404e-4772-92f1-7038a1772270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if config.dataset.type == 'image':\n",
    "#     evaler.process_batch(show_input=True)\n",
    "#     evaler.new_test_batch()\n",
    "#     evaler.process_batch(show_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c19055-3dc4-460b-bc73-7555ddf1b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/home/maxeonyx/msc/msc-cgt-hands/manipnet/Data/SimpleVisualizer/Assets/BVH/bottle1_body1/rightHand.bvh\"\n",
    "\n",
    "# manager = enlighten.get_manager()\n",
    "\n",
    "# dof = 23\n",
    "# prev_frames = 30\n",
    "# n_frames_to_predict = 600\n",
    "\n",
    "# counter = manager.counter(total=n_frames_to_predict)\n",
    "\n",
    "# dof_idxs = tf.tile(tf.range(dof)[None, :], [prev_frames + 1, 1])\n",
    "# frame_idxs = tf.tile(tf.range(prev_frames + 1)[:, None], [1, dof]) * dof\n",
    "# idxs = dof_idxs + frame_idxs\n",
    "# idxs = tf.reshape(idxs, [-1])\n",
    "\n",
    "# def iteration(i, data):\n",
    "#     tar_idx = prev_frames*dof + i + 1\n",
    "#     inp_idxs = tf.range(i, prev_frames*dof + i)\n",
    "#     inp = data[-prev_frames*dof:]\n",
    "#     inp_len = tf.shape(inp_idxs)[0]\n",
    "#     tar_len = 1\n",
    "#     params = model({\n",
    "#         \"colors\": inp[None, :],\n",
    "#         \"inp_idxs\": inp_idxs[None, :],\n",
    "#         \"tar_idxs\": tar_idx[None, None],\n",
    "#         \"enc_mask\": models.get_mask(models.MASK_NONE, inp_len, inp_len),\n",
    "#         \"dec_mask\": models.get_mask(models.MASK_NONE, inp_len, tar_len),\n",
    "#     })\n",
    "#     dist = tfp.layers.MixtureNormal(num_components = 3, event_shape=[])(params)\n",
    "#     sample = dist.sample()\n",
    "#     sample = tf.reshape(sample, [-1])\n",
    "#     data = tf.concat([data, sample], axis=0)\n",
    "#     return i+1, data\n",
    "\n",
    "# @tf.function(\n",
    "#     input_signature=[tf.TensorSpec([None, dof])],\n",
    "# )\n",
    "# def do_batch(data):\n",
    "#     inp_data = tf.reshape(data[-prev_frames:, :], [prev_frames*dof])\n",
    "#     _i, out_data = tf.while_loop(\n",
    "#         cond=lambda i, data: i < dof,\n",
    "#         body=iteration,\n",
    "#         loop_vars=[\n",
    "#             tf.constant(0),\n",
    "#             inp_data\n",
    "#         ],\n",
    "#         shape_invariants=[\n",
    "#             tf.TensorShape([]),\n",
    "#             tf.TensorShape([None]),\n",
    "#         ],\n",
    "#     )\n",
    "#     return tf.reshape(out_data[-dof:], [1, dof])\n",
    "\n",
    "# test_data = tf.cast(create_dataset.load_one_bvh_file(filename, convert_deg_to_rad=True), tf.float32)\n",
    "# generated_data = test_data[:prev_frames, :]\n",
    "# for i in counter(range(n_frames_to_predict)):\n",
    "#     result = do_batch(generated_data)\n",
    "#     generated_data = tf.concat([generated_data, result], axis=0)\n",
    "\n",
    "# counter.close()\n",
    "\n",
    "# print(generated_data)\n",
    "\n",
    "# import create_dataset\n",
    "# create_dataset.write_bvh_file(filename, generated_data.numpy(), convert_rad_to_deg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37ffeacb-7ace-440f-9338-80db930ccf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# np.save(\"/home/maxeonyx/gen_data\", generated_data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1409c9e6-9857-49e0-863e-97d4060fe06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a110310-ed51-43cc-9a8c-e56544e98d55",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
